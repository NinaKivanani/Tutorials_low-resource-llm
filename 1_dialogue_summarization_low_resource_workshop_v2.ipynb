{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48c569d",
   "metadata": {},
   "source": [
    "# Dialogue Summarization Workshop. From English to Low Resource Languages\n",
    "\n",
    "This notebook is a hands on, end to end tutorial on summarizing multi speaker dialogue. You will start with English, then switch into a low resource mindset by restricting data, adding noise, and applying techniques that transfer well when you have little labeled data and limited tools.\n",
    "\n",
    "\"\n",
    "\"You can run everything on CPU. If you have a GPU, the optional LLM section will run faster.\n",
    "\n",
    "\"\n",
    "\"## What you will build\n",
    "\n",
    "\"\n",
    "\"1. A clean dialogue dataset from raw text.\n",
    "\"\n",
    "\"2. A strong non LLM baseline summarizer (TextRank).\n",
    "\"\n",
    "\"3. An LLM based summarizer with prompt engineering (zero shot, one shot, few shot).\n",
    "\"\n",
    "\"4. A small evaluation harness (ROUGE like metrics, plus sanity checks).\n",
    "\"\n",
    "\"5. A low resource adaptation playbook you can reuse for any language.\n",
    "\n",
    "\"\n",
    "\"## How to use this notebook\n",
    "\n",
    "\"\n",
    "\"- Cells marked **Checkpoint** are the recommended stopping points.\n",
    "\"\n",
    "\"- Cells marked **Challenge** are optional. They still run out of the box, then you can modify them to earn extra points.\n",
    "\"\n",
    "\"- If you get stuck, re run from the top. Most steps are deterministic when the random seed is fixed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e85f7",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "### Option A. Minimal pip setup (recommended for workshops)\n",
    "\n",
    "Run the next cell. It installs only what this notebook uses.\n",
    "\n",
    "### Option B. Conda environment (Python 3.9)\n",
    "\n",
    "If you prefer an isolated environment.\n",
    "\n",
    "```bash\n",
    "conda create -n dialogue-sum python=3.9 -y\n",
    "conda activate dialogue-sum\n",
    "pip install -U pip\n",
    "pip install \"numpy<2\" pandas scikit-learn networkx matplotlib tqdm\n",
    "pip install \"transformers==4.49.0\" \"datasets==3.2.0\" \"accelerate>=0.25.0\" sentencepiece\n",
    "pip install rouge-score evaluate\n",
    "pip install ipywidgets\n",
    "```\n",
    "\n",
    "If you are on a managed cluster, you may need to load a CUDA module before installing PyTorch. Use the PyTorch install command recommended for your platform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fd6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal dependencies for this notebook.\n",
    "# If you already have these installed, you can skip this cell.\n",
    "\n",
    "import sys, subprocess\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy<2\",\n",
    "    \"pandas\",\n",
    "    \"scikit-learn\",\n",
    "    \"networkx\",\n",
    "    \"matplotlib\",\n",
    "    \"tqdm\",\n",
    "    \"rouge-score\",\n",
    "    \"evaluate\",\n",
    "    \"transformers==4.49.0\",\n",
    "    \"datasets==3.2.0\",\n",
    "    \"accelerate\",\n",
    "    \"sentencepiece\",\n",
    "]\n",
    "try:\n",
    "    import ipywidgets  # noqa\n",
    "except Exception:\n",
    "    pkgs.append(\"ipywidgets\")\n",
    "\n",
    "try:\n",
    "    pip_install(pkgs)\n",
    "    print(\"Done.\")\n",
    "except Exception as e:\n",
    "    print(\"Install step failed. You can continue if you already have the packages.\")\n",
    "    print(\"Error:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9611d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "random.seed(842)\n",
    "np.random.seed(842)\n",
    "\n",
    "print(\"Imports ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76613e6",
   "metadata": {},
   "source": [
    "## 1. Get a real dialogue dataset\n",
    "\n",
    "To keep this notebook self contained, we use a public domain English play. The text is not invented for this tutorial. It is an excerpt from *The Importance of Being Earnest* by Oscar Wilde (first published in 1895, public domain in many jurisdictions).\n",
    "\n",
    "We will parse it into speaker turns, then create short dialogue segments that resemble real conversations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e7fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_TEXT = '''\n",
    "[Enter Lane.]\n",
    "\n",
    "LANE. Why, Mr. Worthing, I suppose this is one of your pleasant\n",
    "surprises? I have been expecting you back some time ago.\n",
    "\n",
    "JACK. I have not been able to return sooner. I have been detained in\n",
    "town.\n",
    "\n",
    "LANE. I have received a message from Mr. Algernon. He says he will be\n",
    "down at four o'clock.\n",
    "\n",
    "JACK. Is Mr. Algernon here?\n",
    "\n",
    "LANE. Yes, sir. He is in the dining-room.\n",
    "\n",
    "JACK. I must see him at once.\n",
    "\n",
    "[Enter Algernon.]\n",
    "\n",
    "ALGERNON. How are you, my dear Ernest? What brings you up to town?\n",
    "\n",
    "JACK. Oh, pleasure, pleasure. What else should bring one anywhere?\n",
    "\n",
    "ALGERNON. Eating as usual, I see.\n",
    "\n",
    "JACK. I believe it is customary in good society to take some\n",
    "refreshment at five o'clock.\n",
    "\n",
    "ALGERNON. Well, it is a custom that I approve of, and I will do my best\n",
    "to start it again. However, you are not quite truthful. You did not\n",
    "come up for pleasure.\n",
    "\n",
    "JACK. What on earth do you mean?\n",
    "\n",
    "ALGERNON. You came up to town to tell me to keep away from your cousin.\n",
    "\n",
    "JACK. My cousin?\n",
    "\n",
    "ALGERNON. Yes. That charming girl you are always talking about.\n",
    "\n",
    "JACK. Cecily?\n",
    "\n",
    "ALGERNON. Cecily. She is my cousin now, you know.\n",
    "\n",
    "JACK. You have never met her.\n",
    "\n",
    "ALGERNON. She is my cousin because I intend to marry her.\n",
    "'''\n",
    "\n",
    "def parse_play_to_turns(text: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse a simple play excerpt into (speaker, utterance) turns.\n",
    "    Assumptions.\n",
    "    1) Speaker turns look like 'NAME.' at the start of a line.\n",
    "    2) Stage directions are in [brackets] or parentheses and are dropped.\n",
    "\n",
    "    Returns a DataFrame with columns: turn_id, speaker, text.\n",
    "    \"\"\"\n",
    "    lines = [ln.strip() for ln in text.strip().splitlines() if ln.strip()]\n",
    "    turns = []\n",
    "    current_speaker = None\n",
    "    buffer = []\n",
    "\n",
    "    def flush():\n",
    "        nonlocal buffer, current_speaker\n",
    "        if current_speaker and buffer:\n",
    "            utt = \" \".join(buffer).strip()\n",
    "            utt = re.sub(r\"\\s+\", \" \", utt)\n",
    "            if utt:\n",
    "                turns.append({\"speaker\": current_speaker, \"text\": utt})\n",
    "        buffer = []\n",
    "\n",
    "    speaker_pat = re.compile(r\"^([A-Z][A-Z\\s'\\-]+)\\.\\s*(.*)$\")\n",
    "\n",
    "    for ln in lines:\n",
    "        if ln.startswith(\"[\") and ln.endswith(\"]\"):\n",
    "            continue\n",
    "        if ln.startswith(\"(\") and ln.endswith(\")\"):\n",
    "            continue\n",
    "\n",
    "        m = speaker_pat.match(ln)\n",
    "        if m:\n",
    "            flush()\n",
    "            current_speaker = m.group(1).strip()\n",
    "            rest = m.group(2).strip()\n",
    "            if rest:\n",
    "                buffer.append(rest)\n",
    "        else:\n",
    "            buffer.append(ln)\n",
    "\n",
    "    flush()\n",
    "    df = pd.DataFrame(turns)\n",
    "    df.insert(0, \"turn_id\", range(len(df)))\n",
    "    return df\n",
    "\n",
    "turns_df = parse_play_to_turns(RAW_TEXT)\n",
    "turns_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ad9d0",
   "metadata": {},
   "source": [
    "### 1.1 Create dialogue windows\n",
    "\n",
    "Many dialogue datasets are long conversations. Summarization is easier to teach with smaller windows. We will create overlapping windows of turns, then treat each window as a dialogue sample.\n",
    "\n",
    "You can adjust the window size. Smaller windows are easier for small models. Larger windows stress test context handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b57c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dialogue_windows(turns: pd.DataFrame, window_turns: int = 10, stride: int = 6) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a turn DataFrame into overlapping dialogue windows.\n",
    "\n",
    "    Returns a DataFrame with: sample_id, dialogue_text, speakers_involved, n_turns.\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    n = len(turns)\n",
    "    sample_id = 0\n",
    "    for start in range(0, max(1, n - window_turns + 1), stride):\n",
    "        end = min(n, start + window_turns)\n",
    "        chunk = turns.iloc[start:end]\n",
    "        dialogue_lines = [f\"{r.speaker}: {r.text}\" for r in chunk.itertuples()]\n",
    "        dialogue_text = \"\\n\".join(dialogue_lines)\n",
    "        speakers = sorted(set(chunk[\"speaker\"].tolist()))\n",
    "        samples.append(\n",
    "            {\n",
    "                \"sample_id\": sample_id,\n",
    "                \"dialogue_text\": dialogue_text,\n",
    "                \"speakers_involved\": speakers,\n",
    "                \"n_turns\": int(end - start),\n",
    "            }\n",
    "        )\n",
    "        sample_id += 1\n",
    "        if end == n:\n",
    "            break\n",
    "    return pd.DataFrame(samples)\n",
    "\n",
    "samples_df = make_dialogue_windows(turns_df, window_turns=10, stride=6)\n",
    "samples_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6296f",
   "metadata": {},
   "source": [
    "### 1.2 Preview one sample\n",
    "\n",
    "Read the dialogue. Then, in your own words, write a one sentence summary in the next cell. Keep it short. This will become our first human reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070188fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = samples_df.loc[0, \"dialogue_text\"]\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d3f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your one sentence reference summary.\n",
    "# You can edit this string. The notebook will still run if you do not.\n",
    "\n",
    "REFERENCE_SUMMARY = \"Jack arrives and learns Algernon is visiting, then Algernon teases Jack and reveals he plans to marry Jack's cousin Cecily.\"\n",
    "\n",
    "print(REFERENCE_SUMMARY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6406b9ca",
   "metadata": {},
   "source": [
    "## 2. Baseline. Extractive TextRank summarization\n",
    "\n",
    "Before using an LLM, build a baseline that is fast, cheap, and interpretable. TextRank selects the most central sentences using a similarity graph and PageRank.\n",
    "\n",
    "This baseline is language agnostic, as long as you can split text into sentences. That is why it is valuable for low resource languages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2aed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "\n",
    "def split_sentences(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Very simple sentence splitter.\n",
    "    For robust multilingual splitting, consider spaCy or Stanza.\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    sents = re.split(r\"(?<=[\\.\\?\\!])\\s+\", text)\n",
    "    return [s.strip() for s in sents if s.strip()]\n",
    "\n",
    "def textrank_summarize(dialogue_text: str, max_sentences: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Extractive summarization using TextRank on sentence similarity.\n",
    "    \"\"\"\n",
    "    content = re.sub(r\"^[A-Z][A-Z\\s'\\-]+:\\s*\", \"\", dialogue_text, flags=re.MULTILINE)\n",
    "    sentences = split_sentences(content)\n",
    "    if not sentences:\n",
    "        return \"\"\n",
    "    if len(sentences) <= max_sentences:\n",
    "        return \" \".join(sentences)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    X = vectorizer.fit_transform(sentences)\n",
    "    sim = cosine_similarity(X)\n",
    "    np.fill_diagonal(sim, 0.0)\n",
    "\n",
    "    graph = nx.from_numpy_array(sim)\n",
    "    scores = nx.pagerank(graph, max_iter=200)\n",
    "\n",
    "    ranked = sorted(range(len(sentences)), key=lambda i: scores.get(i, 0.0), reverse=True)\n",
    "    picked = sorted(ranked[:max_sentences])\n",
    "    return \" \".join([sentences[i] for i in picked])\n",
    "\n",
    "baseline_summary = textrank_summarize(sample, max_sentences=2)\n",
    "print(\"Baseline summary:\\n\", baseline_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a7d4f",
   "metadata": {},
   "source": [
    "### 2.1 Quick evaluation. ROUGE\n",
    "\n",
    "ROUGE is imperfect, but it is a quick sanity check. We will compute ROUGE 1, ROUGE 2, and ROUGE L against your reference summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ed187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def rouge_scores(pred: str, ref: str) -> Dict[str, float]:\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "    scores = scorer.score(ref, pred)\n",
    "    return {k: v.fmeasure for k, v in scores.items()}\n",
    "\n",
    "print(\"ROUGE (baseline vs reference):\")\n",
    "rouge_scores(baseline_summary, REFERENCE_SUMMARY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97e0e1",
   "metadata": {},
   "source": [
    "## 3. Mini quiz. What makes dialogue summarization harder?\n",
    "\n",
    "Try to answer before running the cell. Then run it for instant feedback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c54153",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "except Exception:\n",
    "    widgets = None\n",
    "\n",
    "QUESTION = \"Which factor is most specific to dialogue summarization, compared to single speaker summarization?\"\n",
    "OPTIONS = [\n",
    "    \"A. Dialogues contain named entities.\",\n",
    "    \"B. Dialogues include speaker turns and pragmatic intent.\",\n",
    "    \"C. Dialogues use punctuation.\",\n",
    "    \"D. Dialogues are always longer than articles.\",\n",
    "]\n",
    "CORRECT = 1\n",
    "EXPLANATION = \"Speaker turns and pragmatic intent are core. You often need to resolve who said what and why.\"\n",
    "\n",
    "def run_quiz():\n",
    "    if widgets is None:\n",
    "        print(QUESTION)\n",
    "        for opt in OPTIONS:\n",
    "            print(opt)\n",
    "        print(\"\\nCorrect:\", OPTIONS[CORRECT])\n",
    "        print(\"Explanation:\", EXPLANATION)\n",
    "        return\n",
    "\n",
    "    radio = widgets.RadioButtons(options=OPTIONS, description=\"Your answer:\")\n",
    "    out = widgets.Output()\n",
    "\n",
    "    def on_change(change):\n",
    "        if change[\"name\"] != \"value\":\n",
    "            return\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            idx = OPTIONS.index(change[\"new\"])\n",
    "            if idx == CORRECT:\n",
    "                print(\"Correct.\")\n",
    "            else:\n",
    "                print(\"Not quite.\")\n",
    "            print(\"Explanation:\", EXPLANATION)\n",
    "\n",
    "    radio.observe(on_change)\n",
    "    display(radio, out)\n",
    "\n",
    "run_quiz()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258f279",
   "metadata": {},
   "source": [
    "## 4. LLM summarization with prompt engineering (optional)\n",
    "\n",
    "We will use a small instruction tuned model. By default we try `google/flan-t5-small`.\n",
    "\n",
    "If you have no internet access, model download will fail. In that case, skip this section or point `MODEL_NAME` to a local model path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9612676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "MODEL_NAME = \"google/flan-t5-small\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "tokenizer = None\n",
    "model = None\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)\n",
    "    print(\"Loaded:\", MODEL_NAME)\n",
    "except Exception as e:\n",
    "    print(\"Could not load model. Reason:\", repr(e))\n",
    "    print(\"You can continue with the baseline sections.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc256477",
   "metadata": {},
   "source": [
    "### 4.1 Zero shot instruction prompt\n",
    "\n",
    "Prompting matters. We will start with a plain instruction. Then we will refine it.\n",
    "\n",
    "Goal. Produce a concise, faithful summary. Mention key decisions, conflicts, and planned actions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f93aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_t5(dialogue_text: str, prompt: str, max_new_tokens: int = 80, temperature: float = 0.0, top_p: float = 1.0) -> str:\n",
    "    if tokenizer is None or model is None:\n",
    "        return \"(LLM section skipped. Model not available.)\"\n",
    "\n",
    "    full_prompt = prompt.strip() + \"\\n\\nDIALOGUE:\\n\" + dialogue_text.strip() + \"\\n\\nSUMMARY:\"\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\", truncation=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=int(max_new_tokens),\n",
    "            do_sample=temperature > 0.0,\n",
    "            temperature=float(max(1e-6, temperature)),\n",
    "            top_p=float(top_p),\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n",
    "\n",
    "ZERO_SHOT_PROMPT = \"Summarize the following conversation in 1 to 2 sentences. Keep only the important information.\"\n",
    "\n",
    "llm_zero = generate_summary_t5(sample, ZERO_SHOT_PROMPT)\n",
    "print(llm_zero)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c400a2f",
   "metadata": {},
   "source": [
    "### 4.2 Prompt remix playground\n",
    "\n",
    "You will remix a prompt by selecting options. This is a safe way to teach prompt engineering without making it feel abstract.\n",
    "\n",
    "Pick your settings, then run the cell. Try to make the summary both concise and faithful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2015b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_OPTIONS = [\"neutral\", \"bullet\", \"tweet\", \"meeting_minutes\"]\n",
    "FOCUS_OPTIONS = [\"decisions\", \"conflict\", \"relationships\", \"actions\"]\n",
    "\n",
    "def build_prompt(style: str, focus: str, max_sentences: int) -> str:\n",
    "    style = style.lower().strip()\n",
    "    focus = focus.lower().strip()\n",
    "\n",
    "    base = f\"Summarize the conversation in at most {max_sentences} sentences.\"\n",
    "    if focus == \"decisions\":\n",
    "        base += \" Focus on decisions and commitments.\"\n",
    "    elif focus == \"conflict\":\n",
    "        base += \" Focus on disagreements and what caused them.\"\n",
    "    elif focus == \"relationships\":\n",
    "        base += \" Focus on who relates to whom and the social situation.\"\n",
    "    elif focus == \"actions\":\n",
    "        base += \" Focus on actions and next steps.\"\n",
    "\n",
    "    if style == \"bullet\":\n",
    "        base += \" Use 2 to 4 bullet points.\"\n",
    "    elif style == \"tweet\":\n",
    "        base += \" Write it as a single tweet style sentence, under 240 characters.\"\n",
    "    elif style == \"meeting_minutes\":\n",
    "        base += \" Format as meeting minutes with sections: Context, Key Points, Next Steps.\"\n",
    "\n",
    "    base += \" Do not invent facts. Preserve names.\"\n",
    "    return base\n",
    "\n",
    "def run_playground(style=\"neutral\", focus=\"relationships\", max_sentences=2):\n",
    "    prompt = build_prompt(style, focus, max_sentences)\n",
    "    print(\"Prompt:\\n\", prompt, \"\\n\")\n",
    "    out = generate_summary_t5(sample, prompt, max_new_tokens=120, temperature=0.0)\n",
    "    print(\"Model output:\\n\", out)\n",
    "    return out\n",
    "\n",
    "llm_play = run_playground(style=\"meeting_minutes\", focus=\"relationships\", max_sentences=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c375adbb",
   "metadata": {},
   "source": [
    "### 4.3 One shot and few shot prompts\n",
    "\n",
    "When you have little data, examples are powerful. We will create a small in notebook prompt set.\n",
    "\n",
    "You can replace the examples with your own dialogues later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9939ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_DIALOGUE = \"\"\"ALICE: Are we still meeting at 3?\n",
    "BOB: Yes, but I will be 10 minutes late.\n",
    "ALICE: Ok. Please bring the slides.\n",
    "BOB: Will do.\"\"\"\n",
    "\n",
    "EXAMPLE_SUMMARY = \"Alice and Bob confirm a 3 pm meeting. Bob will arrive 10 minutes late and will bring the slides.\"\n",
    "\n",
    "ONE_SHOT_PROMPT = f\"\"\"Summarize the conversation in 1 to 2 sentences. Do not invent facts.\n",
    "\n",
    "Example.\n",
    "DIALOGUE:\n",
    "{EXAMPLE_DIALOGUE}\n",
    "\n",
    "SUMMARY:\n",
    "{EXAMPLE_SUMMARY}\n",
    "\n",
    "Now summarize this dialogue.\n",
    "\"\"\"\n",
    "\n",
    "llm_one = generate_summary_t5(sample, ONE_SHOT_PROMPT, max_new_tokens=120, temperature=0.0)\n",
    "print(llm_one)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c395098e",
   "metadata": {},
   "source": [
    "### 4.4 Generation parameters. Temperature and length\n",
    "\n",
    "Temperature can change factuality. Length controls how much detail you get.\n",
    "\n",
    "Use the sliders if available. Otherwise, edit the numbers and rerun.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_generation_controls(temperature: float = 0.0, max_new_tokens: int = 80):\n",
    "    prompt = build_prompt(style=\"neutral\", focus=\"actions\", max_sentences=2)\n",
    "    out = generate_summary_t5(sample, prompt, max_new_tokens=max_new_tokens, temperature=temperature, top_p=0.95)\n",
    "    print(\"temperature:\", temperature, \"max_new_tokens:\", max_new_tokens)\n",
    "    print(out)\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    if tokenizer is None or model is None:\n",
    "        raise RuntimeError(\"Model not available, skipping widgets.\")\n",
    "    ui = widgets.interactive(\n",
    "        demo_generation_controls,\n",
    "        temperature=widgets.FloatSlider(min=0.0, max=1.0, step=0.1, value=0.0),\n",
    "        max_new_tokens=widgets.IntSlider(min=30, max=200, step=10, value=80),\n",
    "    )\n",
    "    display(ui)\n",
    "except Exception:\n",
    "    demo_generation_controls(temperature=0.0, max_new_tokens=80)\n",
    "    demo_generation_controls(temperature=0.7, max_new_tokens=120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7860c7",
   "metadata": {},
   "source": [
    "## 5. Compare baselines vs LLM\n",
    "\n",
    "We compare summaries and compute ROUGE against your reference.\n",
    "\n",
    "In real work, you should also do human evaluation. For example factuality checks, missing action items, and speaker attribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a176f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results.append((\"TextRank baseline\", baseline_summary))\n",
    "results.append((\"LLM zero shot\", llm_zero))\n",
    "results.append((\"LLM one shot\", llm_one))\n",
    "results.append((\"LLM prompt remix\", llm_play))\n",
    "\n",
    "rows = []\n",
    "for name, pred in results:\n",
    "    rows.append({\"system\": name, \"summary\": pred, **rouge_scores(pred, REFERENCE_SUMMARY)})\n",
    "\n",
    "pd.DataFrame(rows).sort_values(\"rougeL\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e6fb1",
   "metadata": {},
   "source": [
    "## 6. Low resource mode. Make English behave like a low resource language\n",
    "\n",
    "Low resource usually means one or more of the following.\n",
    "- Very little labeled data.\n",
    "- Limited tools for tokenization, sentence splitting, and normalization.\n",
    "- Domain mismatch. Your data looks different from what models saw during pre training.\n",
    "- Orthography variation and borrowing, including code switching.\n",
    "\n",
    "We will simulate these constraints in English by.\n",
    "1) Reducing the available context.\n",
    "2) Corrupting the text with noise and inconsistent spelling.\n",
    "3) Removing punctuation, which hurts naive sentence splitting.\n",
    "\n",
    "Then we apply strategies that transfer to true low resource settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19d5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_resource_corrupt(text: str, drop_punct_prob: float = 0.5, typo_prob: float = 0.08) -> str:\n",
    "    rng = random.Random(842)\n",
    "    out_chars = []\n",
    "    for ch in text:\n",
    "        if ch in \".?!,\" and rng.random() < drop_punct_prob:\n",
    "            continue\n",
    "        if ch.isalpha() and rng.random() < typo_prob:\n",
    "            if rng.random() < 0.5:\n",
    "                out_chars.append(ch.swapcase())\n",
    "            else:\n",
    "                out_chars.append(chr(((ord(ch.lower()) - 97 + 1) % 26) + 97))\n",
    "        else:\n",
    "            out_chars.append(ch)\n",
    "    return \"\".join(out_chars)\n",
    "\n",
    "low_text = low_resource_corrupt(sample, drop_punct_prob=0.8, typo_prob=0.05)\n",
    "print(low_text[:600])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline on clean text:\")\n",
    "print(textrank_summarize(sample, max_sentences=2))\n",
    "print(\"\\nBaseline on low resource corrupted text:\")\n",
    "print(textrank_summarize(low_text, max_sentences=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df866059",
   "metadata": {},
   "source": [
    "### 6.1 Strategy toolkit\n",
    "\n",
    "Here are practical tactics that often help in low resource dialogue summarization.\n",
    "\n",
    "1. Normalize input.\n",
    "   - Fix common punctuation issues.\n",
    "   - Normalize whitespace.\n",
    "   - Normalize speaker labels.\n",
    "\n",
    "2. Use robust segmentation.\n",
    "   - If sentence splitting fails, summarize at turn level.\n",
    "\n",
    "3. Constrain generation.\n",
    "   - Use explicit length limits.\n",
    "   - Instruct the model to preserve names, numbers, and decisions.\n",
    "\n",
    "4. Add lightweight context.\n",
    "   - Provide a glossary of names and places.\n",
    "   - Provide a domain hint, such as \"family conversation\" or \"customer support\".\n",
    "\n",
    "5. Evaluate with targeted checks.\n",
    "   - Did we preserve who wants to marry whom.\n",
    "   - Did we hallucinate actions that never happened.\n",
    "\n",
    "We will implement 1 and 2 now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a203e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dialogue(text: str) -> str:\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"([A-Z][A-Z\\s'\\-]+:)\\s*\", r\"\\n\\1 \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def turn_level_summarize(dialogue_text: str, max_turns: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Extractive turn level summarization, more robust than sentence splitting.\n",
    "    \"\"\"\n",
    "    lines = [ln.strip() for ln in dialogue_text.splitlines() if ln.strip()]\n",
    "    lines = [ln for ln in lines if len(ln) > 10]\n",
    "    if not lines:\n",
    "        return \"\"\n",
    "    if len(lines) <= max_turns:\n",
    "        return \" \".join(lines)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    X = vectorizer.fit_transform(lines)\n",
    "    sim = cosine_similarity(X)\n",
    "    np.fill_diagonal(sim, 0.0)\n",
    "    graph = nx.from_numpy_array(sim)\n",
    "    scores = nx.pagerank(graph, max_iter=200)\n",
    "    ranked = sorted(range(len(lines)), key=lambda i: scores.get(i, 0.0), reverse=True)\n",
    "    picked = sorted(ranked[:max_turns])\n",
    "    return \" \".join([lines[i] for i in picked])\n",
    "\n",
    "print(\"Before normalization:\\n\", low_text[:250], \"\\n\")\n",
    "norm_low = normalize_dialogue(low_text)\n",
    "print(\"After normalization:\\n\", norm_low[:250])\n",
    "print(\"\\nTurn level summary on corrupted text:\\n\", turn_level_summarize(norm_low, max_turns=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8837fd",
   "metadata": {},
   "source": [
    "### 6.2 Low resource prompting\n",
    "\n",
    "If you can use an instruction model, you can push it to behave better on noisy input. The key is to add constraints.\n",
    "\n",
    "We will.\n",
    "- Ask for short output.\n",
    "- Ask it to avoid inventing facts.\n",
    "- Ask it to preserve names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOW_RESOURCE_PROMPT = \"\"\"Summarize the conversation in 1 sentence.\n",
    "Rules.\n",
    "1) Do not invent facts.\n",
    "2) Preserve names exactly as they appear.\n",
    "3) If the text is noisy, infer only what is obvious.\"\"\"\n",
    "\n",
    "if tokenizer is None or model is None:\n",
    "    print(\"Model not available, skipping.\")\n",
    "else:\n",
    "    print(generate_summary_t5(norm_low, LOW_RESOURCE_PROMPT, max_new_tokens=60, temperature=0.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f285af",
   "metadata": {},
   "source": [
    "## Optional mini dataset hook. Try a real non-English case in two minutes\n",
    "\n",
    "This workshop is designed to start in English, then transfer the same workflow to a low-resource language.\n",
    "\n",
    "Below are two quick options.\n",
    "\n",
    "1. **MiniLux micro-set (synthetic)**. A small set of short Luxembourgish and LU, FR mixed snippets created for teaching. It is intentionally tiny and imperfect, so that you can iterate fast and discuss typical issues, like code-switching, named entities, and spelling variation.\n",
    "\n",
    "2. **Hugging Face low-resource sample (real text)**. Pull 20 examples from a multilingual summarization dataset and run the same prompt, plus the same evaluation, to see how performance changes outside English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1. MiniLux micro-set (synthetic)\n",
    "# This is only for the workshop. You can replace it with your own low-resource dialogues later.\n",
    "\n",
    "mini_lux = [\n",
    "    {\n",
    "        \"id\": \"lux_001\",\n",
    "        \"dialogue\": \"A: Moien. Hues du Zäit fir e Kaffi?\\nB: Jo, mä just zéng Minutten. Ech muss gläich op d'Aarbecht.\\nA: Ok. Mir treffen eis beim Gare.\\nB: Super, ech kommen direkt.\",\n",
    "        \"reference_summary_en\": \"They agree to meet for a quick coffee at the station before B goes to work.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_002\",\n",
    "        \"dialogue\": \"A: Wéi war d'Reunioun haut?\\nB: Ganz laang. Mir hu just d'Agenda diskutéiert.\\nA: An hu mir eng Decisioun?\\nB: Nee, mir maachen et nächste Woch nach eng Kéier.\",\n",
    "        \"reference_summary_en\": \"The meeting was long, they only discussed the agenda, and no decision was made.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_003\",\n",
    "        \"dialogue\": \"A: Kanns du mer de Rapport schécken?\\nB: Jo. Ech schécken en elo per Mail.\\nA: Merci. Ech muss en nach haut ofginn.\\nB: Kloer, ech maachen et direkt.\",\n",
    "        \"reference_summary_en\": \"B will email A the report immediately because A must submit it today.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_004\",\n",
    "        \"dialogue\": \"A: Ech sinn am Stau op der A6.\\nB: Ok, dann fänke mir ouni dech un.\\nA: Gitt mir zéng Minutten.\\nB: Passt. Mir halen dir e Sëtz fräi.\",\n",
    "        \"reference_summary_en\": \"A is stuck in traffic but will arrive in about ten minutes, and the others will start and save a seat.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_005\",\n",
    "        \"dialogue\": \"A: Ech hu muer en rendez-vous chez le médecin.\\nB: Bass du ok?\\nA: Jo, just e Check-up.\\nB: Ok, soen mer dono wéi et gaangen ass.\",\n",
    "        \"reference_summary_en\": \"A has a doctor appointment tomorrow for a check-up and will update B afterward.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_006\",\n",
    "        \"dialogue\": \"A: Wou si mir mam Projet?\\nB: Mir hu 80 Prozent fäerdeg.\\nA: Wat feelt nach?\\nB: D'Dokumentatioun an d'Tester.\",\n",
    "        \"reference_summary_en\": \"The project is about 80 percent done, but documentation and testing are still missing.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_007\",\n",
    "        \"dialogue\": \"A: Ech kréien ëmmer eng Fehlermeldung.\\nB: Wéi eng?\\nA: 'Permission denied'.\\nB: Dann hues du wahrscheinlech keng Rechter. Probéier et mat sudo oder fro den Admin.\",\n",
    "        \"reference_summary_en\": \"A gets a permission error, and B suggests using sudo or asking the admin for access.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_008\",\n",
    "        \"dialogue\": \"A: Mir treffen eis um 14:00.\\nB: Ech sinn um 14:15 do.\\nA: Ok, ech waarden am Café.\\nB: Merci. Bis gläich.\",\n",
    "        \"reference_summary_en\": \"They planned to meet at 14:00, but B will arrive at 14:15 and A will wait at a café.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_009\",\n",
    "        \"dialogue\": \"A: Hues du d'Presentatioun gesinn?\\nB: Jo, si ass gutt, mä d'Grafike sinn ze kleng.\\nA: Ok, ech maachen se méi grouss.\\nB: Super, dann ass et perfekt.\",\n",
    "        \"reference_summary_en\": \"B thinks the presentation is good but the charts are too small, so A will enlarge them.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_010\",\n",
    "        \"dialogue\": \"A: Ech sinn haut am Homeoffice.\\nB: Ok, kënns du trotzdem an de Call?\\nA: Jo, ech sinn do um 10:00.\\nB: Top, ech schécken de Link.\",\n",
    "        \"reference_summary_en\": \"A works from home but will join the 10:00 call, and B will send the link.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_011\",\n",
    "        \"dialogue\": \"A: Mir brauche nach e Beispill fir d'Course.\\nB: Wat fir ee Beispill?\\nA: E klengt Dialog-Set fir Zesummefaassung.\\nB: Ok, ech schreiwen 20 kuerz Dialogen.\",\n",
    "        \"reference_summary_en\": \"They need a small dialogue dataset for a summarization course, and B will write 20 short dialogues.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_012\",\n",
    "        \"dialogue\": \"A: Kanns du den Text nach eng Kéier kontrolléieren?\\nB: Jo, ech kucken no Tippfeeler.\\nA: An och Punktuatioun.\\nB: Maachen ech.\",\n",
    "        \"reference_summary_en\": \"B will proofread the text for typos and punctuation.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_013\",\n",
    "        \"dialogue\": \"A: Ech hu meng Schlësselen vergiess.\\nB: Wou bass du?\\nA: Virun der Dier.\\nB: Ech kommen, ginn mer fënnef Minutten.\",\n",
    "        \"reference_summary_en\": \"A forgot their keys and is locked out, and B will come in five minutes.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_014\",\n",
    "        \"dialogue\": \"A: De Bus kënnt net.\\nB: Hues du d'App gekuckt?\\nA: Jo, et steet 'retard'.\\nB: Dann huele mir en Taxi.\",\n",
    "        \"reference_summary_en\": \"The bus is delayed, so they decide to take a taxi.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_015\",\n",
    "        \"dialogue\": \"A: Ech muss nach d'Fichieren eroplueden.\\nB: Wou?\\nA: Op Hugging Face.\\nB: Ok, vergiss net d'Lizens an d'Readme.\",\n",
    "        \"reference_summary_en\": \"A needs to upload files to Hugging Face, and B reminds them to include a license and README.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_016\",\n",
    "        \"dialogue\": \"A: D'GPU ass fräi.\\nB: Super, dann starte mir den Training.\\nA: Ech setzen batch size op 4.\\nB: Ok, da maache mir gradient accumulation.\",\n",
    "        \"reference_summary_en\": \"They have GPU availability and will start training with a small batch size and gradient accumulation.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_017\",\n",
    "        \"dialogue\": \"A: Kanns du mir den Deadline soen?\\nB: Et ass Freideg um 18:00.\\nA: Merci, ech maachen et haut nach.\\nB: Gutt Iddi.\",\n",
    "        \"reference_summary_en\": \"The deadline is Friday at 18:00, and A plans to finish today.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_018\",\n",
    "        \"dialogue\": \"A: Ech hunn d'Donnéeën gereinegt.\\nB: Super. Hues du och d'Nummeren normaliséiert?\\nA: Jo, ech hunn se an Wierder ëmgewandelt.\\nB: Perfekt.\",\n",
    "        \"reference_summary_en\": \"A cleaned the data and normalized numbers by converting them into words.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_019\",\n",
    "        \"dialogue\": \"A: Ech verstinn d'Resultater net.\\nB: Wat ass komesch?\\nA: D'Accuracy ass héich, mä d'F1 ass niddreg.\\nB: Dann ass et wahrscheinlech Klassen-Imbalance.\",\n",
    "        \"reference_summary_en\": \"Accuracy is high but F1 is low, suggesting class imbalance.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_020\",\n",
    "        \"dialogue\": \"A: Tu peux me rappeler le plan?\\nB: Oui. D'abord on teste en anglais, après on passe au luxembourgeois.\\nA: An de Prompt bleift ähnlech.\\nB: Genau.\",\n",
    "        \"reference_summary_en\": \"They will test in English first, then switch to Luxembourgish while keeping a similar prompt.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_021\",\n",
    "        \"dialogue\": \"A: Ech sinn net sécher ob 'Zentrum' richteg ass.\\nB: Et hänkt vum Dialektgebiet of.\\nA: Ok, ech kontrolléieren d'Metadata.\\nB: Gutt, d'Labels mussen konsistent sinn.\",\n",
    "        \"reference_summary_en\": \"They will verify the metadata because dialect labels must be consistent.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_022\",\n",
    "        \"dialogue\": \"A: D'Audio ass ze laang.\\nB: Wéi laang?\\nA: 25 Sekonnen.\\nB: Dann schneiden mir et op 10 Sekonnen fir d'Training.\",\n",
    "        \"reference_summary_en\": \"The audio is 25 seconds long, so they will trim it to 10 seconds for training.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_023\",\n",
    "        \"dialogue\": \"A: Ech hu keng Internet um Laptop.\\nB: Probéier d'WLAN nei.\\nA: Ok, ech maachen restart.\\nB: Wann et net geet, huele mir en Hotspot.\",\n",
    "        \"reference_summary_en\": \"A has no internet, B suggests restarting Wi-Fi, and they may use a hotspot if needed.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_024\",\n",
    "        \"dialogue\": \"A: D'Zesummefaassung ass ze laang.\\nB: Setz eng Limit.\\nA: Wéi vill?\\nB: Probéier 2 Sätz an maximal 60 Wierder.\",\n",
    "        \"reference_summary_en\": \"They will constrain the summary length to two sentences and at most 60 words.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"lux_025\",\n",
    "        \"dialogue\": \"A: Ech wëll eng neutral Zesummefaassung.\\nB: Da schreiwe mir am Prompt: 'neutral, factual, no opinion'.\\nA: Ok, ech testen dat.\\nB: Gutt, a kuck ob Bias kënnt.\",\n",
    "        \"reference_summary_en\": \"They want a neutral factual summary and will encode that in the prompt and then test for bias.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "def sample_and_summarize(dialogue_set, k=1, seed=7, prompt=ZERO_SHOT_PROMPT):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    items = random.sample(dialogue_set, k=k)\n",
    "    for ex in items:\n",
    "        print(\"ID:\", ex[\"id\"])\n",
    "        print(\"\\nDIALOGUE:\\n\", ex[\"dialogue\"])\n",
    "        pred = generate_summary_t5(ex[\"dialogue\"], prompt=prompt, max_new_tokens=80, temperature=0.0)\n",
    "        print(\"\\nMODEL SUMMARY:\\n\", pred)\n",
    "        print(\"\\nREFERENCE (EN):\\n\", ex[\"reference_summary_en\"])\n",
    "        print(\"\\n\" + \"-\"*70 + \"\\n\")\n",
    "\n",
    "sample_and_summarize(mini_lux, k=2)\n",
    "\n",
    "# Option 2. Pull a tiny real low-resource sample from Hugging Face\n",
    "# This uses XL-Sum (multilingual news summarization). Not a dialogue dataset.\n",
    "# For the workshop, we convert each article into a \"pseudo-dialogue\" so we can reuse the same pipeline.\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "def article_to_pseudo_dialogue(article_text: str, max_turns: int = 6) -> str:\n",
    "    # Lightweight sentence split. Good enough for teaching.\n",
    "    sentences = [s.strip() for s in article_text.replace(\"\\n\", \" \").split(\".\") if s.strip()]\n",
    "    sentences = sentences[:max_turns]\n",
    "    turns = []\n",
    "    for i, s in enumerate(sentences):\n",
    "        speaker = \"ANCHOR\" if i % 2 == 0 else \"REPORTER\"\n",
    "        turns.append(f\"{speaker}: {s}.\")\n",
    "    return \"\\n\".join(turns)\n",
    "\n",
    "def load_low_resource_hf_sample(language_subset: str = \"yoruba\", n: int = 20):\n",
    "    ds = load_dataset(\"csebuetnlp/xlsum\", language_subset, split=f\"train[:{n}]\")\n",
    "    # XL-Sum fields are typically: \"text\" and \"summary\"\n",
    "    out = []\n",
    "    for i, ex in enumerate(ds):\n",
    "        dialogue = article_to_pseudo_dialogue(ex[\"text\"], max_turns=8)\n",
    "        out.append(\n",
    "            {\n",
    "                \"id\": f\"xlsum_{language_subset}_{i:03d}\",\n",
    "                \"dialogue\": dialogue,\n",
    "                \"reference_summary\": ex[\"summary\"],\n",
    "            }\n",
    "        )\n",
    "    return out\n",
    "\n",
    "xlsum_yoruba = load_low_resource_hf_sample(language_subset=\"yoruba\", n=5)\n",
    "print(\"Example pseudo-dialogue from XL-Sum (yoruba subset):\")\n",
    "print(xlsum_yoruba[0][\"dialogue\"])\n",
    "print(\"\\nReference summary (yoruba):\")\n",
    "print(xlsum_yoruba[0][\"reference_summary\"])\n",
    "\n",
    "print(\"\\nNow run the same English prompt on the pseudo-dialogue. It will usually struggle, and that is the point.\")\n",
    "pred = generate_summary_t5(xlsum_yoruba[0][\"dialogue\"], prompt=ZERO_SHOT_PROMPT, max_new_tokens=80, temperature=0.0)\n",
    "print(\"\\nMODEL SUMMARY:\\n\", pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94d5ff6",
   "metadata": {},
   "source": [
    "## 7. Challenge. Adapt to your own low resource language\n",
    "\n",
    "Now you have an English pipeline. The next step is to replace the English dialogue with data from your target language.\n",
    "\n",
    "If you work on a language with limited resources, use the same structure.\n",
    "1) Create turns with speaker labels.\n",
    "2) Normalize and segment.\n",
    "3) Start with an extractive baseline.\n",
    "4) Add a multilingual model or a translation pivot only if you need it.\n",
    "5) Evaluate with a small set of human references.\n",
    "\n",
    "The next cell includes a ready to use template. It runs as is. Replace `MY_DIALOGUE` with your own data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0897db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DIALOGUE = \"\"\"SPEAKER1: Replace this with your own dialogue in any language.\n",
    "SPEAKER2: Keep speaker labels. Keep short lines if possible.\n",
    "SPEAKER1: Then rerun the cells below.\"\"\"\n",
    "\n",
    "clean = normalize_dialogue(MY_DIALOGUE)\n",
    "summary_baseline = turn_level_summarize(clean, max_turns=3)\n",
    "print(\"Baseline summary:\\n\", summary_baseline)\n",
    "\n",
    "if tokenizer is not None and model is not None:\n",
    "    prompt = build_prompt(style=\"neutral\", focus=\"actions\", max_sentences=2)\n",
    "    summary_llm = generate_summary_t5(clean, prompt, max_new_tokens=80, temperature=0.0)\n",
    "    print(\"\\nLLM summary:\\n\", summary_llm)\n",
    "else:\n",
    "    print(\"\\nLLM not available. Baseline is your default.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f06d1",
   "metadata": {},
   "source": [
    "## 8. Wrap up\n",
    "\n",
    "You now have a reproducible dialogue summarization pipeline that is usable with.\n",
    "- No LLM, via TextRank and turn level extraction.\n",
    "- A small instruction model, via prompt engineering.\n",
    "- Low resource conditions, via normalization and constraints.\n",
    "\n",
    "If you want to push further for true low resource languages.\n",
    "- Swap English stopwords for a custom list, or disable stopwords.\n",
    "- Use character n gram TF IDF for languages without whitespace.\n",
    "- Add a small glossary and a retrieval step, then feed only the relevant turns to the model.\n",
    "- Build a tiny evaluation set, 50 to 200 dialogues with one reference summary each.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
