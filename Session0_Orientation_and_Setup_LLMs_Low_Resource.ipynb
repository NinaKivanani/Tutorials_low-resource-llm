{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be60dbd3",
   "metadata": {},
   "source": [
    "# Session 0: Welcome to the LLM Adventure! ğŸš€\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "**ğŸ“š Course Repository:** [github.com/NinaKivanani/Tutorials_low-resource-llm](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NinaKivanani/Tutorials_low-resource-llm/blob/main/Session0_Orientation_and_Setup_LLMs_Low_Resource.ipynb)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-View%20Repository-blue?logo=github)](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "[![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](https://opensource.org/licenses/Apache-2.0)\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ® Your Learning Quest Begins Here!\n",
    "\n",
    "**Welcome, Language Champion!** ğŸ‘‹ You're about to embark on a journey that will transform you from an AI curious learner into a **multilingual AI expert**. This isn't just another coding tutorialâ€”it's your mission to democratize AI for the world's 6,900+ languages!\n",
    "\n",
    "### ğŸ† Your 30-Minute Setup Challenge:\n",
    "```\n",
    "ğŸ¯ Mission Checklist:\n",
    "â”œâ”€â”€ ğŸ”§ Power Up Your Environment     [â–¡â–¡â–¡â–¡â–¡] 0%\n",
    "â”œâ”€â”€ ğŸŒ Choose Your Language Quest    [â–¡â–¡â–¡â–¡â–¡] 0%  \n",
    "â”œâ”€â”€ ğŸ“Š Build Your Evaluation Toolkit [â–¡â–¡â–¡â–¡â–¡] 0%\n",
    "â”œâ”€â”€ ğŸ¤– Test with Real AI Models      [â–¡â–¡â–¡â–¡â–¡] 0%\n",
    "â””â”€â”€ ğŸš€ Ready for Session 1!         [â–¡â–¡â–¡â–¡â–¡] 0%\n",
    "```\n",
    "\n",
    "**â±ï¸ Total time:** 30-45 minutes of pure setup magic!  \n",
    "**ğŸ¯ Difficulty:** Beginner-friendly with expert insights\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒŸ The Big Picture: Why Your Mission Matters\n",
    "\n",
    "**ğŸš¨ The Problem:** Right now, AI works amazingly for English, okay for ~10 major languages, and poorly (or not at all) for 6,800+ other languages. This isn't just a technical issueâ€”it's creating a **digital divide** that leaves billions of people behind.\n",
    "\n",
    "**ğŸ¦¸â€â™€ï¸ Your Superpower:** After this course, you'll be able to:\n",
    "- ğŸ” **Diagnose** why AI fails for specific languages\n",
    "- ğŸ› ï¸ **Fix** models to work better with limited resources  \n",
    "- âš–ï¸ **Audit** systems for fairness and cultural sensitivity\n",
    "- ğŸŒ **Bridge** the gap between cutting-edge AI and real-world diversity\n",
    "\n",
    "**ğŸ’¡ Plot Twist:** You don't need to be a programming wizard! We'll teach you everything step-by-step, with plenty of visual explanations and hands-on practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474afb1",
   "metadata": {},
   "source": [
    "## ğŸ—ºï¸ Your Epic Learning Adventure: 4 Sessions, 4 Superpowers\n",
    "\n",
    "### ğŸ® Course Game Plan\n",
    "```\n",
    "ğŸ° Building Your Multilingual AI Castle:\n",
    "\n",
    "Session 0: ğŸ—ï¸  Foundation (Setup & Orientation)     â† YOU ARE HERE\n",
    "Session 1: ğŸ” Detective Work (Dialogue + Analysis)   â† Solve language mysteries  \n",
    "Session 2: ğŸ¯ Prompt Mastery (Teaching AI)          â† Become an AI whisperer\n",
    "Session 3: âš™ï¸  Custom Building (Fine-tuning)        â† Craft personalized models\n",
    "Session 4: âš–ï¸  Guardian Mode (Bias & Ethics)        â† Protect communities\n",
    "```\n",
    "\n",
    "### ğŸ¯ What Each Session Unlocks:\n",
    "\n",
    "**ğŸ” Session 1: Language Detective** *(2-3 hours)*\n",
    "- **Mission:** Investigate how AI \"sees\" different languages through dialogue summarization\n",
    "- **Skills:** Tokenization analysis, TextRank algorithms, systematic evaluation\n",
    "- **Boss Fight:** Handle noisy, corrupted text like a pro\n",
    "- **Reward:** Robust baseline system that works everywhere\n",
    "\n",
    "**ğŸ¯ Session 2: AI Whisperer** *(2 hours)*  \n",
    "- **Mission:** Master the art of talking to AI in any language\n",
    "- **Skills:** Prompt engineering, zero-shot learning, cross-lingual strategies\n",
    "- **Boss Fight:** Make English-trained models work in your language\n",
    "- **Reward:** Personal prompt library and advanced techniques\n",
    "\n",
    "**âš™ï¸ Session 3: Model Architect** *(2 hours)*\n",
    "- **Mission:** Customize AI models for your specific language needs\n",
    "- **Skills:** Fine-tuning, parameter efficiency, domain adaptation\n",
    "- **Boss Fight:** Achieve better performance with limited data\n",
    "- **Reward:** Your own fine-tuned model\n",
    "\n",
    "**âš–ï¸ Session 4: AI Guardian** *(2 hours)*\n",
    "- **Mission:** Ensure AI systems are fair and culturally appropriate\n",
    "- **Skills:** Bias detection, fairness metrics, ethical evaluation\n",
    "- **Boss Fight:** Identify and fix hidden biases\n",
    "- **Reward:** Comprehensive bias audit framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37863517",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Your Course Arsenal: GitHub Repository\n",
    "\n",
    "**ğŸ¯ Quick Access:** [github.com/NinaKivanani/Tutorials_low-resource-llm](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "\n",
    "### ğŸ® What's in Your Toolkit?\n",
    "```\n",
    "ğŸ° Your AI Castle Blueprint:\n",
    "â”œâ”€â”€ ğŸ—ï¸  Session 0: This orientation guide\n",
    "â”œâ”€â”€ ğŸ” Session 1: Dialogue detective work  \n",
    "â”œâ”€â”€ ğŸ¯ Session 2: Prompt mastery training\n",
    "â”œâ”€â”€ âš™ï¸  Session 3: Model customization lab\n",
    "â”œâ”€â”€ âš–ï¸  Session 4: Bias audit framework\n",
    "â”œâ”€â”€ ğŸ“Š data/: Practice datasets\n",
    "â””â”€â”€ ğŸ¯ examples/: Working solutions\n",
    "```\n",
    "\n",
    "### ğŸš€ Access Methods:\n",
    "- **ğŸ¥‡ Colab:** Click \"Open in Colab\" badges (easiest!)\n",
    "- **ğŸ’» Local:** `git clone` or download ZIP\n",
    "- **ğŸ“± Mobile:** View on GitHub mobile app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9082f776",
   "metadata": {},
   "source": [
    "## ğŸ¯ Quick Start Checklist\n",
    "\n",
    "### âœ… Your Pre-Mission Briefing:\n",
    "\n",
    "**ğŸ”§ Platform Ready?**\n",
    "- [ ] Colab account OR local Jupyter setup\n",
    "- [ ] Can create and run a simple notebook\n",
    "- [ ] GPU access (optional but helpful)\n",
    "\n",
    "**ğŸŒ Language Mission Selected?**\n",
    "- [ ] Pick your target language (Luxembourgish, Irish, Welsh, etc.)\n",
    "- [ ] Gather 5-10 sample sentences (6-20 words each)\n",
    "- [ ] Ensure text is publicly shareable (no personal data!)\n",
    "\n",
    "**ğŸ”‘ Optional Power-Ups:**\n",
    "- [ ] [Hugging Face account](https://huggingface.co) (free model access)\n",
    "- [ ] [GitHub account](https://github.com) (save your work)\n",
    "\n",
    "### ğŸš¨ Ready Check:\n",
    "If you checked all the boxes above, you're ready to begin! If not, don't worryâ€”we'll help you get set up as we go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95cf03",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ® Notebook Survival Guide\n",
    "\n",
    "### ğŸ”„ Essential Habits (Save Yourself Hours of Debugging!)\n",
    "- **Run cells top-to-bottom** when starting fresh\n",
    "- **Restart runtime if weird errors appear** (Runtime â†’ Restart runtime)\n",
    "- **Save frequently** (Ctrl+S / Cmd+S)\n",
    "- **Keep outputs** - they're useful for comparison!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040d5fe",
   "metadata": {},
   "source": [
    "## ğŸ”§ Mission 2: Power Up Your Environment! âš¡\n",
    "\n",
    "Time to transform your computer into a multilingual AI powerhouse! Choose your platform and let's get started:\n",
    "\n",
    "### ğŸ¯ Platform Selection (Pick Your Fighter!)\n",
    "\n",
    "```\n",
    "ğŸ¥‡ Google Colab (Recommended)\n",
    "   â”œâ”€â”€ âœ… Zero setup required\n",
    "   â”œâ”€â”€ âœ… Free GPU power\n",
    "   â”œâ”€â”€ âœ… Works everywhere\n",
    "   â””â”€â”€ ğŸ® Click \"Open in Colab\" above!\n",
    "\n",
    "ğŸ¥ˆ Local Jupyter  \n",
    "   â”œâ”€â”€ âœ… Full control\n",
    "   â”œâ”€â”€ âœ… Works offline\n",
    "   â”œâ”€â”€ âš ï¸  Requires Python 3.8+\n",
    "   â””â”€â”€ ğŸ® Install packages below\n",
    "\n",
    "ğŸ¥‰ Other Platforms\n",
    "   â”œâ”€â”€ Kaggle Notebooks\n",
    "   â”œâ”€â”€ Azure ML Studio  \n",
    "   â””â”€â”€ Any Jupyter environment\n",
    "```\n",
    "\n",
    "### ğŸš€ Installation Magic Spell\n",
    "\n",
    "Ready to cast the installation spell? Run the next cell and watch the magic happen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14e214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15395.43s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires requests==2.31.0, but you have requests 2.32.5 which is incompatible.\n",
      "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m15466.45s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ğŸš€ Mission 2: Install Your AI Superpowers!\n",
    "\n",
    "print(\"ğŸ® LOADING AI SUPERPOWERS...\")\n",
    "print(\"=\" * 50)\n",
    "print(\"â±ï¸  ETA: 2-3 minutes (perfect for a coffee break!)\")\n",
    "print(\"ğŸ¯ Installing your multilingual AI toolkit...\")\n",
    "print()\n",
    "\n",
    "# Core AI libraries for language processing\n",
    "print(\"ğŸ¤– Installing AI brain modules...\")\n",
    "!pip -q install transformers datasets sentencepiece tokenizers accelerate\n",
    "\n",
    "# Additional tools for analysis and visualization  \n",
    "print(\"ğŸ“Š Installing analysis tools...\")\n",
    "!pip -q install sentence-transformers scikit-learn\n",
    "\n",
    "print()\n",
    "print(\"ğŸ‰ SUPERPOWERS ACTIVATED!\")\n",
    "print(\"=\" * 50)\n",
    "print(\"âœ… Your AI toolkit is ready!\")\n",
    "print(\"ğŸ’¡ Those dependency warnings? Totally normal in Colab!\")\n",
    "print(\"ğŸš€ Let's test everything in the next cell...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba6e81d",
   "metadata": {},
   "source": [
    "## ğŸ” Mission 3: System Diagnostics & Power Check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1bdc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“… Setup Check Report\n",
      "========================================\n",
      "ğŸ“… Date: 2026-01-12 11:01 UTC\n",
      "ğŸ Python: 3.11.5\n",
      "ğŸ’» Platform: macOS-15.3-arm64-arm-64bit\n",
      "\n",
      "ğŸ“š Library Versions:\n",
      "  âœ… ğŸ¤— Transformers: 4.57.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nina.hosseinikivanan/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… ğŸ“Š Datasets: 4.4.2\n",
      "  âœ… ğŸ”¤ Sentence Transformers: 5.2.0\n",
      "  âœ… ğŸ”¥ PyTorch: 2.9.1\n",
      "  âœ… ğŸ§  Scikit-learn: 1.8.0\n",
      "  âœ… ğŸ“ˆ Matplotlib: 3.10.8\n",
      "  âœ… ğŸ¼ Pandas: 2.3.3\n",
      "  âœ… ğŸ”¢ NumPy: 1.26.4\n",
      "\n",
      "ğŸ’¡ All libraries should show âœ… - if you see âŒ, re-run the installation cell above!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Mission 3: System Diagnostics & Power Check!\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "\n",
    "def get_package_version(name: str) -> str:\n",
    "    \"\"\"Get version of an installed package\"\"\"\n",
    "    try:\n",
    "        return importlib.import_module(name).__version__\n",
    "    except Exception:\n",
    "        return \"âŒ not available\"\n",
    "\n",
    "print(\"ğŸ® SYSTEM DIAGNOSTICS REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ“… Mission Date: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\")\n",
    "print(f\"ğŸ Python: {sys.version.split()[0]}\")\n",
    "print(f\"ğŸ’» Platform: {platform.platform()}\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“š Library Versions:\")\n",
    "libraries = [\n",
    "    (\"transformers\", \"ğŸ¤— Transformers\"),\n",
    "    (\"datasets\", \"ğŸ“Š Datasets\"), \n",
    "    (\"sentence_transformers\", \"ğŸ”¤ Sentence Transformers\"),\n",
    "    (\"torch\", \"ğŸ”¥ PyTorch\"),\n",
    "    (\"sklearn\", \"ğŸ§  Scikit-learn\"),\n",
    "    (\"matplotlib\", \"ğŸ“ˆ Matplotlib\"),\n",
    "    (\"pandas\", \"ğŸ¼ Pandas\"),\n",
    "    (\"numpy\", \"ğŸ”¢ NumPy\")\n",
    "]\n",
    "\n",
    "for pkg_name, display_name in libraries:\n",
    "    version = get_package_version(pkg_name)\n",
    "    status = \"âœ…\" if \"not available\" not in version else \"âŒ\"\n",
    "    print(f\"  {status} {display_name}: {version}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ All libraries should show âœ… - if you see âŒ, re-run the installation cell above!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ–¥ï¸ Hardware Check - Let's see what computing power you have!\n",
    "print(\"\\nğŸ–¥ï¸ Hardware Information:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    # Check for GPU availability\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    \n",
    "    if gpu_available:\n",
    "        print(\"ğŸš€ GPU Status: âœ… Available!\")\n",
    "        print(f\"   ğŸ® GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   âš¡ CUDA Version: {torch.version.cuda}\")\n",
    "        print(\"   ğŸ’¡ Great! You can run larger models faster\")\n",
    "    else:\n",
    "        print(\"ğŸ–¥ï¸  GPU Status: âŒ Not available (using CPU)\")\n",
    "        print(\"   ğŸ’¡ No worries! CPU works fine for this course\")\n",
    "        print(\"   ğŸ”§ To get GPU in Colab: Runtime â†’ Change runtime type â†’ GPU\")\n",
    "    \n",
    "    print(f\"\\nğŸ§  PyTorch Backend: {torch.version.__version__}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Hardware check failed: {e}\")\n",
    "    print(\"ğŸ’¡ This might be okay - try continuing with the course\")\n",
    "\n",
    "print(\"\\nğŸ‰ Setup check complete! You're ready to start learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab568db",
   "metadata": {},
   "source": [
    "## ğŸŒ Mission 4: Choose Your Language Quest!\n",
    "\n",
    "Time to pick your linguistic adventure! You'll select a language and create test sentences that will be your companions throughout all sessions.\n",
    "\n",
    "### ğŸ¯ Language Selection Strategy:\n",
    "```\n",
    "ğŸ† Perfect Test Languages:\n",
    "â”œâ”€â”€ ğŸ‡±ğŸ‡º Luxembourgish (~600K speakers)\n",
    "â”œâ”€â”€ ğŸ‡®ğŸ‡ª Irish (~1.7M speakers)  \n",
    "â”œâ”€â”€ ğŸ‡²ğŸ‡¹ Maltese (~500K speakers)\n",
    "â”œâ”€â”€ ğŸ‡®ğŸ‡¸ Icelandic (~350K speakers)\n",
    "â”œâ”€â”€ ğŸ´ó §ó ¢ó ·ó ¬ó ³ó ¿ Welsh (~900K speakers)\n",
    "â””â”€â”€ ğŸ‡ªğŸ‡¸ Basque (~750K speakers)\n",
    "```\n",
    "\n",
    "### ğŸ“ Your Test Sentence Mission:\n",
    "Create 5-7 sentences that are:\n",
    "- **ğŸ“ Goldilocks length:** 6-20 words (not too short, not too long)\n",
    "- **ğŸ”’ Public-friendly:** Safe to share with the world\n",
    "- **ğŸ¯ Diverse:** Different types to stress-test AI models\n",
    "- **ğŸ§ª Scientific:** Include numbers, punctuation, borrowed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30058e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Mission 4: Language Selection & Dataset Creation\n",
    "\n",
    "# ğŸŒ Choose your linguistic adventure!\n",
    "TARGET_LANG = \"lb\"  # ğŸ‡±ğŸ‡º Luxembourgish (change to your choice!)\n",
    "\n",
    "print(f\"ğŸ® LANGUAGE QUEST SELECTED: {TARGET_LANG}\")\n",
    "print(\"ğŸ”„ (Edit the cell above to change your language)\")\n",
    "print()\n",
    "\n",
    "# ğŸ“š Your Test Sentence Arsenal\n",
    "# Replace these with your own sentences in your chosen language!\n",
    "mini_texts = {\n",
    "    \"en\": [\n",
    "        \"I enjoy learning how language models process text.\",\n",
    "        \"This sentence includes a number: 2026, and a comma.\",\n",
    "        \"Short prompts can still produce complex outputs.\",\n",
    "        \"Tokenization choices can change meaning and cost.\",\n",
    "        \"We will evaluate correctness, fluency, and safety.\"\n",
    "    ],\n",
    "    \"lb\": [  # Luxembourgish examples\n",
    "        \"Ech hunn Loscht ze verstoen, wÃ©i Sproochmodeller Text verschaffen.\",\n",
    "        \"DÃ«se Saz enthÃ¤lt eng Zuel: 2026, an eng Komma.\",\n",
    "        \"Kuerz Prompte kÃ«nnen trotzdeem komplex Ã„ntwerte produzÃ©ieren.\",\n",
    "        \"TokenisÃ©ierung kann Bedeitung an KÃ¤schte beaflossen.\",\n",
    "        \"Mir evaluÃ©ieren Richtegkeet, FlÃ«ssegkeet an SÃ©cherheet.\"\n",
    "    ],\n",
    "    \"ga\": [  # Irish examples\n",
    "        \"Is maith liom foghlaim conas a phrÃ³iseÃ¡lann samhlacha teanga tÃ©acs.\",\n",
    "        \"TÃ¡ uimhir sa abairt seo: 2026, agus camÃ³g.\",\n",
    "        \"Is fÃ©idir le leid ghearr aschuir chasta a thÃ¡irgeadh fÃ³s.\",\n",
    "        \"Is fÃ©idir le roghanna tocainithe brÃ­ agus costas a athrÃº.\",\n",
    "        \"DÃ©anaimid measÃºnÃº ar chruinneas, lÃ­ofacht agus sÃ¡bhÃ¡ilteacht.\"\n",
    "    ],\n",
    "    \"mt\": [  # Maltese examples  \n",
    "        \"JogÄ§obni nitgÄ§allem kif il-mudelli tal-lingwa jipproÄ‹essaw it-test.\",\n",
    "        \"Din is-sentenza tinkludi numru: 2026, u virgola.\",\n",
    "        \"Prompts qosra xorta jistgÄ§u jipproduÄ‹u outputs kumplessi.\",\n",
    "        \"L-gÄ§aÅ¼liet tat-tokenization jistgÄ§u jbiddlu t-tifsira u l-ispejjeÅ¼.\",\n",
    "        \"AÄ§na nevalwaw it-tÄ§assib, il-fluwenza u s-sigurtÃ .\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ğŸ”§ Add your language if it's not in the examples above\n",
    "if TARGET_LANG not in mini_texts:\n",
    "    print(f\"\\nğŸ“ {TARGET_LANG} not in examples - please add your sentences below!\")\n",
    "    mini_texts[TARGET_LANG] = [\n",
    "        \"Add your first sentence here (6-20 words).\",\n",
    "        \"Add your second sentence with a number: 2026.\",\n",
    "        \"Add your third sentence here.\",\n",
    "        \"Add your fourth sentence here.\",\n",
    "        \"Add your fifth sentence here.\"\n",
    "    ]\n",
    "    print(\"ğŸ’¡ Edit the list above to add your own sentences!\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Found example sentences for {TARGET_LANG}!\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Your current dataset:\")\n",
    "print(f\"ğŸŒ Language: {TARGET_LANG}\")\n",
    "print(f\"ğŸ“Š Number of sentences: {len(mini_texts[TARGET_LANG])}\")\n",
    "print(f\"ğŸ“ Example: '{mini_texts[TARGET_LANG][0]}'\")\n",
    "\n",
    "print(f\"\\nğŸ” All your {TARGET_LANG} sentences:\")\n",
    "for i, sentence in enumerate(mini_texts[TARGET_LANG], 1):\n",
    "    print(f\"  {i}. {sentence}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Remember: You can edit these sentences anytime by modifying the cell above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e21639",
   "metadata": {},
   "source": [
    "## ğŸ“Š Mission 5: Build Your Evaluation Toolkit\n",
    "\n",
    "Time to create your secret weapon for systematic AI evaluation! This is crucial for low-resource languages where standard benchmarks don't exist.\n",
    "\n",
    "### ğŸ¯ Your Evaluation Framework (0-2 Scale):\n",
    "```\n",
    "âœ… Correctness: Does it solve the task?\n",
    "ğŸ—£ï¸ Fluency: Does it sound natural?  \n",
    "ğŸŒ Cultural: Does it respect norms?\n",
    "ğŸ›¡ï¸ Safety: Does it avoid harm?\n",
    "ğŸ“ Notes: Your observations\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc27f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Create your personalized evaluation sheet\n",
    "import pandas as pd\n",
    "\n",
    "def create_evaluation_sheet(texts: dict, target_lang: str) -> pd.DataFrame:\n",
    "    \"\"\"Create a structured evaluation sheet for tracking model outputs\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    # Add English sentences for comparison\n",
    "    for i, sentence in enumerate(texts.get(\"en\", []), start=1):\n",
    "        rows.append({\n",
    "            \"item_id\": f\"en_{i}\",\n",
    "            \"language\": \"en\",\n",
    "            \"input_text\": sentence,\n",
    "            \"task\": \"\",  # Will be filled during sessions\n",
    "            \"model\": \"\",  # Will be filled during sessions\n",
    "            \"prompt_style\": \"\",  # Will be filled during sessions\n",
    "            \"output_text\": \"\",  # Will be filled during sessions\n",
    "            \"correctness_0to2\": \"\",  # Your rating 0-2\n",
    "            \"fluency_0to2\": \"\",  # Your rating 0-2\n",
    "            \"cultural_0to2\": \"\",  # Your rating 0-2\n",
    "            \"safety_0to2\": \"\",  # Your rating 0-2\n",
    "            \"notes\": \"\"  # Your observations\n",
    "        })\n",
    "    \n",
    "    # Add your target language sentences\n",
    "    for i, sentence in enumerate(texts.get(target_lang, []), start=1):\n",
    "        rows.append({\n",
    "            \"item_id\": f\"{target_lang}_{i}\",\n",
    "            \"language\": target_lang,\n",
    "            \"input_text\": sentence,\n",
    "            \"task\": \"\",\n",
    "            \"model\": \"\",\n",
    "            \"prompt_style\": \"\",\n",
    "            \"output_text\": \"\",\n",
    "            \"correctness_0to2\": \"\",\n",
    "            \"fluency_0to2\": \"\",\n",
    "            \"cultural_0to2\": \"\",\n",
    "            \"safety_0to2\": \"\",\n",
    "            \"notes\": \"\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Create your evaluation sheet\n",
    "eval_df = create_evaluation_sheet(mini_texts, TARGET_LANG)\n",
    "\n",
    "print(f\"ğŸ“‹ Created evaluation sheet with {len(eval_df)} rows\")\n",
    "print(f\"ğŸŒ Languages: English + {TARGET_LANG}\")\n",
    "print(f\"ğŸ“Š Sentences per language: {len(mini_texts['en'])}\")\n",
    "\n",
    "print(\"\\nğŸ‘€ Preview of your evaluation sheet:\")\n",
    "print(\"=\" * 60)\n",
    "display(eval_df.head(8))\n",
    "\n",
    "print(\"\\nğŸ’¡ This sheet will be your companion throughout all sessions!\")\n",
    "print(\"ğŸ“ You'll fill in the empty columns as you test different models and prompts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4510b9f2",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Mission 6: Save Your Evaluation Arsenal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¾ Save your evaluation sheet for future sessions\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"session0_outputs\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the evaluation sheet\n",
    "filename = f\"evaluation_sheet_{TARGET_LANG}.csv\"\n",
    "file_path = output_dir / filename\n",
    "\n",
    "eval_df.to_csv(file_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"âœ… Evaluation sheet saved successfully!\")\n",
    "print(f\"ğŸ“ Location: {file_path}\")\n",
    "print(f\"ğŸ“Š Contains: {len(eval_df)} evaluation rows\")\n",
    "\n",
    "# Show how to download in different environments\n",
    "print(\"\\nğŸ“¥ How to access your file:\")\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"ğŸ”— In Colab: Check the Files panel on the left â†’ session0_outputs folder\")\n",
    "    print(\"ğŸ’¾ To download: Right-click the file â†’ Download\")\n",
    "else:\n",
    "    print(f\"ğŸ“‚ Local file saved at: {os.path.abspath(file_path)}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Keep this file safe! You'll use it in all upcoming sessions.\")\n",
    "print(\"ğŸ“ Pro tip: Make a backup copy before each session!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f40f0f",
   "metadata": {},
   "source": [
    "## âœ… Mission 7: Final Boss Fight - Multilingual Model Test!\n",
    "\n",
    "Time for the ultimate test! Let's confirm everything works by running a real multilingual AI model on your sentences.\n",
    "\n",
    "### ğŸ¯ Your Final Challenge:\n",
    "```\n",
    "ğŸ¤– Load multilingual AI model\n",
    "ğŸ“Š Generate sentence embeddings  \n",
    "ğŸ“ˆ Visualize language clustering\n",
    "ğŸ‰ Confirm readiness for Session 1!\n",
    "```\n",
    "\n",
    "**âš ï¸ Network issues? Skip this test and proceed - you're still ready for Session 1!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤– Load and test a multilingual model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# ğŸ”„ Loading a state-of-the-art multilingual model\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "print(\"ğŸ”„ Loading multilingual model...\")\n",
    "print(f\"ğŸ“¦ Model: {MODEL_NAME}\")\n",
    "print(\"â±ï¸ This might take 1-2 minutes the first time (downloading ~420MB)\")\n",
    "\n",
    "try:\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "    print(\"âœ… Model loaded successfully!\")\n",
    "    \n",
    "    # ğŸ“ Prepare your sentences for testing\n",
    "    test_texts = []\n",
    "    test_labels = []\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Preparing sentences for embedding:\")\n",
    "    for lang in [\"en\", TARGET_LANG]:\n",
    "        if lang in mini_texts:\n",
    "            for sentence in mini_texts[lang]:\n",
    "                test_texts.append(sentence)\n",
    "                test_labels.append(lang)\n",
    "                print(f\"  ğŸ“ {lang}: {sentence[:50]}{'...' if len(sentence) > 50 else ''}\")\n",
    "    \n",
    "    # ğŸ§  Generate embeddings (numerical representations)\n",
    "    print(f\"\\nğŸ§  Generating embeddings for {len(test_texts)} sentences...\")\n",
    "    embeddings = model.encode(test_texts, normalize_embeddings=True)\n",
    "    \n",
    "    print(f\"âœ… Success! Generated embeddings:\")\n",
    "    print(f\"   ğŸ“Š Shape: {embeddings.shape}\")\n",
    "    print(f\"   ğŸ”¢ Each sentence â†’ {embeddings.shape[1]} numbers\")\n",
    "    print(f\"   ğŸŒ Languages: {len(set(test_labels))}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Model loading failed: {e}\")\n",
    "    print(\"ğŸ’¡ This might be due to network issues - you can continue with the course\")\n",
    "    print(\"ğŸ”§ Try: Runtime â†’ Restart Runtime, then re-run from the top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ˆ Create a visualization to see how the model groups languages\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'embeddings' in locals():\n",
    "    print(\"ğŸ“ˆ Creating visualization...\")\n",
    "    \n",
    "    # Use PCA to reduce high-dimensional embeddings to 2D for plotting\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    embeddings_2d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Plot each language with different colors\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    unique_languages = sorted(set(test_labels))\n",
    "    \n",
    "    for i, lang in enumerate(unique_languages):\n",
    "        # Find all sentences in this language\n",
    "        lang_indices = [j for j, label in enumerate(test_labels) if label == lang]\n",
    "        \n",
    "        # Plot them with the same color\n",
    "        plt.scatter(embeddings_2d[lang_indices, 0], \n",
    "                   embeddings_2d[lang_indices, 1], \n",
    "                   label=f'{lang} ({len(lang_indices)} sentences)',\n",
    "                   color=colors[i % len(colors)],\n",
    "                   s=100, alpha=0.7)\n",
    "    \n",
    "    plt.title(f'ğŸŒ How the Model \"Sees\" Your Languages\\n(Each dot = one sentence)', fontsize=14)\n",
    "    plt.xlabel('ğŸ“Š Principal Component 1', fontsize=12)\n",
    "    plt.ylabel('ğŸ“Š Principal Component 2', fontsize=12)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add some explanation\n",
    "    plt.figtext(0.5, 0.02, \n",
    "                'ğŸ’¡ Closer dots = more similar according to the model | Different colors = different languages',\n",
    "                ha='center', fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ğŸ‰ Visualization complete!\")\n",
    "    print(\"ğŸ” What to look for:\")\n",
    "    print(\"  â€¢ Do sentences from the same language cluster together?\")\n",
    "    print(\"  â€¢ Are equivalent sentences (same meaning) close to each other?\")\n",
    "    print(\"  â€¢ Any surprising patterns or outliers?\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Skipping visualization - model loading failed above\")\n",
    "    print(\"ğŸ’¡ This is okay - you can still continue with the course!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f8981",
   "metadata": {},
   "source": [
    "## ğŸ†˜ Quick Troubleshooting\n",
    "\n",
    "**ğŸ”§ Common Issues:**\n",
    "- **Install errors:** Restart runtime, then reinstall\n",
    "- **Model download fails:** Network issue - try different connection\n",
    "- **Out of memory:** Switch to CPU runtime\n",
    "- **Unicode problems:** Save files as UTF-8\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee37ce",
   "metadata": {},
   "source": [
    "## ğŸ¯ Mission Complete! What's Next?\n",
    "\n",
    "### âœ… Pre-Session 1 Checklist:\n",
    "- [ ] Replace example sentences with your own (include numbers & punctuation)\n",
    "- [ ] Save updated evaluation sheet\n",
    "- [ ] Write 2 hypotheses about potential language-specific issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf43678",
   "metadata": {},
   "source": [
    "### ğŸ¤” Optional Reflection:\n",
    "1. What parts of your language are underrepresented in web data?\n",
    "2. Where might prompt-following fail first for your language?\n",
    "3. What would success look like for you in this course?\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‰ Congratulations, Language Champion!\n",
    "\n",
    "You've successfully completed Session 0! Your multilingual AI adventure begins with Session 1, where you'll become a **Language Detective** and master dialogue summarization techniques.\n",
    "\n",
    "**ğŸš€ Ready for Session 1?** Open `Session1_dialogue_summarization_low_resource.ipynb` and let the adventure continue!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
