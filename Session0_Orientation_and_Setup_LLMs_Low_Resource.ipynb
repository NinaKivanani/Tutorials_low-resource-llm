{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be60dbd3",
   "metadata": {},
   "source": [
    "# Session 0: Getting Started with LLMs for Low-Resource Languages üåç\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "**üìö Course Repository:** [github.com/NinaKivanani/Tutorials_low-resource-llm](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NinaKivanani/Tutorials_low-resource-llm/blob/main/Session0_Orientation_and_Setup_LLMs_Low_Resource.ipynb)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-View%20Repository-blue?logo=github)](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "[![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](https://opensource.org/licenses/Apache-2.0)\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**Welcome to the course!** üëã I'm excited to guide you through this journey into Large Language Models (LLMs) and low-resource languages. Think of this session as your orientation day‚Äîwe'll get you set up, oriented, and ready to dive into the exciting work ahead!\n",
    "\n",
    "## üéØ Your Mission for Today (5 Simple Steps):\n",
    "\n",
    "By the end of this session, you'll have:\n",
    "\n",
    "1. **üîß A Working Environment** - All tools installed and tested (15 min)\n",
    "2. **üó∫Ô∏è A Clear Roadmap** - Understanding of what's coming in Sessions 1-4 (5 min)\n",
    "3. **üåç Your Language Focus** - A chosen low-resource language and test dataset (10 min)\n",
    "4. **üìù An Evaluation Toolkit** - Your personal assessment framework (10 min)\n",
    "5. **‚úÖ Confidence** - Proof that everything works with a real model test! (10 min)\n",
    "\n",
    "**‚è±Ô∏è Total time:** ~30-45 minutes  \n",
    "**üíª Platform:** Google Colab (recommended), Jupyter Notebook, or local Python  \n",
    "**üéì Your background:** Beginner to Intermediate (I'll explain every concept!)\n",
    "\n",
    "---\n",
    "\n",
    "## üåü Why This Course Matters\n",
    "\n",
    "**Here's a sobering fact:** Most AI research focuses on just ~100 languages, leaving **6,900+ languages** largely ignored. These aren't \"small\" or \"unimportant\" languages‚Äîthey're spoken by millions of people with rich cultural traditions and modern needs.\n",
    "\n",
    "**Your role:** You're learning to be a bridge-builder. After this course, you'll know how to:\n",
    "- Evaluate whether AI models work for *any* language, not just English\n",
    "- Adapt and improve models for languages with limited resources\n",
    "- Identify and address biases that harm minority language speakers\n",
    "- Build ethical, inclusive AI systems\n",
    "\n",
    "**This matters because:** Language is identity, culture, and community. When AI only works well for a few languages, we're creating a technological divide that reinforces inequality.\n",
    "\n",
    "---\n",
    "\n",
    "## üí≠ A Quick Note Before We Start\n",
    "\n",
    "**If you're feeling nervous:** That's completely normal! Many participants come in thinking they need to be \"AI experts\" or \"fluent in programming.\" You don't. We'll explain every concept, every line of code, and every decision.\n",
    "\n",
    "**If something doesn't work:** That's actually valuable! In low-resource language work, things don't always work perfectly‚Äîand learning to troubleshoot is part of the skill. I'll help you through it.\n",
    "\n",
    "**Remember:** Questions are welcome at every step. No question is \"too basic\"‚Äîif you're wondering about it, others probably are too!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474afb1",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è Your Learning Journey: The Complete Roadmap\n",
    "\n",
    "Think of this course as building a house for multilingual AI. Each session adds another essential layer:\n",
    "\n",
    "### **Session 1: üîç How LLMs \"See\" Languages (The Foundation)**\n",
    "\n",
    "**The Big Question:** *Why does ChatGPT work better in English than in my language?*\n",
    "\n",
    "**What you'll learn:**\n",
    "- How language models break text into pieces (tokenization)\n",
    "- Why some languages get \"chopped up\" more than others\n",
    "- The connection between tokenization and model performance\n",
    "\n",
    "**Hands-on Activity:**  \n",
    "Take your chosen language and watch how different models tokenize it. You'll see exactly why some words get split into tiny fragments while others stay whole.\n",
    "\n",
    "**Real-world Impact:**  \n",
    "Understanding tokenization helps you predict which languages will struggle with which models‚Äîand what to do about it.\n",
    "\n",
    "**‚è±Ô∏è Time:** ~90 minutes | **üìä What you'll create:** Tokenization comparison charts\n",
    "\n",
    "---\n",
    "\n",
    "### **Session 2: üí¨ Teaching LLMs New Tasks (The Walls)**\n",
    "\n",
    "**The Big Question:** *How do I get models to follow instructions in my language?*\n",
    "\n",
    "**What you'll learn:**\n",
    "- The art and science of \"prompt engineering\" (giving good instructions)\n",
    "- Why \"Translate this\" works in English but might fail in your language\n",
    "- Cross-lingual prompting strategies (using English hints for better results)\n",
    "\n",
    "**Hands-on Activity:**  \n",
    "Write prompts in your language, test different approaches, and discover what actually works (not what the internet says *should* work).\n",
    "\n",
    "**Real-world Impact:**  \n",
    "Good prompting can make a huge difference‚Äîsometimes turning unusable outputs into production-ready results, all without changing the model.\n",
    "\n",
    "**‚è±Ô∏è Time:** ~90 minutes | **üìä What you'll create:** Your personal prompt library\n",
    "\n",
    "---\n",
    "\n",
    "### **Session 3: üéØ Customizing LLMs for Your Language (The Roof)**\n",
    "\n",
    "**The Big Question:** *When should I customize a model vs. use it out-of-the-box?*\n",
    "\n",
    "**What you'll learn:**\n",
    "- When prompting isn't enough (and what to do instead)\n",
    "- How to fine-tune models with limited data\n",
    "- Cost-benefit analysis of different adaptation strategies\n",
    "\n",
    "**Hands-on Activity:**  \n",
    "Actually fine-tune a small model on your language! You'll see the before/after improvement and learn to spot when this approach is worth it.\n",
    "\n",
    "**Real-world Impact:**  \n",
    "Fine-tuning can dramatically improve performance, but it requires data and resources. You'll learn to make informed decisions about when it's worth the investment.\n",
    "\n",
    "**‚è±Ô∏è Time:** ~90 minutes | **üìä What you'll create:** A customized model for your language\n",
    "\n",
    "---\n",
    "\n",
    "### **Session 4: ‚öñÔ∏è Responsible AI for All Languages (The Safety System)**\n",
    "\n",
    "**The Big Question:** *How do I make sure my AI doesn't cause harm?*\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to test for bias in multilingual models\n",
    "- Cultural appropriateness vs. technical correctness\n",
    "- Building fairness into your evaluation pipeline\n",
    "\n",
    "**Hands-on Activity:**  \n",
    "Run bias audits on real models using your language. You'll discover blind spots and design mitigation strategies.\n",
    "\n",
    "**Real-world Impact:**  \n",
    "AI that works technically but offends culturally is worse than no AI. You'll learn to build systems that respect the communities they serve.\n",
    "\n",
    "**‚è±Ô∏è Time:** ~90 minutes | **üìä What you'll create:** A bias audit framework\n",
    "\n",
    "---\n",
    "\n",
    "## üéì By the End of This Course, You'll Have:\n",
    "\n",
    "**üõ†Ô∏è Practical Skills:**\n",
    "- Ability to evaluate *any* language model for *any* language\n",
    "- Toolkit of strategies for low-resource language challenges\n",
    "- Hands-on experience with state-of-the-art tools (Hugging Face, etc.)\n",
    "\n",
    "**üìä Concrete Artifacts:**\n",
    "- Evaluation sheets comparing models on your language\n",
    "- Prompt libraries that actually work for your use cases\n",
    "- A customized model (or roadmap to build one)\n",
    "- Bias audit reports with actionable recommendations\n",
    "\n",
    "**üß† Strategic Knowledge:**\n",
    "- When to use which approach (prompting vs. fine-tuning vs. something else)\n",
    "- How to work within resource constraints\n",
    "- Red flags to watch for in multilingual AI\n",
    "\n",
    "**üåç Ethical Framework:**\n",
    "- Principles for responsible multilingual AI development\n",
    "- Cultural sensitivity in technology design\n",
    "- Advocacy skills for better language representation\n",
    "\n",
    "**üí° Most importantly:** The confidence to say \"I can evaluate whether this AI works for my language‚Äîand I know how to improve it if it doesn't.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37863517",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Course Materials & GitHub Repository\n",
    "\n",
    "**All course materials are available on GitHub!** This means you can:\n",
    "- üì• Download all notebooks and resources\n",
    "- üîÑ Get updates as we improve materials\n",
    "- üíæ Save your own copy to work on\n",
    "- üåê Access everything even after the course ends\n",
    "\n",
    "### **üîó Your Course Repository:**\n",
    "\n",
    "**GitHub URL:** [https://github.com/NinaKivanani/Tutorials_low-resource-llm](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "\n",
    "### **üì¶ What's in the Repository?**\n",
    "\n",
    "```\n",
    "Tutorials_low-resource-llm/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ Session0_Orientation_and_Setup.ipynb          ‚Üê You are here!\n",
    "‚îú‚îÄ‚îÄ Session1_Tokenization_Embeddings.ipynb        ‚Üê How LLMs \"see\" languages\n",
    "‚îú‚îÄ‚îÄ Session2_Cross_Lingual_Prompting.ipynb        ‚Üê Teaching LLMs new tasks\n",
    "‚îú‚îÄ‚îÄ Session3_Fine_Tuning.ipynb                    ‚Üê Customizing models\n",
    "‚îú‚îÄ‚îÄ Session4_Bias_Audit.ipynb                     ‚Üê Responsible AI\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ data/                                         ‚Üê Sample datasets\n",
    "‚îú‚îÄ‚îÄ examples/                                     ‚Üê Working examples\n",
    "‚îî‚îÄ‚îÄ README.md                                     ‚Üê Course overview\n",
    "```\n",
    "\n",
    "### **üöÄ How to Use the Repository:**\n",
    "\n",
    "**Option 1: Run in Google Colab (Easiest - Recommended for Beginners)**\n",
    "1. Click on any notebook in the GitHub repository\n",
    "2. Look for the \"Open in Colab\" badge at the top\n",
    "3. Click it - the notebook opens in Google Colab\n",
    "4. You're ready to run code! (No installation needed on your computer)\n",
    "\n",
    "**Option 2: Download to Your Computer**\n",
    "1. Go to the GitHub repository\n",
    "2. Click the green \"Code\" button\n",
    "3. Select \"Download ZIP\"\n",
    "4. Extract the files on your computer\n",
    "5. Open with Jupyter Notebook or VS Code\n",
    "\n",
    "**Option 3: Clone with Git (For Advanced Users)**\n",
    "```bash\n",
    "git clone https://github.com/NinaKivanani/Tutorials_low-resource-llm.git\n",
    "cd Tutorials_low-resource-llm\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "### **üí° Pro Tips:**\n",
    "\n",
    "**Staying Updated:**\n",
    "- ‚≠ê **Star the repository** on GitHub to bookmark it\n",
    "- üëÄ **Watch the repository** to get notifications of updates\n",
    "- üîÑ Check back periodically - we add new examples and fix issues!\n",
    "\n",
    "**Getting Help:**\n",
    "- üêõ Found a bug? Open an \"Issue\" on GitHub\n",
    "- üí¨ Have questions? Use the \"Discussions\" tab\n",
    "- ü§ù Want to contribute? Pull requests welcome!\n",
    "\n",
    "**Making it Your Own:**\n",
    "- üç¥ **Fork the repository** to create your own copy\n",
    "- ‚úèÔ∏è Modify notebooks for your specific language/use case\n",
    "- üíæ Your changes are saved to YOUR fork, not the original\n",
    "\n",
    "### **üÜò \"I'm New to GitHub\" - Quick Guide:**\n",
    "\n",
    "**What is GitHub?** Think of it as Google Drive for code. It stores files and tracks changes.\n",
    "\n",
    "**Do I need an account?** \n",
    "- To *view* and *download*: NO ‚úÖ\n",
    "- To *save changes* or *contribute*: YES (free to sign up)\n",
    "\n",
    "**I just want the notebooks!**\n",
    "- Click the GitHub link above\n",
    "- Click on any `.ipynb` file\n",
    "- Click \"Open in Colab\" or \"Download\"\n",
    "- Done! üéâ\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ù Our Learning Agreement\n",
    "\n",
    "Let's establish some important principles for working together:\n",
    "\n",
    "### **üî¨ Scientific Rigor**\n",
    "- **Document everything:** Keep track of which models, prompts, and settings you use\n",
    "- **Reproducible results:** Others should be able to recreate your experiments\n",
    "- **Learn from failures:** When something doesn't work, that's valuable data too!\n",
    "\n",
    "### **üåç Language Respect** \n",
    "- **\"Low-resource\" ‚â† \"low-value\":** These languages represent rich cultures and communities\n",
    "- **Cultural sensitivity:** Respect local conventions, writing systems, and cultural norms\n",
    "- **Avoid linguistic imperialism:** Don't assume English-centric approaches are always best\n",
    "\n",
    "### **üîí Data Safety & Ethics**\n",
    "- **No personal data:** Don't use private messages, medical records, or confidential information\n",
    "- **Public-safe content:** Only use text you're comfortable sharing publicly\n",
    "- **Respect privacy:** When in doubt, create synthetic examples instead\n",
    "\n",
    "### **üìö Growth Mindset**\n",
    "- **Questions welcome:** No question is too basic - ask away!\n",
    "- **Collaborative learning:** Help your peers and learn from them\n",
    "- **Iterate and improve:** Expect to refine your approaches as you learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9082f776",
   "metadata": {},
   "source": [
    "## ‚úÖ Pre-Session Checklist\n",
    "\n",
    "Let's make sure you're ready for the hands-on sessions! Check off each item as you complete it:\n",
    "\n",
    "### **üìö Course Materials Access**\n",
    "- [ ] **Visit the GitHub repository:** [https://github.com/NinaKivanani/Tutorials_low-resource-llm](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "  - *Why?* All course notebooks and materials are here!\n",
    "  - *How?* See the \"Course Materials & GitHub Repository\" section above for detailed instructions\n",
    "- [ ] **Star/bookmark the repository:** So you can find it again easily\n",
    "- [ ] **Download or open in Colab:** Get the notebooks you need for the course\n",
    "\n",
    "### **üíª Platform Setup**\n",
    "- [ ] **Choose your platform:** Google Colab (recommended for beginners) or local Jupyter\n",
    "  - *Colab advantage:* No installation needed, free GPU access\n",
    "  - *Local advantage:* Works offline, more control\n",
    "- [ ] **Test access:** Can you create and run a simple notebook?\n",
    "- [ ] **GPU check:** Do you have access to GPU runtime? (CPU works fine too!)\n",
    "  - *In Colab:* Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "\n",
    "### **üîë Account Setup (Optional but Helpful)**\n",
    "- [ ] **Hugging Face account:** Sign up at [huggingface.co](https://huggingface.co) (free)\n",
    "  - *Why?* Access to thousands of pre-trained models and datasets\n",
    "  - *When you'll use it:* Sessions 1-4 for downloading models\n",
    "- [ ] **GitHub account:** Sign up at [github.com](https://github.com) (free)  \n",
    "  - *Why?* Save your work, contribute to course materials, star repositories\n",
    "  - *Not required:* You can view and download without an account!\n",
    "\n",
    "### **üåç Language Selection**\n",
    "- [ ] **Pick your target language:** Choose one low-resource language to focus on\n",
    "  - *Need ideas?* Try: Luxembourgish, Irish, Maltese, Icelandic, Basque, Welsh, or your heritage language\n",
    "  - *Unsure?* Use Luxembourgish as default - we have good examples ready!\n",
    "\n",
    "### **üìù Text Preparation**  \n",
    "- [ ] **Gather 5-10 sentences** in your target language\n",
    "  - *Requirements:* 6-20 words each, publicly shareable, no personal info\n",
    "  - *Include:* At least one with numbers, one with punctuation, one with borrowed words (if applicable)\n",
    "  - *Examples provided below!*\n",
    "\n",
    "### **üéØ Mindset**\n",
    "- [ ] **Ready to experiment:** Embrace trial and error - it's how we learn!\n",
    "- [ ] **Curious about languages:** Excited to explore how AI handles different languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95cf03",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Part 1: Getting Oriented (Read This First!)\n",
    "\n",
    "Before we start coding, let's make sure you understand how to work with notebooks and what to expect.\n",
    "\n",
    "## üìã Working with Notebooks: Essential Habits\n",
    "\n",
    "These simple habits will save you tons of time and frustration throughout the course. Trust me on these!\n",
    "\n",
    "### **üîÑ Execution Order**\n",
    "- **Always run cells top-to-bottom** when starting fresh\n",
    "- **Restart runtime if things get weird** - it's like turning it off and on again!\n",
    "- **Re-run from the top** if you get unexpected errors\n",
    "\n",
    "### **üíæ Save Your Work**  \n",
    "- **Keep all outputs** - they're useful for debugging and comparing results\n",
    "- **Save notebooks frequently** - don't lose your progress!\n",
    "- **Download results** - especially evaluation sheets and charts\n",
    "\n",
    "### **üìä Documentation Habits**\n",
    "- **Record model names** - write down which models you're using\n",
    "- **Note any changes** - if you modify prompts or settings, document it\n",
    "- **Screenshot interesting results** - especially visualizations and error messages\n",
    "\n",
    "### **üîç Language Comparison Tips**\n",
    "- **Keep meaning consistent** - when comparing languages, use equivalent sentences\n",
    "- **Respect language differences** - don't force English grammar onto other languages\n",
    "- **Note cultural context** - some concepts don't translate directly\n",
    "\n",
    "### **üÜò When Things Go Wrong**\n",
    "1. **Check the error message** - read it carefully, it usually tells you what's wrong\n",
    "2. **Restart and re-run** - many issues are solved this way\n",
    "3. **Ask for help** - don't struggle alone!\n",
    "4. **Document the problem** - it might be useful later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040d5fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé¨ Part 2: Hands-On Setup (Now We Start Coding!)\n",
    "\n",
    "Great! Now that you understand the context and best practices, let's get your hands dirty with actual code. Don't worry‚ÄîI'll explain every step.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Step 1: Install Required Libraries (Your AI Toolbox)\n",
    "\n",
    "**What we're doing:** Installing Python packages that contain pre-written code for working with AI models.\n",
    "\n",
    "**Think of it like this:** You're downloading apps on your phone. Each \"library\" is like an app that gives you specific superpowers:\n",
    "\n",
    "### **üì¶ Your AI Superpowers (What We're Installing):**\n",
    "\n",
    "**ü§ó The Model Library (Transformers + Friends):**\n",
    "- `transformers` - Access to GPT, BERT, and thousands of other models\n",
    "  - *Real talk:* This is the most important package. It's maintained by Hugging Face and used by researchers worldwide.\n",
    "- `datasets` - Pre-made collections of text in many languages\n",
    "- `sentence-transformers` - Turn sentences into numbers (for comparing them)\n",
    "\n",
    "**üìä The Data Science Stack:**\n",
    "- `pandas` - Organize your results in spreadsheet-like tables\n",
    "  - *Beginner tip:* Think of it as Excel, but in Python\n",
    "- `numpy` - Do math on large arrays of numbers quickly\n",
    "- `matplotlib` - Create charts and graphs\n",
    "\n",
    "**üß† The Machine Learning Tools:**\n",
    "- `scikit-learn` - Tools for clustering, classification, and more\n",
    "  - *When you'll use it:* Session 1 (reducing dimensions for visualization)\n",
    "\n",
    "**‚ö° The Performance Boosters:**\n",
    "- `accelerate` - Makes models run faster (especially with GPU)\n",
    "- `tokenizers` - Fast text processing\n",
    "\n",
    "**‚è±Ô∏è Time: 2-3 minutes** (downloading ~500MB of code)\n",
    "\n",
    "**What you'll see:**\n",
    "- Lots of text scrolling by ‚úÖ Normal!\n",
    "- \"Successfully installed...\" ‚úÖ Perfect!\n",
    "- Orange/yellow warnings ‚ö†Ô∏è Usually safe to ignore\n",
    "- Red ERROR messages ‚ùå We need to fix these (I'll help!)\n",
    "\n",
    "**Pro tip:** While this runs, think about which language you want to focus on. Do you have a heritage language? A language you're learning? Or are you curious about a specific low-resource language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Installing Your AI Toolbox\n",
    "# \n",
    "# What these flags mean:\n",
    "# -q = \"quiet mode\" (less output spam)\n",
    "# -U = \"upgrade\" (get the latest versions)\n",
    "# install = download and set up the package\n",
    "#\n",
    "# You'll run this cell ONCE at the start of each session\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üöÄ INSTALLATION STARTING\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚è±Ô∏è  This will take 2-3 minutes...\")\n",
    "print(\"üì• Downloading ~500MB of Python packages...\")\n",
    "print()\n",
    "\n",
    "# --- PART 1: Core AI/NLP Libraries ---\n",
    "print(\"üìö Part 1/2: Installing AI model libraries...\")\n",
    "print(\"   (transformers, datasets, tokenizers, etc.)\")\n",
    "!pip -q install -U transformers datasets sentencepiece tokenizers accelerate\n",
    "\n",
    "# --- PART 2: Data Science Tools ---\n",
    "print(\"üìä Part 2/2: Installing data science tools...\")\n",
    "print(\"   (pandas, numpy, matplotlib, etc.)\")\n",
    "!pip -q install -U sentence-transformers scikit-learn matplotlib pandas numpy\n",
    "\n",
    "# --- DONE! ---\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ INSTALLATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"üí° What just happened:\")\n",
    "print(\"   ‚Ä¢ Downloaded pre-written code from the internet\")\n",
    "print(\"   ‚Ä¢ Installed it into your Python environment\")\n",
    "print(\"   ‚Ä¢ Made it available for the upcoming code cells\")\n",
    "print()\n",
    "print(\"‚ö†Ô∏è Saw warnings? That's usually fine! Warnings (yellow/orange) are different from errors (red).\")\n",
    "print()\n",
    "print(\"üîÑ If you see errors or imports fail later:\")\n",
    "print(\"   1. Try: Runtime ‚Üí Restart Runtime\")\n",
    "print(\"   2. Re-run this cell and all cells below it\")\n",
    "print(\"   3. Still stuck? That's what instructors are for!\")\n",
    "print()\n",
    "print(\"üéâ Ready for the next step!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba6e81d",
   "metadata": {},
   "source": [
    "## üîç Step 2: Check Your Setup\n",
    "\n",
    "Let's make sure everything installed correctly and see what hardware you're working with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1bdc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Let's check what we're working with!\n",
    "import sys\n",
    "import platform\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "\n",
    "def get_package_version(name: str) -> str:\n",
    "    \"\"\"Get version of an installed package\"\"\"\n",
    "    try:\n",
    "        return importlib.import_module(name).__version__\n",
    "    except Exception:\n",
    "        return \"‚ùå not available\"\n",
    "\n",
    "print(\"üìÖ Setup Check Report\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üìÖ Date: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\")\n",
    "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
    "print(f\"üíª Platform: {platform.platform()}\")\n",
    "print()\n",
    "\n",
    "print(\"üìö Library Versions:\")\n",
    "libraries = [\n",
    "    (\"transformers\", \"ü§ó Transformers\"),\n",
    "    (\"datasets\", \"üìä Datasets\"), \n",
    "    (\"sentence_transformers\", \"üî§ Sentence Transformers\"),\n",
    "    (\"torch\", \"üî• PyTorch\"),\n",
    "    (\"sklearn\", \"üß† Scikit-learn\"),\n",
    "    (\"matplotlib\", \"üìà Matplotlib\"),\n",
    "    (\"pandas\", \"üêº Pandas\"),\n",
    "    (\"numpy\", \"üî¢ NumPy\")\n",
    "]\n",
    "\n",
    "for pkg_name, display_name in libraries:\n",
    "    version = get_package_version(pkg_name)\n",
    "    status = \"‚úÖ\" if \"not available\" not in version else \"‚ùå\"\n",
    "    print(f\"  {status} {display_name}: {version}\")\n",
    "\n",
    "print(\"\\nüí° All libraries should show ‚úÖ - if you see ‚ùå, re-run the installation cell above!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üñ•Ô∏è Hardware Check - Let's see what computing power you have!\n",
    "print(\"\\nüñ•Ô∏è Hardware Information:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    # Check for GPU availability\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    \n",
    "    if gpu_available:\n",
    "        print(\"üöÄ GPU Status: ‚úÖ Available!\")\n",
    "        print(f\"   üéÆ GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   ‚ö° CUDA Version: {torch.version.cuda}\")\n",
    "        print(\"   üí° Great! You can run larger models faster\")\n",
    "    else:\n",
    "        print(\"üñ•Ô∏è  GPU Status: ‚ùå Not available (using CPU)\")\n",
    "        print(\"   üí° No worries! CPU works fine for this course\")\n",
    "        print(\"   üîß To get GPU in Colab: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "    \n",
    "    print(f\"\\nüß† PyTorch Backend: {torch.version.__version__}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Hardware check failed: {e}\")\n",
    "    print(\"üí° This might be okay - try continuing with the course\")\n",
    "\n",
    "print(\"\\nüéâ Setup check complete! You're ready to start learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab568db",
   "metadata": {},
   "source": [
    "## üåç Step 3: Choose Your Language & Create Your Dataset\n",
    "\n",
    "This is the fun part! You'll pick a language to focus on and create a small dataset that you'll use throughout all sessions.\n",
    "\n",
    "### **ü§î What makes a language \"low-resource\"?**\n",
    "- **Limited training data:** Less text available online for AI models to learn from\n",
    "- **Fewer speakers:** Often spoken by smaller communities  \n",
    "- **Less tech support:** Fewer tools, keyboards, fonts available\n",
    "- **Examples:** Luxembourgish (~600K speakers), Irish (~1.7M), Maltese (~500K), Icelandic (~350K)\n",
    "\n",
    "### **üìù Dataset Requirements:**\n",
    "Your sentences should be:\n",
    "- **üìè Short:** 6-20 words each (easier for models to handle)\n",
    "- **üîí Public-safe:** Nothing personal, private, or confidential\n",
    "- **üåç Diverse:** Include different sentence types for better testing\n",
    "- **üìä Consistent:** We'll compare these across different models\n",
    "\n",
    "### **üí° Pro Tips for Good Test Sentences:**\n",
    "- ‚úÖ Include one with **numbers** (tests number handling)\n",
    "- ‚úÖ Include one with **punctuation** (tests formatting)  \n",
    "- ‚úÖ Include one with **borrowed words** (tests multilingual mixing)\n",
    "- ‚úÖ Include **different topics** (greetings, facts, questions)\n",
    "- ‚ùå Avoid **names of real people** or **private information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30058e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåç Choose your target language and create your dataset!\n",
    "\n",
    "# üî§ Set your target language code\n",
    "# Common options: \"lb\" (Luxembourgish), \"ga\" (Irish), \"mt\" (Maltese), \n",
    "#                \"is\" (Icelandic), \"eu\" (Basque), \"cy\" (Welsh)\n",
    "TARGET_LANG = \"lb\"  # Change this to your chosen language!\n",
    "\n",
    "print(f\"üéØ Your chosen language: {TARGET_LANG}\")\n",
    "print(\"üí° You can change this anytime by editing the cell above\")\n",
    "\n",
    "# üìö Sample datasets to get you started\n",
    "# These show the pattern - replace with your own sentences!\n",
    "mini_texts = {\n",
    "    \"en\": [\n",
    "        \"I enjoy learning how language models process text.\",\n",
    "        \"This sentence includes a number: 2026, and a comma.\",\n",
    "        \"Short prompts can still produce complex outputs.\",\n",
    "        \"Tokenization choices can change meaning and cost.\",\n",
    "        \"We will evaluate correctness, fluency, and safety.\"\n",
    "    ],\n",
    "    \"lb\": [  # Luxembourgish examples\n",
    "        \"Ech hunn Loscht ze verstoen, w√©i Sproochmodeller Text verschaffen.\",\n",
    "        \"D√´se Saz enth√§lt eng Zuel: 2026, an eng Komma.\",\n",
    "        \"Kuerz Prompte k√´nnen trotzdeem komplex √Ñntwerte produz√©ieren.\",\n",
    "        \"Tokenis√©ierung kann Bedeitung an K√§schte beaflossen.\",\n",
    "        \"Mir evalu√©ieren Richtegkeet, Fl√´ssegkeet an S√©cherheet.\"\n",
    "    ],\n",
    "    \"ga\": [  # Irish examples\n",
    "        \"Is maith liom foghlaim conas a phr√≥ise√°lann samhlacha teanga t√©acs.\",\n",
    "        \"T√° uimhir sa abairt seo: 2026, agus cam√≥g.\",\n",
    "        \"Is f√©idir le leid ghearr aschuir chasta a th√°irgeadh f√≥s.\",\n",
    "        \"Is f√©idir le roghanna tocainithe br√≠ agus costas a athr√∫.\",\n",
    "        \"D√©anaimid meas√∫n√∫ ar chruinneas, l√≠ofacht agus s√°bh√°ilteacht.\"\n",
    "    ],\n",
    "    \"mt\": [  # Maltese examples  \n",
    "        \"Jogƒßobni nitgƒßallem kif il-mudelli tal-lingwa jipproƒãessaw it-test.\",\n",
    "        \"Din is-sentenza tinkludi numru: 2026, u virgola.\",\n",
    "        \"Prompts qosra xorta jistgƒßu jipproduƒãu outputs kumplessi.\",\n",
    "        \"L-gƒßa≈ºliet tat-tokenization jistgƒßu jbiddlu t-tifsira u l-ispejje≈º.\",\n",
    "        \"Aƒßna nevalwaw it-tƒßassib, il-fluwenza u s-sigurt√†.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# üîß Add your language if it's not in the examples above\n",
    "if TARGET_LANG not in mini_texts:\n",
    "    print(f\"\\nüìù {TARGET_LANG} not in examples - please add your sentences below!\")\n",
    "    mini_texts[TARGET_LANG] = [\n",
    "        \"Add your first sentence here (6-20 words).\",\n",
    "        \"Add your second sentence with a number: 2026.\",\n",
    "        \"Add your third sentence here.\",\n",
    "        \"Add your fourth sentence here.\",\n",
    "        \"Add your fifth sentence here.\"\n",
    "    ]\n",
    "    print(\"üí° Edit the list above to add your own sentences!\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Found example sentences for {TARGET_LANG}!\")\n",
    "\n",
    "print(f\"\\nüìã Your current dataset:\")\n",
    "print(f\"üåç Language: {TARGET_LANG}\")\n",
    "print(f\"üìä Number of sentences: {len(mini_texts[TARGET_LANG])}\")\n",
    "print(f\"üìù Example: '{mini_texts[TARGET_LANG][0]}'\")\n",
    "\n",
    "print(f\"\\nüîç All your {TARGET_LANG} sentences:\")\n",
    "for i, sentence in enumerate(mini_texts[TARGET_LANG], 1):\n",
    "    print(f\"  {i}. {sentence}\")\n",
    "\n",
    "print(\"\\nüí° Remember: You can edit these sentences anytime by modifying the cell above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e21639",
   "metadata": {},
   "source": [
    "## üìä Step 4: Create Your Evaluation Toolkit\n",
    "\n",
    "Now we'll build a systematic way to evaluate AI model outputs. This is crucial for low-resource languages where automated metrics often don't work well!\n",
    "\n",
    "### **üéØ Why do we need this?**\n",
    "- **No \"ground truth\":** Unlike English, we often can't rely on existing benchmarks\n",
    "- **Cultural nuance:** Models might be technically correct but culturally inappropriate  \n",
    "- **Systematic comparison:** We need consistent ways to compare different approaches\n",
    "- **Documentation:** Track what works and what doesn't for your language\n",
    "\n",
    "### **üìè Our Evaluation Dimensions:**\n",
    "We'll rate each output on a 0-2 scale:\n",
    "\n",
    "1. **‚úÖ Correctness:** Does it solve the task correctly?\n",
    "   - 2 = Perfect, 1 = Mostly right, 0 = Wrong or nonsensical\n",
    "\n",
    "2. **üó£Ô∏è Fluency:** Does it sound natural in your language?  \n",
    "   - 2 = Native-like, 1 = Understandable but awkward, 0 = Broken/ungrammatical\n",
    "\n",
    "3. **üåç Cultural Appropriateness:** Does it respect cultural norms?\n",
    "   - 2 = Culturally appropriate, 1 = Minor issues, 0 = Offensive or inappropriate\n",
    "\n",
    "4. **üõ°Ô∏è Safety:** Does it avoid harmful content?\n",
    "   - 2 = Safe and helpful, 1 = Minor concerns, 0 = Harmful or dangerous\n",
    "\n",
    "5. **üìù Notes:** Free text for observations, failure patterns, interesting behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc27f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Create your personalized evaluation sheet\n",
    "import pandas as pd\n",
    "\n",
    "def create_evaluation_sheet(texts: dict, target_lang: str) -> pd.DataFrame:\n",
    "    \"\"\"Create a structured evaluation sheet for tracking model outputs\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    # Add English sentences for comparison\n",
    "    for i, sentence in enumerate(texts.get(\"en\", []), start=1):\n",
    "        rows.append({\n",
    "            \"item_id\": f\"en_{i}\",\n",
    "            \"language\": \"en\",\n",
    "            \"input_text\": sentence,\n",
    "            \"task\": \"\",  # Will be filled during sessions\n",
    "            \"model\": \"\",  # Will be filled during sessions\n",
    "            \"prompt_style\": \"\",  # Will be filled during sessions\n",
    "            \"output_text\": \"\",  # Will be filled during sessions\n",
    "            \"correctness_0to2\": \"\",  # Your rating 0-2\n",
    "            \"fluency_0to2\": \"\",  # Your rating 0-2\n",
    "            \"cultural_0to2\": \"\",  # Your rating 0-2\n",
    "            \"safety_0to2\": \"\",  # Your rating 0-2\n",
    "            \"notes\": \"\"  # Your observations\n",
    "        })\n",
    "    \n",
    "    # Add your target language sentences\n",
    "    for i, sentence in enumerate(texts.get(target_lang, []), start=1):\n",
    "        rows.append({\n",
    "            \"item_id\": f\"{target_lang}_{i}\",\n",
    "            \"language\": target_lang,\n",
    "            \"input_text\": sentence,\n",
    "            \"task\": \"\",\n",
    "            \"model\": \"\",\n",
    "            \"prompt_style\": \"\",\n",
    "            \"output_text\": \"\",\n",
    "            \"correctness_0to2\": \"\",\n",
    "            \"fluency_0to2\": \"\",\n",
    "            \"cultural_0to2\": \"\",\n",
    "            \"safety_0to2\": \"\",\n",
    "            \"notes\": \"\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Create your evaluation sheet\n",
    "eval_df = create_evaluation_sheet(mini_texts, TARGET_LANG)\n",
    "\n",
    "print(f\"üìã Created evaluation sheet with {len(eval_df)} rows\")\n",
    "print(f\"üåç Languages: English + {TARGET_LANG}\")\n",
    "print(f\"üìä Sentences per language: {len(mini_texts['en'])}\")\n",
    "\n",
    "print(\"\\nüëÄ Preview of your evaluation sheet:\")\n",
    "print(\"=\" * 60)\n",
    "display(eval_df.head(8))\n",
    "\n",
    "print(\"\\nüí° This sheet will be your companion throughout all sessions!\")\n",
    "print(\"üìù You'll fill in the empty columns as you test different models and prompts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4510b9f2",
   "metadata": {},
   "source": [
    "## üíæ Step 5: Save Your Evaluation Sheet\n",
    "\n",
    "Let's save your evaluation sheet so you can use it throughout the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ Save your evaluation sheet for future sessions\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"session0_outputs\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the evaluation sheet\n",
    "filename = f\"evaluation_sheet_{TARGET_LANG}.csv\"\n",
    "file_path = output_dir / filename\n",
    "\n",
    "eval_df.to_csv(file_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"‚úÖ Evaluation sheet saved successfully!\")\n",
    "print(f\"üìÅ Location: {file_path}\")\n",
    "print(f\"üìä Contains: {len(eval_df)} evaluation rows\")\n",
    "\n",
    "# Show how to download in different environments\n",
    "print(\"\\nüì• How to access your file:\")\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"üîó In Colab: Check the Files panel on the left ‚Üí session0_outputs folder\")\n",
    "    print(\"üíæ To download: Right-click the file ‚Üí Download\")\n",
    "else:\n",
    "    print(f\"üìÇ Local file saved at: {os.path.abspath(file_path)}\")\n",
    "\n",
    "print(\"\\nüí° Keep this file safe! You'll use it in all upcoming sessions.\")\n",
    "print(\"üìù Pro tip: Make a backup copy before each session!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f40f0f",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 6: Test Everything Works - Multilingual Model Demo\n",
    "\n",
    "Time for the exciting part! Let's test that everything works by running a real multilingual model on your sentences.\n",
    "\n",
    "### **üéØ What this test does:**\n",
    "- **Downloads a multilingual model** from Hugging Face (first time only)\n",
    "- **Creates embeddings** (numerical representations) of your sentences  \n",
    "- **Visualizes the results** to see how the model \"sees\" different languages\n",
    "- **Confirms your setup** is working for the upcoming sessions\n",
    "\n",
    "### **üìä What you should see:**\n",
    "1. ‚úÖ Successful model loading (might take 1-2 minutes first time)\n",
    "2. üìä Embedding vectors for your sentences  \n",
    "3. üìà A 2D chart showing how languages cluster together\n",
    "4. üéâ Confirmation that you're ready for Session 1!\n",
    "\n",
    "**‚ö†Ô∏è If you're offline or have network restrictions, you can skip this test and proceed to the troubleshooting section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ Load and test a multilingual model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# üîÑ Loading a state-of-the-art multilingual model\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "print(\"üîÑ Loading multilingual model...\")\n",
    "print(f\"üì¶ Model: {MODEL_NAME}\")\n",
    "print(\"‚è±Ô∏è This might take 1-2 minutes the first time (downloading ~420MB)\")\n",
    "\n",
    "try:\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "    \n",
    "    # üìù Prepare your sentences for testing\n",
    "    test_texts = []\n",
    "    test_labels = []\n",
    "    \n",
    "    print(f\"\\nüìä Preparing sentences for embedding:\")\n",
    "    for lang in [\"en\", TARGET_LANG]:\n",
    "        if lang in mini_texts:\n",
    "            for sentence in mini_texts[lang]:\n",
    "                test_texts.append(sentence)\n",
    "                test_labels.append(lang)\n",
    "                print(f\"  üìù {lang}: {sentence[:50]}{'...' if len(sentence) > 50 else ''}\")\n",
    "    \n",
    "    # üß† Generate embeddings (numerical representations)\n",
    "    print(f\"\\nüß† Generating embeddings for {len(test_texts)} sentences...\")\n",
    "    embeddings = model.encode(test_texts, normalize_embeddings=True)\n",
    "    \n",
    "    print(f\"‚úÖ Success! Generated embeddings:\")\n",
    "    print(f\"   üìä Shape: {embeddings.shape}\")\n",
    "    print(f\"   üî¢ Each sentence ‚Üí {embeddings.shape[1]} numbers\")\n",
    "    print(f\"   üåç Languages: {len(set(test_labels))}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Model loading failed: {e}\")\n",
    "    print(\"üí° This might be due to network issues - you can continue with the course\")\n",
    "    print(\"üîß Try: Runtime ‚Üí Restart Runtime, then re-run from the top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà Create a visualization to see how the model groups languages\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'embeddings' in locals():\n",
    "    print(\"üìà Creating visualization...\")\n",
    "    \n",
    "    # Use PCA to reduce high-dimensional embeddings to 2D for plotting\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    embeddings_2d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Plot each language with different colors\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    unique_languages = sorted(set(test_labels))\n",
    "    \n",
    "    for i, lang in enumerate(unique_languages):\n",
    "        # Find all sentences in this language\n",
    "        lang_indices = [j for j, label in enumerate(test_labels) if label == lang]\n",
    "        \n",
    "        # Plot them with the same color\n",
    "        plt.scatter(embeddings_2d[lang_indices, 0], \n",
    "                   embeddings_2d[lang_indices, 1], \n",
    "                   label=f'{lang} ({len(lang_indices)} sentences)',\n",
    "                   color=colors[i % len(colors)],\n",
    "                   s=100, alpha=0.7)\n",
    "    \n",
    "    plt.title(f'üåç How the Model \"Sees\" Your Languages\\n(Each dot = one sentence)', fontsize=14)\n",
    "    plt.xlabel('üìä Principal Component 1', fontsize=12)\n",
    "    plt.ylabel('üìä Principal Component 2', fontsize=12)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add some explanation\n",
    "    plt.figtext(0.5, 0.02, \n",
    "                'üí° Closer dots = more similar according to the model | Different colors = different languages',\n",
    "                ha='center', fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üéâ Visualization complete!\")\n",
    "    print(\"üîç What to look for:\")\n",
    "    print(\"  ‚Ä¢ Do sentences from the same language cluster together?\")\n",
    "    print(\"  ‚Ä¢ Are equivalent sentences (same meaning) close to each other?\")\n",
    "    print(\"  ‚Ä¢ Any surprising patterns or outliers?\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping visualization - model loading failed above\")\n",
    "    print(\"üí° This is okay - you can still continue with the course!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f8981",
   "metadata": {},
   "source": [
    "## 0.11 Troubleshooting\n",
    "\n",
    "1. **Install errors.** Rerun the install cell. If it still fails, restart runtime, then reinstall.\n",
    "2. **Model download errors.** Your network may block downloads. Try again on a different network, or use a local environment with cached models.\n",
    "3. **Out of memory.** Use CPU runtime, and keep batch sizes small.\n",
    "4. **Unicode issues.** Always save text files as UTF 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee37ce",
   "metadata": {},
   "source": [
    "## 0.12 Prework for Session 1\n",
    "\n",
    "Before Session 1, do the following.\n",
    "\n",
    "1. Replace the default sentences in `mini_texts[TARGET_LANG]` with your own approved examples.\n",
    "2. Add at least one sentence that includes digits, and one sentence with quotation marks if your language uses them.\n",
    "3. Save the updated evaluation sheet CSV again.\n",
    "4. Write down two hypotheses about what might go wrong for your language, for example tokenization splits borrowed words, or punctuation is handled inconsistently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf43678",
   "metadata": {},
   "source": [
    "## 0.13 Optional reflection questions\n",
    "\n",
    "1. Which parts of your language are likely to be underrepresented in general web scale training data.\n",
    "2. Where do you expect prompt following to fail first. Grammar, reasoning, politeness norms, or domain knowledge.\n",
    "3. What would you consider a successful outcome for this course in your own work context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
