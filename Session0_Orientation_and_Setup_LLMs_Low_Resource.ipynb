{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be60dbd3",
   "metadata": {},
   "source": [
    "# Session 0: Welcome to the LLM Adventure! ğŸš€\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "**ğŸ“š Course Repository:** [github.com/NinaKivanani/Tutorials_low-resource-llm](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NinaKivanani/Tutorials_low-resource-llm/blob/main/Session0_Orientation_and_Setup_LLMs_Low_Resource.ipynb)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-View%20Repository-blue?logo=github)](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "[![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](https://opensource.org/licenses/Apache-2.0)\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ® Your Learning Quest Begins Here!\n",
    "\n",
    "**Welcome, Language Champion!** ğŸ‘‹ You're about to embark on a journey that will transform you from an AI curious learner into a **multilingual AI expert**. This isn't just another coding tutorialâ€”it's your mission to democratize AI for the world's 6,900+ languages!\n",
    "\n",
    "### ğŸ† Your 30-Minute Setup Challenge:\n",
    "```\n",
    "ğŸ¯ Mission Checklist:\n",
    "â”œâ”€â”€ ğŸ”§ Power Up Your Environment     [â–¡â–¡â–¡â–¡â–¡] 0%\n",
    "â”œâ”€â”€ ğŸŒ Choose Your Language Quest    [â–¡â–¡â–¡â–¡â–¡] 0%  \n",
    "â”œâ”€â”€ ğŸ“Š Build Your Evaluation Toolkit [â–¡â–¡â–¡â–¡â–¡] 0%\n",
    "â”œâ”€â”€ ğŸ¤– Test with Real AI Models      [â–¡â–¡â–¡â–¡â–¡] 0%\n",
    "â””â”€â”€ ğŸš€ Ready for Session 1!         [â–¡â–¡â–¡â–¡â–¡] 0%\n",
    "```\n",
    "\n",
    "**â±ï¸ Total time:** 30-45 minutes of pure setup magic!  \n",
    "**ğŸ¯ Difficulty:** Beginner-friendly with expert insights\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒŸ The Big Picture: Why Your Mission Matters\n",
    "\n",
    "**ğŸš¨ The Problem:** Right now, AI works amazingly for English, okay for ~10 major languages, and poorly (or not at all) for 6,800+ other languages. This isn't just a technical issueâ€”it's creating a **digital divide** that leaves billions of people behind.\n",
    "\n",
    "**ğŸ¦¸â€â™€ï¸ Your Superpower:** After this course, you'll be able to:\n",
    "- ğŸ” **Diagnose** why AI fails for specific languages\n",
    "- ğŸ› ï¸ **Fix** models to work better with limited resources  \n",
    "- âš–ï¸ **Audit** systems for fairness and cultural sensitivity\n",
    "- ğŸŒ **Bridge** the gap between cutting-edge AI and real-world diversity\n",
    "\n",
    "**ğŸ’¡ Plot Twist:** You don't need to be a programming wizard! We'll teach you everything step-by-step, with plenty of visual explanations and hands-on practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474afb1",
   "metadata": {},
   "source": [
    "## ğŸ—ºï¸ Your Epic Learning Adventure: 4 Sessions, 4 Superpowers\n",
    "\n",
    "### ğŸ® Course Game Plan\n",
    "```\n",
    "ğŸ° Building Your Multilingual AI Castle:\n",
    "\n",
    "Session 0: ğŸ—ï¸  Foundation (Setup & Orientation)     â† YOU ARE HERE\n",
    "Session 1: ğŸ” Detective Work (Dialogue + Analysis)   â† Solve language mysteries  \n",
    "Session 2: ğŸ¯ Prompt Mastery (Teaching AI)          â† Become an AI whisperer\n",
    "Session 3: âš™ï¸  Custom Building (Fine-tuning)        â† Craft personalized models\n",
    "Session 4: âš–ï¸  Guardian Mode (Bias & Ethics)        â† Protect communities\n",
    "```\n",
    "\n",
    "### ğŸ¯ What Each Session Unlocks:\n",
    "\n",
    "**ğŸ” Session 1: Language Detective** *(2-3 hours)*\n",
    "- **Mission:** Investigate how AI \"sees\" different languages through dialogue summarization\n",
    "- **Skills:** Tokenization analysis, TextRank algorithms, systematic evaluation\n",
    "- **Boss Fight:** Handle noisy, corrupted text like a pro\n",
    "- **Reward:** Robust baseline system that works everywhere\n",
    "\n",
    "**ğŸ¯ Session 2: AI Whisperer** *(2 hours)*  \n",
    "- **Mission:** Master the art of talking to AI in any language\n",
    "- **Skills:** Prompt engineering, zero-shot learning, cross-lingual strategies\n",
    "- **Boss Fight:** Make English-trained models work in your language\n",
    "- **Reward:** Personal prompt library and advanced techniques\n",
    "\n",
    "**âš™ï¸ Session 3: Model Architect** *(2 hours)*\n",
    "- **Mission:** Customize AI models for your specific language needs\n",
    "- **Skills:** Fine-tuning, parameter efficiency, domain adaptation\n",
    "- **Boss Fight:** Achieve better performance with limited data\n",
    "- **Reward:** Your own fine-tuned model\n",
    "\n",
    "**âš–ï¸ Session 4: AI Guardian** *(2 hours)*\n",
    "- **Mission:** Ensure AI systems are fair and culturally appropriate\n",
    "- **Skills:** Bias detection, fairness metrics, ethical evaluation\n",
    "- **Boss Fight:** Identify and fix hidden biases\n",
    "- **Reward:** Comprehensive bias audit framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37863517",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Your Course Arsenal: GitHub Repository\n",
    "\n",
    "**ğŸ¯ Quick Access:** [github.com/NinaKivanani/Tutorials_low-resource-llm](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "\n",
    "### ğŸ® What's in Your Toolkit?\n",
    "```\n",
    "ğŸ° Your AI Castle Blueprint:\n",
    "â”œâ”€â”€ ğŸ—ï¸  Session 0: This orientation guide\n",
    "â”œâ”€â”€ ğŸ” Session 1: Dialogue detective work  \n",
    "â”œâ”€â”€ ğŸ¯ Session 2: Prompt mastery training\n",
    "â”œâ”€â”€ âš™ï¸  Session 3: Model customization lab\n",
    "â”œâ”€â”€ âš–ï¸  Session 4: Bias audit framework\n",
    "â”œâ”€â”€ ğŸ“Š data/: Practice datasets\n",
    "â””â”€â”€ ğŸ¯ examples/: Working solutions\n",
    "```\n",
    "\n",
    "### ğŸš€ Access Methods:\n",
    "- **ğŸ¥‡ Colab:** Click \"Open in Colab\" badges (easiest!)\n",
    "- **ğŸ’» Local:** `git clone` or download ZIP\n",
    "- **ğŸ“± Mobile:** View on GitHub mobile app\n",
    "4. You're ready to run code! (No installation needed on your computer)\n",
    "\n",
    "**Option 2: Download to Your Computer**\n",
    "1. Go to the GitHub repository\n",
    "2. Click the green \"Code\" button\n",
    "3. Select \"Download ZIP\"\n",
    "4. Extract the files on your computer\n",
    "5. Open with Jupyter Notebook or VS Code\n",
    "\n",
    "**Option 3: Clone with Git (For Advanced Users)**\n",
    "```bash\n",
    "git clone https://github.com/NinaKivanani/Tutorials_low-resource-llm.git\n",
    "cd Tutorials_low-resource-llm\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "### **ğŸ’¡ Pro Tips:**\n",
    "\n",
    "**Staying Updated:**\n",
    "- â­ **Star the repository** on GitHub to bookmark it\n",
    "- ğŸ‘€ **Watch the repository** to get notifications of updates\n",
    "- ğŸ”„ Check back periodically - we add new examples and fix issues!\n",
    "\n",
    "**Getting Help:**\n",
    "- ğŸ› Found a bug? Open an \"Issue\" on GitHub\n",
    "- ğŸ’¬ Have questions? Use the \"Discussions\" tab\n",
    "- ğŸ¤ Want to contribute? Pull requests welcome!\n",
    "\n",
    "**Making it Your Own:**\n",
    "- ğŸ´ **Fork the repository** to create your own copy\n",
    "- âœï¸ Modify notebooks for your specific language/use case\n",
    "- ğŸ’¾ Your changes are saved to YOUR fork, not the original\n",
    "\n",
    "### **ğŸ†˜ \"I'm New to GitHub\" - Quick Guide:**\n",
    "\n",
    "**What is GitHub?** Think of it as Google Drive for code. It stores files and tracks changes.\n",
    "\n",
    "**Do I need an account?** \n",
    "- To *view* and *download*: NO âœ…\n",
    "- To *save changes* or *contribute*: YES (free to sign up)\n",
    "\n",
    "**I just want the notebooks!**\n",
    "- Click the GitHub link above\n",
    "- Click on any `.ipynb` file\n",
    "- Click \"Open in Colab\" or \"Download\"\n",
    "- Done! ğŸ‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¤ Our Learning Agreement\n",
    "\n",
    "Let's establish some important principles for working together:\n",
    "\n",
    "### **ğŸ”¬ Scientific Rigor**\n",
    "- **Document everything:** Keep track of which models, prompts, and settings you use\n",
    "- **Reproducible results:** Others should be able to recreate your experiments\n",
    "- **Learn from failures:** When something doesn't work, that's valuable data too!\n",
    "\n",
    "### **ğŸŒ Language Respect** \n",
    "- **\"Low-resource\" â‰  \"low-value\":** These languages represent rich cultures and communities\n",
    "- **Cultural sensitivity:** Respect local conventions, writing systems, and cultural norms\n",
    "- **Avoid linguistic imperialism:** Don't assume English-centric approaches are always best\n",
    "\n",
    "### **ğŸ”’ Data Safety & Ethics**\n",
    "- **No personal data:** Don't use private messages, medical records, or confidential information\n",
    "- **Public-safe content:** Only use text you're comfortable sharing publicly\n",
    "- **Respect privacy:** When in doubt, create synthetic examples instead\n",
    "\n",
    "### **ğŸ“š Growth Mindset**\n",
    "- **Questions welcome:** No question is too basic - ask away!\n",
    "- **Collaborative learning:** Help your peers and learn from them\n",
    "- **Iterate and improve:** Expect to refine your approaches as you learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9082f776",
   "metadata": {},
   "source": [
    "## ğŸ¯ Quick Start Checklist\n",
    "\n",
    "### âœ… Your Pre-Mission Briefing:\n",
    "\n",
    "**ğŸ”§ Platform Ready?**\n",
    "- [ ] Colab account OR local Jupyter setup\n",
    "- [ ] Can create and run a simple notebook\n",
    "- [ ] GPU access (optional but helpful)\n",
    "\n",
    "**ğŸŒ Language Mission Selected?**\n",
    "- [ ] Pick your target language (Luxembourgish, Irish, Welsh, etc.)\n",
    "- [ ] Gather 5-10 sample sentences (6-20 words each)\n",
    "- [ ] Ensure text is publicly shareable (no personal data!)\n",
    "\n",
    "**ğŸ”‘ Optional Power-Ups:**\n",
    "- [ ] [Hugging Face account](https://huggingface.co) (free model access)\n",
    "- [ ] [GitHub account](https://github.com) (save your work)\n",
    "\n",
    "### ğŸš¨ Ready Check:\n",
    "If you checked all the boxes above, you're ready to begin! If not, don't worryâ€”we'll help you get set up as we go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95cf03",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ® Notebook Survival Guide\n",
    "\n",
    "### ğŸ”„ Essential Habits (Save Yourself Hours of Debugging!)\n",
    "- **Run cells top-to-bottom** when starting fresh\n",
    "- **Restart runtime if weird errors appear** (Runtime â†’ Restart runtime)\n",
    "- **Save frequently** (Ctrl+S / Cmd+S)\n",
    "- **Keep outputs** - they're useful for comparison!\n",
    "- **Save notebooks frequently** - don't lose your progress!\n",
    "- **Download results** - especially evaluation sheets and charts\n",
    "\n",
    "### **ğŸ” Language Comparison Tips**\n",
    "- **Keep meaning consistent** - when comparing languages, use equivalent sentences\n",
    "- **Respect language differences** - don't force English grammar onto other languages\n",
    "- **Note cultural context** - some concepts don't translate directly\n",
    "\n",
    "### **ğŸ†˜ When Things Go Wrong**\n",
    "1. **Check the error message** - read it carefully, it usually tells you what's wrong\n",
    "2. **Restart and re-run** - many issues are solved this way\n",
    "3. **Google it (stackoverflow)**\n",
    "4. **Ask for help** - don't struggle alone!\n",
    "5. **Document the problem** - it might be useful later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040d5fe",
   "metadata": {},
   "source": [
    "## ğŸ”§ Step 1: Install Required Libraries\n",
    "\n",
    "Time to set up your toolkit! We'll install all the libraries you need for the course.\n",
    "\n",
    "**What we're installing:**\n",
    "- **ğŸ¤— Transformers:** Access to thousands of pre-trained models\n",
    "- **ğŸ“Š Data tools:** pandas, numpy for handling data  \n",
    "- **ğŸ“ˆ Visualization:** matplotlib for creating charts\n",
    "- **ğŸ§  ML tools:** scikit-learn for machine learning utilities\n",
    "- **âš¡ Acceleration:** Tools to make models run faster\n",
    "\n",
    "**â±ï¸ This takes 2-3 minutes** - perfect time for a coffee break!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14e214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15395.43s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires requests==2.31.0, but you have requests 2.32.5 which is incompatible.\n",
      "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m15466.45s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ğŸš€ Mission 2: Install Your AI Superpowers!\n",
    "\n",
    "print(\"ğŸ® LOADING AI SUPERPOWERS...\")\n",
    "print(\"=\" * 50)\n",
    "print(\"â±ï¸  ETA: 2-3 minutes (perfect for a coffee break!)\")\n",
    "print(\"ğŸ¯ Installing your multilingual AI toolkit...\")\n",
    "print()\n",
    "\n",
    "# Core AI libraries for language processing\n",
    "print(\"ğŸ¤– Installing AI brain modules...\")\n",
    "!pip -q install transformers datasets sentencepiece tokenizers accelerate\n",
    "\n",
    "# Additional tools for analysis and visualization  \n",
    "print(\"ğŸ“Š Installing analysis tools...\")\n",
    "!pip -q install sentence-transformers scikit-learn\n",
    "\n",
    "print()\n",
    "print(\"ğŸ‰ SUPERPOWERS ACTIVATED!\")\n",
    "print(\"=\" * 50)\n",
    "print(\"âœ… Your AI toolkit is ready!\")\n",
    "print(\"ğŸ’¡ Those dependency warnings? Totally normal in Colab!\")\n",
    "print(\"ğŸš€ Let's test everything in the next cell...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba6e81d",
   "metadata": {},
   "source": [
    "## ğŸ” Step 2: Check Your Setup\n",
    "\n",
    "Let's make sure everything installed correctly and see what hardware you're working with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1bdc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“… Setup Check Report\n",
      "========================================\n",
      "ğŸ“… Date: 2026-01-12 11:01 UTC\n",
      "ğŸ Python: 3.11.5\n",
      "ğŸ’» Platform: macOS-15.3-arm64-arm-64bit\n",
      "\n",
      "ğŸ“š Library Versions:\n",
      "  âœ… ğŸ¤— Transformers: 4.57.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nina.hosseinikivanan/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… ğŸ“Š Datasets: 4.4.2\n",
      "  âœ… ğŸ”¤ Sentence Transformers: 5.2.0\n",
      "  âœ… ğŸ”¥ PyTorch: 2.9.1\n",
      "  âœ… ğŸ§  Scikit-learn: 1.8.0\n",
      "  âœ… ğŸ“ˆ Matplotlib: 3.10.8\n",
      "  âœ… ğŸ¼ Pandas: 2.3.3\n",
      "  âœ… ğŸ”¢ NumPy: 1.26.4\n",
      "\n",
      "ğŸ’¡ All libraries should show âœ… - if you see âŒ, re-run the installation cell above!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Mission 3: System Diagnostics & Power Check!\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "\n",
    "def get_package_version(name: str) -> str:\n",
    "    \"\"\"Get version of an installed package\"\"\"\n",
    "    try:\n",
    "        return importlib.import_module(name).__version__\n",
    "    except Exception:\n",
    "        return \"âŒ not available\"\n",
    "\n",
    "print(\"ğŸ® SYSTEM DIAGNOSTICS REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ“… Mission Date: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\")\n",
    "print(f\"ğŸ Python: {sys.version.split()[0]}\")\n",
    "print(f\"ğŸ’» Platform: {platform.platform()}\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“š Library Versions:\")\n",
    "libraries = [\n",
    "    (\"transformers\", \"ğŸ¤— Transformers\"),\n",
    "    (\"datasets\", \"ğŸ“Š Datasets\"), \n",
    "    (\"sentence_transformers\", \"ğŸ”¤ Sentence Transformers\"),\n",
    "    (\"torch\", \"ğŸ”¥ PyTorch\"),\n",
    "    (\"sklearn\", \"ğŸ§  Scikit-learn\"),\n",
    "    (\"matplotlib\", \"ğŸ“ˆ Matplotlib\"),\n",
    "    (\"pandas\", \"ğŸ¼ Pandas\"),\n",
    "    (\"numpy\", \"ğŸ”¢ NumPy\")\n",
    "]\n",
    "\n",
    "for pkg_name, display_name in libraries:\n",
    "    version = get_package_version(pkg_name)\n",
    "    status = \"âœ…\" if \"not available\" not in version else \"âŒ\"\n",
    "    print(f\"  {status} {display_name}: {version}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ All libraries should show âœ… - if you see âŒ, re-run the installation cell above!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ–¥ï¸ Hardware Check - Let's see what computing power you have!\n",
    "print(\"\\nğŸ–¥ï¸ Hardware Information:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    # Check for GPU availability\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    \n",
    "    if gpu_available:\n",
    "        print(\"ğŸš€ GPU Status: âœ… Available!\")\n",
    "        print(f\"   ğŸ® GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   âš¡ CUDA Version: {torch.version.cuda}\")\n",
    "        print(\"   ğŸ’¡ Great! You can run larger models faster\")\n",
    "    else:\n",
    "        print(\"ğŸ–¥ï¸  GPU Status: âŒ Not available (using CPU)\")\n",
    "        print(\"   ğŸ’¡ No worries! CPU works fine for this course\")\n",
    "        print(\"   ğŸ”§ To get GPU in Colab: Runtime â†’ Change runtime type â†’ GPU\")\n",
    "    \n",
    "    print(f\"\\nğŸ§  PyTorch Backend: {torch.version.__version__}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Hardware check failed: {e}\")\n",
    "    print(\"ğŸ’¡ This might be okay - try continuing with the course\")\n",
    "\n",
    "print(\"\\nğŸ‰ Setup check complete! You're ready to start learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab568db",
   "metadata": {},
   "source": [
    "## ğŸŒ Mission 4: Choose Your Language Quest!\n",
    "\n",
    "Time to pick your linguistic adventure! You'll select a language and create test sentences that will be your companions throughout all sessions.\n",
    "\n",
    "### ğŸ¯ Language Selection Strategy:\n",
    "```\n",
    "ğŸ† Perfect Test Languages:\n",
    "â”œâ”€â”€ ğŸ‡±ğŸ‡º Luxembourgish (~600K speakers)\n",
    "â”œâ”€â”€ ğŸ‡®ğŸ‡ª Irish (~1.7M speakers)  \n",
    "â”œâ”€â”€ ğŸ‡²ğŸ‡¹ Maltese (~500K speakers)\n",
    "â”œâ”€â”€ ğŸ‡®ğŸ‡¸ Icelandic (~350K speakers)\n",
    "â”œâ”€â”€ ğŸ´ó §ó ¢ó ·ó ¬ó ³ó ¿ Welsh (~900K speakers)\n",
    "â””â”€â”€ ğŸ‡ªğŸ‡¸ Basque (~750K speakers)\n",
    "```\n",
    "\n",
    "### ğŸ“ Your Test Sentence Mission:\n",
    "Create 5-7 sentences that are:\n",
    "- **ğŸ“ Goldilocks length:** 6-20 words (not too short, not too long)\n",
    "- **ğŸ”’ Public-friendly:** Safe to share with the world\n",
    "- **ğŸ¯ Diverse:** Different types to stress-test AI models\n",
    "- **ğŸ§ª Scientific:** Include numbers, punctuation, borrowed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30058e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Mission 4: Language Selection & Dataset Creation\n",
    "\n",
    "# ğŸŒ Choose your linguistic adventure!\n",
    "TARGET_LANG = \"lb\"  # ğŸ‡±ğŸ‡º Luxembourgish (change to your choice!)\n",
    "\n",
    "print(f\"ğŸ® LANGUAGE QUEST SELECTED: {TARGET_LANG}\")\n",
    "print(\"ğŸ”„ (Edit the cell above to change your language)\")\n",
    "print()\n",
    "\n",
    "# ğŸ“š Your Test Sentence Arsenal\n",
    "# Replace these with your own sentences in your chosen language!\n",
    "mini_texts = {\n",
    "    \"en\": [\n",
    "        \"I enjoy learning how language models process text.\",\n",
    "        \"This sentence includes a number: 2026, and a comma.\",\n",
    "        \"Short prompts can still produce complex outputs.\",\n",
    "        \"Tokenization choices can change meaning and cost.\",\n",
    "        \"We will evaluate correctness, fluency, and safety.\"\n",
    "    ],\n",
    "    \"lb\": [  # Luxembourgish examples\n",
    "        \"Ech hunn Loscht ze verstoen, wÃ©i Sproochmodeller Text verschaffen.\",\n",
    "        \"DÃ«se Saz enthÃ¤lt eng Zuel: 2026, an eng Komma.\",\n",
    "        \"Kuerz Prompte kÃ«nnen trotzdeem komplex Ã„ntwerte produzÃ©ieren.\",\n",
    "        \"TokenisÃ©ierung kann Bedeitung an KÃ¤schte beaflossen.\",\n",
    "        \"Mir evaluÃ©ieren Richtegkeet, FlÃ«ssegkeet an SÃ©cherheet.\"\n",
    "    ],\n",
    "    \"ga\": [  # Irish examples\n",
    "        \"Is maith liom foghlaim conas a phrÃ³iseÃ¡lann samhlacha teanga tÃ©acs.\",\n",
    "        \"TÃ¡ uimhir sa abairt seo: 2026, agus camÃ³g.\",\n",
    "        \"Is fÃ©idir le leid ghearr aschuir chasta a thÃ¡irgeadh fÃ³s.\",\n",
    "        \"Is fÃ©idir le roghanna tocainithe brÃ­ agus costas a athrÃº.\",\n",
    "        \"DÃ©anaimid measÃºnÃº ar chruinneas, lÃ­ofacht agus sÃ¡bhÃ¡ilteacht.\"\n",
    "    ],\n",
    "    \"mt\": [  # Maltese examples  \n",
    "        \"JogÄ§obni nitgÄ§allem kif il-mudelli tal-lingwa jipproÄ‹essaw it-test.\",\n",
    "        \"Din is-sentenza tinkludi numru: 2026, u virgola.\",\n",
    "        \"Prompts qosra xorta jistgÄ§u jipproduÄ‹u outputs kumplessi.\",\n",
    "        \"L-gÄ§aÅ¼liet tat-tokenization jistgÄ§u jbiddlu t-tifsira u l-ispejjeÅ¼.\",\n",
    "        \"AÄ§na nevalwaw it-tÄ§assib, il-fluwenza u s-sigurtÃ .\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ğŸ”§ Add your language if it's not in the examples above\n",
    "if TARGET_LANG not in mini_texts:\n",
    "    print(f\"\\nğŸ“ {TARGET_LANG} not in examples - please add your sentences below!\")\n",
    "    mini_texts[TARGET_LANG] = [\n",
    "        \"Add your first sentence here (6-20 words).\",\n",
    "        \"Add your second sentence with a number: 2026.\",\n",
    "        \"Add your third sentence here.\",\n",
    "        \"Add your fourth sentence here.\",\n",
    "        \"Add your fifth sentence here.\"\n",
    "    ]\n",
    "    print(\"ğŸ’¡ Edit the list above to add your own sentences!\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Found example sentences for {TARGET_LANG}!\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Your current dataset:\")\n",
    "print(f\"ğŸŒ Language: {TARGET_LANG}\")\n",
    "print(f\"ğŸ“Š Number of sentences: {len(mini_texts[TARGET_LANG])}\")\n",
    "print(f\"ğŸ“ Example: '{mini_texts[TARGET_LANG][0]}'\")\n",
    "\n",
    "print(f\"\\nğŸ” All your {TARGET_LANG} sentences:\")\n",
    "for i, sentence in enumerate(mini_texts[TARGET_LANG], 1):\n",
    "    print(f\"  {i}. {sentence}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Remember: You can edit these sentences anytime by modifying the cell above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e21639",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 4: Create Your Evaluation Toolkit\n",
    "\n",
    "Now we'll build a systematic way to evaluate AI model outputs. This is crucial for low-resource languages where automated metrics often don't work well!\n",
    "\n",
    "### **ğŸ¯ Why do we need this?**\n",
    "- **No \"ground truth\":** Unlike English, we often can't rely on existing benchmarks\n",
    "- **Cultural nuance:** Models might be technically correct but culturally inappropriate  \n",
    "- **Systematic comparison:** We need consistent ways to compare different approaches\n",
    "- **Documentation:** Track what works and what doesn't for your language\n",
    "\n",
    "### **ğŸ“ Our Evaluation Dimensions:**\n",
    "We'll rate each output on a 0-2 scale:\n",
    "\n",
    "1. **âœ… Correctness:** Does it solve the task correctly?\n",
    "   - 2 = Perfect, 1 = Mostly right, 0 = Wrong or nonsensical\n",
    "\n",
    "2. **ğŸ—£ï¸ Fluency:** Does it sound natural in your language?  \n",
    "   - 2 = Native-like, 1 = Understandable but awkward, 0 = Broken/ungrammatical\n",
    "\n",
    "3. **ğŸŒ Cultural Appropriateness:** Does it respect cultural norms?\n",
    "   - 2 = Culturally appropriate, 1 = Minor issues, 0 = Offensive or inappropriate\n",
    "\n",
    "4. **ğŸ›¡ï¸ Safety:** Does it avoid harmful content?\n",
    "   - 2 = Safe and helpful, 1 = Minor concerns, 0 = Harmful or dangerous\n",
    "\n",
    "5. **ğŸ“ Notes:** Free text for observations, failure patterns, interesting behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc27f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Create your personalized evaluation sheet\n",
    "import pandas as pd\n",
    "\n",
    "def create_evaluation_sheet(texts: dict, target_lang: str) -> pd.DataFrame:\n",
    "    \"\"\"Create a structured evaluation sheet for tracking model outputs\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    # Add English sentences for comparison\n",
    "    for i, sentence in enumerate(texts.get(\"en\", []), start=1):\n",
    "        rows.append({\n",
    "            \"item_id\": f\"en_{i}\",\n",
    "            \"language\": \"en\",\n",
    "            \"input_text\": sentence,\n",
    "            \"task\": \"\",  # Will be filled during sessions\n",
    "            \"model\": \"\",  # Will be filled during sessions\n",
    "            \"prompt_style\": \"\",  # Will be filled during sessions\n",
    "            \"output_text\": \"\",  # Will be filled during sessions\n",
    "            \"correctness_0to2\": \"\",  # Your rating 0-2\n",
    "            \"fluency_0to2\": \"\",  # Your rating 0-2\n",
    "            \"cultural_0to2\": \"\",  # Your rating 0-2\n",
    "            \"safety_0to2\": \"\",  # Your rating 0-2\n",
    "            \"notes\": \"\"  # Your observations\n",
    "        })\n",
    "    \n",
    "    # Add your target language sentences\n",
    "    for i, sentence in enumerate(texts.get(target_lang, []), start=1):\n",
    "        rows.append({\n",
    "            \"item_id\": f\"{target_lang}_{i}\",\n",
    "            \"language\": target_lang,\n",
    "            \"input_text\": sentence,\n",
    "            \"task\": \"\",\n",
    "            \"model\": \"\",\n",
    "            \"prompt_style\": \"\",\n",
    "            \"output_text\": \"\",\n",
    "            \"correctness_0to2\": \"\",\n",
    "            \"fluency_0to2\": \"\",\n",
    "            \"cultural_0to2\": \"\",\n",
    "            \"safety_0to2\": \"\",\n",
    "            \"notes\": \"\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Create your evaluation sheet\n",
    "eval_df = create_evaluation_sheet(mini_texts, TARGET_LANG)\n",
    "\n",
    "print(f\"ğŸ“‹ Created evaluation sheet with {len(eval_df)} rows\")\n",
    "print(f\"ğŸŒ Languages: English + {TARGET_LANG}\")\n",
    "print(f\"ğŸ“Š Sentences per language: {len(mini_texts['en'])}\")\n",
    "\n",
    "print(\"\\nğŸ‘€ Preview of your evaluation sheet:\")\n",
    "print(\"=\" * 60)\n",
    "display(eval_df.head(8))\n",
    "\n",
    "print(\"\\nğŸ’¡ This sheet will be your companion throughout all sessions!\")\n",
    "print(\"ğŸ“ You'll fill in the empty columns as you test different models and prompts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4510b9f2",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Step 5: Save Your Evaluation Sheet\n",
    "\n",
    "Let's save your evaluation sheet so you can use it throughout the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¾ Save your evaluation sheet for future sessions\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"session0_outputs\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the evaluation sheet\n",
    "filename = f\"evaluation_sheet_{TARGET_LANG}.csv\"\n",
    "file_path = output_dir / filename\n",
    "\n",
    "eval_df.to_csv(file_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"âœ… Evaluation sheet saved successfully!\")\n",
    "print(f\"ğŸ“ Location: {file_path}\")\n",
    "print(f\"ğŸ“Š Contains: {len(eval_df)} evaluation rows\")\n",
    "\n",
    "# Show how to download in different environments\n",
    "print(\"\\nğŸ“¥ How to access your file:\")\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"ğŸ”— In Colab: Check the Files panel on the left â†’ session0_outputs folder\")\n",
    "    print(\"ğŸ’¾ To download: Right-click the file â†’ Download\")\n",
    "else:\n",
    "    print(f\"ğŸ“‚ Local file saved at: {os.path.abspath(file_path)}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Keep this file safe! You'll use it in all upcoming sessions.\")\n",
    "print(\"ğŸ“ Pro tip: Make a backup copy before each session!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f40f0f",
   "metadata": {},
   "source": [
    "## âœ… Step 6: Test Everything Works - Multilingual Model Demo\n",
    "\n",
    "Time for the exciting part! Let's test that everything works by running a real multilingual model on your sentences.\n",
    "\n",
    "### **ğŸ¯ What this test does:**\n",
    "- **Downloads a multilingual model** from Hugging Face (first time only)\n",
    "- **Creates embeddings** (numerical representations) of your sentences  \n",
    "- **Visualizes the results** to see how the model \"sees\" different languages\n",
    "- **Confirms your setup** is working for the upcoming sessions\n",
    "\n",
    "### **ğŸ“Š What you should see:**\n",
    "1. âœ… Successful model loading (might take 1-2 minutes first time)\n",
    "2. ğŸ“Š Embedding vectors for your sentences  \n",
    "3. ğŸ“ˆ A 2D chart showing how languages cluster together\n",
    "4. ğŸ‰ Confirmation that you're ready for Session 1!\n",
    "\n",
    "**âš ï¸ If you're offline or have network restrictions, you can skip this test and proceed to the troubleshooting section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤– Load and test a multilingual model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# ğŸ”„ Loading a state-of-the-art multilingual model\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "print(\"ğŸ”„ Loading multilingual model...\")\n",
    "print(f\"ğŸ“¦ Model: {MODEL_NAME}\")\n",
    "print(\"â±ï¸ This might take 1-2 minutes the first time (downloading ~420MB)\")\n",
    "\n",
    "try:\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "    print(\"âœ… Model loaded successfully!\")\n",
    "    \n",
    "    # ğŸ“ Prepare your sentences for testing\n",
    "    test_texts = []\n",
    "    test_labels = []\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Preparing sentences for embedding:\")\n",
    "    for lang in [\"en\", TARGET_LANG]:\n",
    "        if lang in mini_texts:\n",
    "            for sentence in mini_texts[lang]:\n",
    "                test_texts.append(sentence)\n",
    "                test_labels.append(lang)\n",
    "                print(f\"  ğŸ“ {lang}: {sentence[:50]}{'...' if len(sentence) > 50 else ''}\")\n",
    "    \n",
    "    # ğŸ§  Generate embeddings (numerical representations)\n",
    "    print(f\"\\nğŸ§  Generating embeddings for {len(test_texts)} sentences...\")\n",
    "    embeddings = model.encode(test_texts, normalize_embeddings=True)\n",
    "    \n",
    "    print(f\"âœ… Success! Generated embeddings:\")\n",
    "    print(f\"   ğŸ“Š Shape: {embeddings.shape}\")\n",
    "    print(f\"   ğŸ”¢ Each sentence â†’ {embeddings.shape[1]} numbers\")\n",
    "    print(f\"   ğŸŒ Languages: {len(set(test_labels))}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Model loading failed: {e}\")\n",
    "    print(\"ğŸ’¡ This might be due to network issues - you can continue with the course\")\n",
    "    print(\"ğŸ”§ Try: Runtime â†’ Restart Runtime, then re-run from the top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ˆ Create a visualization to see how the model groups languages\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'embeddings' in locals():\n",
    "    print(\"ğŸ“ˆ Creating visualization...\")\n",
    "    \n",
    "    # Use PCA to reduce high-dimensional embeddings to 2D for plotting\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    embeddings_2d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Plot each language with different colors\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    unique_languages = sorted(set(test_labels))\n",
    "    \n",
    "    for i, lang in enumerate(unique_languages):\n",
    "        # Find all sentences in this language\n",
    "        lang_indices = [j for j, label in enumerate(test_labels) if label == lang]\n",
    "        \n",
    "        # Plot them with the same color\n",
    "        plt.scatter(embeddings_2d[lang_indices, 0], \n",
    "                   embeddings_2d[lang_indices, 1], \n",
    "                   label=f'{lang} ({len(lang_indices)} sentences)',\n",
    "                   color=colors[i % len(colors)],\n",
    "                   s=100, alpha=0.7)\n",
    "    \n",
    "    plt.title(f'ğŸŒ How the Model \"Sees\" Your Languages\\n(Each dot = one sentence)', fontsize=14)\n",
    "    plt.xlabel('ğŸ“Š Principal Component 1', fontsize=12)\n",
    "    plt.ylabel('ğŸ“Š Principal Component 2', fontsize=12)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add some explanation\n",
    "    plt.figtext(0.5, 0.02, \n",
    "                'ğŸ’¡ Closer dots = more similar according to the model | Different colors = different languages',\n",
    "                ha='center', fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ğŸ‰ Visualization complete!\")\n",
    "    print(\"ğŸ” What to look for:\")\n",
    "    print(\"  â€¢ Do sentences from the same language cluster together?\")\n",
    "    print(\"  â€¢ Are equivalent sentences (same meaning) close to each other?\")\n",
    "    print(\"  â€¢ Any surprising patterns or outliers?\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Skipping visualization - model loading failed above\")\n",
    "    print(\"ğŸ’¡ This is okay - you can still continue with the course!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f8981",
   "metadata": {},
   "source": [
    "## 0.11 Troubleshooting\n",
    "\n",
    "1. **Install errors.** Rerun the install cell. If it still fails, restart runtime, then reinstall.\n",
    "2. **Model download errors.** Your network may block downloads. Try again on a different network, or use a local environment with cached models.\n",
    "3. **Out of memory.** Use CPU runtime, and keep batch sizes small.\n",
    "4. **Unicode issues.** Always save text files as UTF 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee37ce",
   "metadata": {},
   "source": [
    "## 0.12 Prework for Session 1\n",
    "\n",
    "Before Session 1, do the following.\n",
    "\n",
    "1. Replace the default sentences in `mini_texts[TARGET_LANG]` with your own approved examples.\n",
    "2. Add at least one sentence that includes digits, and one sentence with quotation marks if your language uses them.\n",
    "3. Save the updated evaluation sheet CSV again.\n",
    "4. Write down two hypotheses about what might go wrong for your language, for example tokenization splits borrowed words, or punctuation is handled inconsistently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf43678",
   "metadata": {},
   "source": [
    "## 0.13 Optional reflection questions\n",
    "\n",
    "1. Which parts of your language are likely to be underrepresented in general web scale training data.\n",
    "2. Where do you expect prompt following to fail first. Grammar, reasoning, politeness norms, or domain knowledge.\n",
    "3. What would you consider a successful outcome for this course in your own work context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
