{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 0: Getting Started ğŸŒ\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "**ğŸ“š Course Repository:** [github.com/NinaKivanani/Tutorials_low-resource-llm](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NinaKivanani/Tutorials_low-resource-llm/blob/main/0_Setup.ipynb)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-View%20Repository-blue?logo=github)](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**Welcome!** This is a gentle introduction to working with models. Think of it as a warm-up before we dive into the main tutorial.\n",
    "\n",
    "## ğŸ¯ What you'll learn (step by step):\n",
    "\n",
    "1. <span style=\"color: #2196F3;\">**ğŸ”§ Setup**</span> - Install tools and load them\n",
    "2. <span style=\"color: #4CAF50;\">**âœ‚ï¸ Tokenization**</span> - See how models break text into pieces  \n",
    "3. <span style=\"color: #FF9800;\">**ğŸ” Simple comparison**</span> - Compare English vs. your target language\n",
    "4. <span style=\"color: #9C27B0;\">**ğŸ“Š Basic visualization**</span> - Create your first language comparison chart\n",
    "5. <span style=\"color: #F44336;\">**ğŸ“ Observations**</span> - Document what you discover\n",
    "\n",
    "**â±ï¸ Time needed:** ~20-30 minutes  \n",
    "**ğŸ’» Requirements:** Just this notebook - no complex setup needed!\n",
    "\n",
    "**ğŸš€ Why this matters:** Understanding how models handle different languages helps you make better choices for dialogue summarization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: ğŸ”§ Setup - Let's get the tools we need!\n",
    "\n",
    "**What we're doing:** Installing the basic tools to work with multilingual models.  \n",
    "**Why:** These are the standard libraries used in most NLP projects.  \n",
    "**Time:** ~2-3 minutes (depending on your internet speed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ Install the packages we need\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Simple function to install required packages\"\"\"\n",
    "    packages = [\n",
    "        \"transformers\",  # For loading multilingual models\n",
    "        \"torch\",         # PyTorch (the engine behind most models)\n",
    "        \"matplotlib\",    # For creating charts\n",
    "        \"pandas\",        # For organizing data in tables\n",
    "        \"numpy\"          # For number crunching\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ”„ Installing packages...\")\n",
    "    for pkg in packages:\n",
    "        print(f\"  Installing {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "    \n",
    "    print(\"âœ… All packages installed!\")\n",
    "\n",
    "# Run the installation\n",
    "try:\n",
    "    install_packages()\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ Installation had issues, but you can probably continue.\")\n",
    "    print(\"If you already have these packages, you're good to go!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š Import the libraries (like importing tools from a toolbox)\n",
    "import pandas as pd              # For organizing data in tables\n",
    "import matplotlib.pyplot as plt  # For making charts and graphs\n",
    "import numpy as np              # For working with numbers and arrays\n",
    "from transformers import AutoTokenizer  # The main tool for loading tokenizers\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(\"ğŸ‰ You're ready to start exploring multilingual models!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: âœ‚ï¸ Understanding Tokenization - How models \"read\" text\n",
    "\n",
    "**What is tokenization?** ğŸ¤”  \n",
    "Think of tokenization like cutting a sentence into puzzle pieces. Different models cut differently!\n",
    "\n",
    "**Why does this matter?**  \n",
    "- Some languages get cut into tiny pieces (bad for the model)\n",
    "- Others get cut nicely (good for the model)\n",
    "- This affects how well the model understands your language\n",
    "\n",
    "**Let's see this in action!** ğŸ‘€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ Let's start with some simple test sentences\n",
    "# We'll use the same meaning in different languages\n",
    "\n",
    "test_sentences = {\n",
    "    \"English\": \"Hello, how are you today?\",\n",
    "    \"French\": \"Bonjour, comment allez-vous aujourd'hui?\", \n",
    "    \"German\": \"Hallo, wie geht es Ihnen heute?\",\n",
    "    \"Luxembourgish\": \"Moien, wÃ©i geet et Iech haut?\",\n",
    "    \"Arabic\": \"Ù…Ø±Ø­Ø¨Ø§ØŒ ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ\"\n",
    "}\n",
    "\n",
    "print(\"ğŸŒ Our test sentences (all mean 'Hello, how are you today?'):\")\n",
    "print(\"=\" * 60)\n",
    "for language, sentence in test_sentences.items():\n",
    "    print(f\"{language:12}: {sentence}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Notice: Same meaning, different scripts and structures!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤– Let's load a popular multilingual model\n",
    "# We'll use mBERT (multilingual BERT) - it's widely used and reliable\n",
    "\n",
    "print(\"ğŸ”„ Loading mBERT tokenizer...\")\n",
    "print(\"(This might take a minute the first time - it's downloading the model)\")\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "    print(\"âœ… Success! mBERT tokenizer is ready to use\")\n",
    "    print(\"ğŸ“Š This model knows 104 languages!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Oops! Something went wrong: {e}\")\n",
    "    print(\"ğŸ’¡ Try running this cell again, or check your internet connection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Now let's see how the model tokenizes our sentences!\n",
    "\n",
    "print(\"âœ‚ï¸ TOKENIZATION EXPERIMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# We'll store our results here\n",
    "results = []\n",
    "\n",
    "for language, sentence in test_sentences.items():\n",
    "    print(f\"\\nğŸŒ Language: {language}\")\n",
    "    print(f\"ğŸ“ Sentence: {sentence}\")\n",
    "    \n",
    "    # Tokenize the sentence\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    # Count tokens and characters\n",
    "    num_tokens = len(tokens)\n",
    "    num_chars = len(sentence)\n",
    "    \n",
    "    print(f\"âœ‚ï¸  Tokens: {tokens}\")\n",
    "    print(f\"ğŸ“Š Number of tokens: {num_tokens}\")\n",
    "    print(f\"ğŸ“ Characters per token: {num_chars/num_tokens:.1f}\")\n",
    "    \n",
    "    # Store results for later\n",
    "    results.append({\n",
    "        'Language': language,\n",
    "        'Sentence': sentence,\n",
    "        'Num_Tokens': num_tokens,\n",
    "        'Num_Chars': num_chars,\n",
    "        'Chars_per_Token': num_chars/num_tokens\n",
    "    })\n",
    "\n",
    "print(\"\\nğŸ‰ Tokenization complete! Let's analyze the results...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: ğŸ“Š Let's make a simple chart to compare languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our results to a pandas table (easier to work with)\n",
    "df = pd.DataFrame(results)\n",
    "print(\"ğŸ“‹ Results Summary:\")\n",
    "print(df)\n",
    "\n",
    "# Create a simple bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df['Language'], df['Chars_per_Token'], color=['skyblue', 'lightgreen', 'orange', 'pink', 'lightcoral'])\n",
    "plt.title('ğŸ“Š Characters per Token by Language\\n(Higher = More efficient tokenization)', fontsize=14)\n",
    "plt.xlabel('Language', fontsize=12)\n",
    "plt.ylabel('Characters per Token', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for i, v in enumerate(df['Chars_per_Token']):\n",
    "    plt.text(i, v + 0.1, f'{v:.1f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ” What do you notice?\")\n",
    "print(\"ğŸ’¡ Languages with higher bars are tokenized more efficiently!\")\n",
    "print(\"ğŸ’¡ Languages with lower bars get 'chopped up' more by the model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: ğŸ¤” Let's think about what we learned\n",
    "\n",
    "**What did our experiment show us?**\n",
    "\n",
    "Take a look at your chart above and think about these questions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤” Discussion Questions - Think about these!\n",
    "\n",
    "print(\"ğŸ” REFLECTION QUESTIONS\")\n",
    "print(\"=\" * 40)\n",
    "print()\n",
    "print(\"1. ğŸ“Š Which language had the HIGHEST characters per token?\")\n",
    "print(\"   ğŸ’­ What does this mean for that language?\")\n",
    "print()\n",
    "print(\"2. ğŸ“Š Which language had the LOWEST characters per token?\") \n",
    "print(\"   ğŸ’­ What challenges might this create?\")\n",
    "print()\n",
    "print(\"3. ğŸŒ If you were building a chatbot, which language might be:\")\n",
    "print(\"   â€¢ Easiest for the model to understand?\")\n",
    "print(\"   â€¢ Most challenging for the model?\")\n",
    "print()\n",
    "print(\"4. ğŸ’¡ Why do you think some languages get 'chopped up' more than others?\")\n",
    "print(\"   Hint: Think about the alphabet, word structure, etc.\")\n",
    "print()\n",
    "\n",
    "# Let's find the best and worst performing languages\n",
    "best_lang = df.loc[df['Chars_per_Token'].idxmax()]\n",
    "worst_lang = df.loc[df['Chars_per_Token'].idxmin()]\n",
    "\n",
    "print(\"ğŸ“ˆ QUICK ANALYSIS:\")\n",
    "print(f\"ğŸ† Most efficient tokenization: {best_lang['Language']} ({best_lang['Chars_per_Token']:.1f} chars/token)\")\n",
    "print(f\"âš ï¸  Least efficient tokenization: {worst_lang['Language']} ({worst_lang['Chars_per_Token']:.1f} chars/token)\")\n",
    "print()\n",
    "print(\"ğŸ’¡ This means the model might understand\", best_lang['Language'], \"better than\", worst_lang['Language'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ Your Observation Notes\n",
    "# Feel free to edit this cell and add your thoughts!\n",
    "\n",
    "observations = {\n",
    "    \"Most efficient language\": \"Fill this in based on your chart\",\n",
    "    \"Least efficient language\": \"Fill this in based on your chart\", \n",
    "    \"Surprising finding\": \"What surprised you about the results?\",\n",
    "    \"Implications for dialogue summarization\": \"How might this affect dialogue summarization?\",\n",
    "    \"Questions for further investigation\": \"What would you like to explore next?\"\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‹ MY OBSERVATIONS FROM SESSION 0\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in observations.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "    \n",
    "print(\"\\nğŸ’¡ Remember these insights for Session 1!\")\n",
    "print(\"They'll help you make better decisions about:\")\n",
    "print(\"â€¢ Which models to use\")\n",
    "print(\"â€¢ How to preprocess your text\") \n",
    "print(\"â€¢ What challenges to expect\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Congratulations! You've completed Session 0!\n",
    "\n",
    "**What you accomplished:**\n",
    "âœ… Set up your first multilingual model  \n",
    "âœ… Learned about tokenization  \n",
    "âœ… Compared how different languages are handled  \n",
    "âœ… Created your first language comparison chart  \n",
    "âœ… Documented your observations  \n",
    "\n",
    "**Key takeaways:**\n",
    "- Different languages are tokenized very differently\n",
    "- Some languages work better with current models than others\n",
    "- This affects how well models understand different languages\n",
    "- These insights will help you in dialogue summarization\n",
    "\n",
    "**ğŸš€ You're now ready for Session 1: Dialogue Summarization!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Quick Summary of Your Results\n",
    "\n",
    "print(\"ğŸ“Š SESSION 0 SUMMARY\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"ğŸ”¬ Languages tested: {len(test_sentences)}\")\n",
    "print(f\"ğŸ¤– Model used: mBERT (multilingual BERT)\")\n",
    "print(f\"ğŸ“ˆ Most efficient: {best_lang['Language']} ({best_lang['Chars_per_Token']:.1f} chars/token)\")\n",
    "print(f\"ğŸ“‰ Least efficient: {worst_lang['Language']} ({worst_lang['Chars_per_Token']:.1f} chars/token)\")\n",
    "print()\n",
    "print(\"ğŸš€ Ready for Session 1: Dialogue Summarization!\")\n",
    "print(\"ğŸ’¡ Use these insights to make better model choices!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
