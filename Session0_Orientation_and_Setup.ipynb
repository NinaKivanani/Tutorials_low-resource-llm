{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be60dbd3",
   "metadata": {},
   "source": [
    "# Session 0: Getting Started with LLMs for Low-Resource Languages ğŸŒ\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "**ğŸ“š Course Repository:** [github.com/NinaKivanani/Tutorials_low-resource-llm](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NinaKivanani/Tutorials_low-resource-llm/blob/main/Session0_Orientation_and_Setup_LLMs_Low_Resource.ipynb)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-View%20Repository-blue?logo=github)](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "[![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](https://opensource.org/licenses/Apache-2.0)\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**Welcome to the course!** ğŸ‘‹ I'm excited to guide you through this journey into Large Language Models (LLMs) and low-resource languages. Think of this session as your orientation dayâ€”we'll get you set up, oriented, and ready to dive into the exciting work ahead!\n",
    "\n",
    "## ğŸ¯ Your Mission for Today (5 Simple Steps):\n",
    "\n",
    "By the end of this session, you'll have:\n",
    "\n",
    "1. **ğŸ”§ A Working Environment** - All tools installed and tested (15 min)\n",
    "2. **ğŸ—ºï¸ A Clear Roadmap** - Understanding of what's coming in Sessions 1-4 (5 min)\n",
    "3. **ğŸŒ Your Language Focus** - A chosen low-resource language and test dataset (10 min)\n",
    "4. **ğŸ“ An Evaluation Toolkit** - Your personal assessment framework (10 min)\n",
    "5. **âœ… Confidence** - Proof that everything works with a real model test! (10 min)\n",
    "\n",
    "**â±ï¸ Total time:** ~30-45 minutes  \n",
    "**ğŸ’» Platform:** Google Colab (recommended), Jupyter Notebook, or local Python\n",
    "---\n",
    "\n",
    "## ğŸŒŸ Why This Course Matters\n",
    "\n",
    "**Here's a sobering fact:** Most AI research focuses on just ~100 languages, leaving **6,900+ languages** largely ignored. These aren't \"small\" or \"unimportant\" languagesâ€”they're spoken by millions of people with rich cultural traditions and modern needs.\n",
    "\n",
    "**Your role:** You're learning to be a bridge-builder. After this course, you'll know how to:\n",
    "- Evaluate whether AI models work for *any* language, not just English\n",
    "- Adapt and improve models for languages with limited resources\n",
    "- Identify and address biases that harm minority language speakers\n",
    "- Build ethical, inclusive AI systems\n",
    "\n",
    "**This matters because:** Language is identity, culture, and community. When AI only works well for a few languages, we're creating a technological divide that reinforces inequality.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’­ A Quick Note Before We Start\n",
    "\n",
    "**If you're feeling nervous:** That's completely normal! Many participants come in thinking they need to be \"AI experts\" or \"fluent in programming.\" You don't. We'll explain every concept, every line of code, and every decision.\n",
    "\n",
    "**If something doesn't work:** That's actually valuable! In low-resource language work, things don't always work perfectlyâ€”and learning to troubleshoot is part of the skill. I'll help you through it.\n",
    "\n",
    "**Remember:** Questions are welcome at every step. No question is \"too basic\"â€”if you're wondering about it, others probably are too!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474afb1",
   "metadata": {},
   "source": [
    "## ğŸ—ºï¸ Your Learning Journey: The Complete Roadmap\n",
    "\n",
    "Think of this course as building a house for multilingual AI. Each session adds another essential layer:\n",
    "\n",
    "### **Session 1: ğŸ” How LLMs \"See\" Languages (The Foundation)**\n",
    "\n",
    "**The Big Question:** *Why does ChatGPT work better in English than in my language?*\n",
    "\n",
    "**What you'll learn:**\n",
    "- How language models break text into pieces (tokenization)\n",
    "- Why some languages get \"chopped up\" more than others\n",
    "- The connection between tokenization and model performance\n",
    "\n",
    "**Hands-on Activity:**  \n",
    "Take your chosen language and watch how different models tokenize it. You'll see exactly why some words get split into tiny fragments while others stay whole.\n",
    "\n",
    "**Real-world Impact:**  \n",
    "Understanding tokenization helps you predict which languages will struggle with which modelsâ€”and what to do about it.\n",
    "\n",
    "**â±ï¸ Time:** ~120 minutes | **ğŸ“Š What you'll create:** Tokenization comparison charts\n",
    "\n",
    "---\n",
    "\n",
    "### **Session 2: ğŸ’¬ Teaching LLMs New Tasks (The Walls)**\n",
    "\n",
    "**The Big Question:** *How do I get models to follow instructions in my language?*\n",
    "\n",
    "**What you'll learn:**\n",
    "- The art and science of \"prompt engineering\" (giving good instructions)\n",
    "- Why \"Translate this\" works in English but might fail in your language\n",
    "- Cross-lingual prompting strategies (using English hints for better results)\n",
    "\n",
    "**Hands-on Activity:**  \n",
    "Write prompts in your language, test different approaches, and discover what actually works (not what the internet says *should* work).\n",
    "\n",
    "**Real-world Impact:**  \n",
    "Good prompting can make a huge differenceâ€”sometimes turning unusable outputs into production-ready results, all without changing the model.\n",
    "\n",
    "**â±ï¸ Time:** ~120 minutes | **ğŸ“Š What you'll create:** Your personal prompt library\n",
    "\n",
    "---\n",
    "\n",
    "### **Session 3: ğŸ¯ Customizing LLMs for Your Language (The Roof)**\n",
    "\n",
    "**The Big Question:** *When should I customize a model vs. use it out-of-the-box?*\n",
    "\n",
    "**What you'll learn:**\n",
    "- When prompting isn't enough (and what to do instead)\n",
    "- How to fine-tune models with limited data\n",
    "- Cost-benefit analysis of different adaptation strategies\n",
    "\n",
    "**Hands-on Activity:**  \n",
    "Actually fine-tune a small model on your language! You'll see the before/after improvement and learn to spot when this approach is worth it.\n",
    "\n",
    "**Real-world Impact:**  \n",
    "Fine-tuning can dramatically improve performance, but it requires data and resources. You'll learn to make informed decisions about when it's worth the investment.\n",
    "\n",
    "**â±ï¸ Time:** ~120 minutes | **ğŸ“Š What you'll create:** A customized model for your language\n",
    "\n",
    "---\n",
    "\n",
    "### **Session 4: âš–ï¸ Responsible AI for All Languages (The Safety System)**\n",
    "\n",
    "**The Big Question:** *How do I make sure my AI doesn't cause harm?*\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to test for bias in multilingual models\n",
    "- Cultural appropriateness vs. technical correctness\n",
    "- Building fairness into your evaluation pipeline\n",
    "\n",
    "**Hands-on Activity:**  \n",
    "Run bias audits on real models using your language. You'll discover blind spots and design mitigation strategies.\n",
    "\n",
    "**Real-world Impact:**  \n",
    "AI that works technically but offends culturally is worse than no AI. You'll learn to build systems that respect the communities they serve.\n",
    "\n",
    "**â±ï¸ Time:** ~120 minutes | **ğŸ“Š What you'll create:** A bias audit framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37863517",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Course Materials & GitHub Repository\n",
    "\n",
    "**All course materials are available on GitHub!** This means you can:\n",
    "- ğŸ“¥ Download all notebooks and resources\n",
    "- ğŸ”„ Get updates as we improve materials\n",
    "- ğŸ’¾ Save your own copy to work on\n",
    "- ğŸŒ Access everything even after the course ends\n",
    "\n",
    "### **ğŸ”— Your Course Repository:**\n",
    "\n",
    "**GitHub URL:** [https://github.com/NinaKivanani/Tutorials_low-resource-llm](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "\n",
    "### **ğŸ“¦ What's in the Repository?**\n",
    "\n",
    "```\n",
    "Tutorials_low-resource-llm/\n",
    "â”‚\n",
    "â”œâ”€â”€ Session0_Orientation_and_Setup.ipynb          â† You are here!\n",
    "â”œâ”€â”€ Session1_Tokenization_Embeddings.ipynb        â† How LLMs \"see\" languages\n",
    "â”œâ”€â”€ Session2_Cross_Lingual_Prompting.ipynb        â† Teaching LLMs new tasks\n",
    "â”œâ”€â”€ Session3_Fine_Tuning.ipynb                    â† Customizing models\n",
    "â”œâ”€â”€ Session4_Bias_Audit.ipynb                     â† Responsible AI\n",
    "â”‚\n",
    "â”œâ”€â”€ data/                                         â† Sample datasets\n",
    "â”œâ”€â”€ examples/                                     â† Working examples\n",
    "â””â”€â”€ README.md                                     â† Course overview\n",
    "```\n",
    "\n",
    "### **ğŸš€ How to Use the Repository:**\n",
    "\n",
    "**Option 1: Run in Google Colab (Easiest - Recommended for Beginners)**\n",
    "1. Click on any notebook in the GitHub repository\n",
    "2. Look for the \"Open in Colab\" badge at the top\n",
    "3. Click it - the notebook opens in Google Colab\n",
    "4. You're ready to run code! (No installation needed on your computer)\n",
    "\n",
    "**Option 2: Download to Your Computer**\n",
    "1. Go to the GitHub repository\n",
    "2. Click the green \"Code\" button\n",
    "3. Select \"Download ZIP\"\n",
    "4. Extract the files on your computer\n",
    "5. Open with Jupyter Notebook or VS Code\n",
    "\n",
    "**Option 3: Clone with Git (For Advanced Users)**\n",
    "```bash\n",
    "git clone https://github.com/NinaKivanani/Tutorials_low-resource-llm.git\n",
    "cd Tutorials_low-resource-llm\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "### **ğŸ’¡ Pro Tips:**\n",
    "\n",
    "**Staying Updated:**\n",
    "- â­ **Star the repository** on GitHub to bookmark it\n",
    "- ğŸ‘€ **Watch the repository** to get notifications of updates\n",
    "- ğŸ”„ Check back periodically - we add new examples and fix issues!\n",
    "\n",
    "**Getting Help:**\n",
    "- ğŸ› Found a bug? Open an \"Issue\" on GitHub\n",
    "- ğŸ’¬ Have questions? Use the \"Discussions\" tab\n",
    "- ğŸ¤ Want to contribute? Pull requests welcome!\n",
    "\n",
    "**Making it Your Own:**\n",
    "- ğŸ´ **Fork the repository** to create your own copy\n",
    "- âœï¸ Modify notebooks for your specific language/use case\n",
    "- ğŸ’¾ Your changes are saved to YOUR fork, not the original\n",
    "\n",
    "### **ğŸ†˜ \"I'm New to GitHub\" - Quick Guide:**\n",
    "\n",
    "**What is GitHub?** Think of it as Google Drive for code. It stores files and tracks changes.\n",
    "\n",
    "**Do I need an account?** \n",
    "- To *view* and *download*: NO âœ…\n",
    "- To *save changes* or *contribute*: YES (free to sign up)\n",
    "\n",
    "**I just want the notebooks!**\n",
    "- Click the GitHub link above\n",
    "- Click on any `.ipynb` file\n",
    "- Click \"Open in Colab\" or \"Download\"\n",
    "- Done! ğŸ‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¤ Our Learning Agreement\n",
    "\n",
    "Let's establish some important principles for working together:\n",
    "\n",
    "### **ğŸ”¬ Scientific Rigor**\n",
    "- **Document everything:** Keep track of which models, prompts, and settings you use\n",
    "- **Reproducible results:** Others should be able to recreate your experiments\n",
    "- **Learn from failures:** When something doesn't work, that's valuable data too!\n",
    "\n",
    "### **ğŸŒ Language Respect** \n",
    "- **\"Low-resource\" â‰  \"low-value\":** These languages represent rich cultures and communities\n",
    "- **Cultural sensitivity:** Respect local conventions, writing systems, and cultural norms\n",
    "- **Avoid linguistic imperialism:** Don't assume English-centric approaches are always best\n",
    "\n",
    "### **ğŸ”’ Data Safety & Ethics**\n",
    "- **No personal data:** Don't use private messages, medical records, or confidential information\n",
    "- **Public-safe content:** Only use text you're comfortable sharing publicly\n",
    "- **Respect privacy:** When in doubt, create synthetic examples instead\n",
    "\n",
    "### **ğŸ“š Growth Mindset**\n",
    "- **Questions welcome:** No question is too basic - ask away!\n",
    "- **Collaborative learning:** Help your peers and learn from them\n",
    "- **Iterate and improve:** Expect to refine your approaches as you learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9082f776",
   "metadata": {},
   "source": [
    "## âœ… Pre-Session Checklist\n",
    "\n",
    "Let's make sure you're ready for the hands-on sessions! Check off each item as you complete it:\n",
    "\n",
    "### **ğŸ“š Course Materials Access**\n",
    "- [ ] **Visit the GitHub repository:** [https://github.com/NinaKivanani/Tutorials_low-resource-llm](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
    "  - *Why?* All course notebooks and materials are here!\n",
    "  - *How?* See the \"Course Materials & GitHub Repository\" section above for detailed instructions\n",
    "- [ ] **Star/bookmark the repository:** So you can find it again easily\n",
    "- [ ] **Download or open in Colab:** Get the notebooks you need for the course\n",
    "\n",
    "### **ğŸ’» Platform Setup**\n",
    "- [ ] **Choose your platform:** Google Colab (recommended for beginners) or local Jupyter\n",
    "  - *Colab advantage:* No installation needed, free GPU access\n",
    "  - *Local advantage:* Works offline, more control\n",
    "- [ ] **Test access:** Can you create and run a simple notebook?\n",
    "- [ ] **GPU check:** Do you have access to GPU runtime? (CPU works fine too!)\n",
    "  - *In Colab:* Runtime â†’ Change runtime type â†’ GPU\n",
    "\n",
    "### **ğŸ”‘ Account Setup (Optional but Helpful)**\n",
    "- [ ] **Hugging Face account:** Sign up at [huggingface.co](https://huggingface.co) (free)\n",
    "  - *Why?* Access to thousands of pre-trained models and datasets\n",
    "  - *When you'll use it:* Sessions 1-4 for downloading models\n",
    "- [ ] **GitHub account:** Sign up at [github.com](https://github.com) (free)  \n",
    "  - *Why?* Save your work, contribute to course materials, star repositories\n",
    "  - *Not required:* You can view and download without an account!\n",
    "\n",
    "### **ğŸŒ Language Selection**\n",
    "- [ ] **Pick your target language:** Choose one low-resource language to focus on\n",
    "  - *Need ideas?* Try: Luxembourgish, Irish, Maltese, Icelandic, Basque, Welsh, or your heritage language\n",
    "  - *Unsure?* Use Luxembourgish as default - we have good examples ready!\n",
    "\n",
    "### **ğŸ“ Text Preparation**  \n",
    "- [ ] **Gather 5-10 sentences** in your target language\n",
    "  - *Requirements:* 6-20 words each, publicly shareable, no personal info\n",
    "  - *Include:* At least one with numbers, one with punctuation, one with borrowed words (if applicable)\n",
    "  - *Examples provided below!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95cf03",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Part 1: Getting Oriented (Read This First!)\n",
    "\n",
    "Before we start coding, let's make sure you understand how to work with notebooks and what to expect.\n",
    "\n",
    "## ğŸ“‹ Working with Notebooks: Essential Habits\n",
    "\n",
    "These simple habits will save you tons of time and frustration throughout the course. Trust me on these!\n",
    "\n",
    "### **ğŸ”„ Execution Order**\n",
    "- **Always run cells top-to-bottom** when starting fresh\n",
    "- **Restart runtime if things get weird** - it's like turning it off and on again!\n",
    "- **Re-run from the top** if you get unexpected errors\n",
    "\n",
    "### **ğŸ’¾ Save Your Work**  \n",
    "- **Keep all outputs** - they're useful for debugging and comparing results\n",
    "- **Save notebooks frequently** - don't lose your progress!\n",
    "- **Download results** - especially evaluation sheets and charts\n",
    "\n",
    "### **ğŸ” Language Comparison Tips**\n",
    "- **Keep meaning consistent** - when comparing languages, use equivalent sentences\n",
    "- **Respect language differences** - don't force English grammar onto other languages\n",
    "- **Note cultural context** - some concepts don't translate directly\n",
    "\n",
    "### **ğŸ†˜ When Things Go Wrong**\n",
    "1. **Check the error message** - read it carefully, it usually tells you what's wrong\n",
    "2. **Restart and re-run** - many issues are solved this way\n",
    "3. **Google it (stackoverflow)**\n",
    "4. **Ask for help** - don't struggle alone!\n",
    "5. **Document the problem** - it might be useful later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040d5fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¬ Part 2: Hands-On Setup (Now We Start Coding!)\n",
    "\n",
    "Great! Now that you understand the context and best practices, let's get your hands dirty with actual code. Don't worryâ€”I'll explain every step.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ Step 1: Install Required Libraries (Your AI Toolbox)\n",
    "\n",
    "**What we're doing:** Installing Python packages that contain pre-written code for working with AI models.\n",
    "\n",
    "**Think of it like this:** You're downloading apps on your phone. Each \"library\" is like an app that gives you specific superpowers:\n",
    "\n",
    "### **ğŸ“¦ Your AI Superpowers (What We're Installing):**\n",
    "\n",
    "**ğŸ¤— The Model Library (Transformers + Friends):**\n",
    "- `transformers` - Access to GPT, BERT, and thousands of other models\n",
    "  - *Real talk:* This is the most important package. It's maintained by Hugging Face and used by researchers worldwide.\n",
    "- `datasets` - Pre-made collections of text in many languages\n",
    "- `sentence-transformers` - Turn sentences into numbers (for comparing them)\n",
    "\n",
    "**ğŸ“Š The Data Science Stack:**\n",
    "- `pandas` - Organize your results in spreadsheet-like tables\n",
    "  - *Beginner tip:* Think of it as Excel, but in Python\n",
    "- `numpy` - Do math on large arrays of numbers quickly\n",
    "- `matplotlib` - Create charts and graphs\n",
    "\n",
    "**ğŸ§  The Machine Learning Tools:**\n",
    "- `scikit-learn` - Tools for clustering, classification, and more\n",
    "  - *When you'll use it:* Session 1 (reducing dimensions for visualization)\n",
    "\n",
    "**âš¡ The Performance Boosters:**\n",
    "- `accelerate` - Makes models run faster (especially with GPU)\n",
    "- `tokenizers` - Fast text processing\n",
    "\n",
    "**â±ï¸ Time: 2-3 minutes** (downloading ~500MB of code)\n",
    "\n",
    "**What you'll see:**\n",
    "- Lots of text scrolling by âœ… Normal!\n",
    "- \"Successfully installed...\" âœ… Perfect!\n",
    "- Orange/yellow warnings âš ï¸ Usually safe to ignore\n",
    "- Red ERROR messages âŒ We need to fix these (I'll help!)\n",
    "\n",
    "**Pro tip:** While this runs, think about which language you want to focus on. Do you have a heritage language? A language you're learning? Or are you curious about a specific low-resource language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b14e214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15395.43s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires requests==2.31.0, but you have requests 2.32.5 which is incompatible.\n",
      "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m15466.45s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Installing Your AI Toolbox\n",
    "# \n",
    "# What these flags mean:\n",
    "# -q = \"quiet mode\" (less output spam)\n",
    "# -U = \"upgrade\" (get the latest versions)\n",
    "# install = download and set up the package\n",
    "#\n",
    "# You'll run this cell ONCE at the start of each session\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸš€ INSTALLATION STARTING\")\n",
    "print(\"=\"*60)\n",
    "print(\"â±ï¸  This will take 2-3 minutes...\")\n",
    "print(\"ğŸ“¥ Downloading ~500MB of Python packages...\")\n",
    "print()\n",
    "\n",
    "# --- PART 1: Core AI/NLP Libraries ---\n",
    "print(\"ğŸ“š Part 1/2: Installing AI model libraries...\")\n",
    "print(\"   (transformers, datasets, tokenizers, etc.)\")\n",
    "!pip -q install -U transformers datasets sentencepiece tokenizers accelerate\n",
    "\n",
    "# --- PART 2: Data Science Tools ---\n",
    "print(\"ğŸ“Š Part 2/2: Installing data science tools...\")\n",
    "print(\"   (pandas, numpy, matplotlib, etc.)\")\n",
    "!pip -q install -U sentence-transformers scikit-learn matplotlib pandas numpy\n",
    "\n",
    "# --- DONE! ---\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"âœ… INSTALLATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"ğŸ’¡ What just happened:\")\n",
    "print(\"   â€¢ Downloaded pre-written code from the internet\")\n",
    "print(\"   â€¢ Installed it into your Python environment\")\n",
    "print(\"   â€¢ Made it available for the upcoming code cells\")\n",
    "print()\n",
    "print(\"âš ï¸ Saw warnings? That's usually fine! Warnings (yellow/orange) are different from errors (red).\")\n",
    "print()\n",
    "print(\"ğŸ”„ If you see errors or imports fail later:\")\n",
    "print(\"   1. Try: Runtime â†’ Restart Runtime\")\n",
    "print(\"   2. Re-run this cell and all cells below it\")\n",
    "print(\"   3. Still stuck? That's what instructors are for!\")\n",
    "print()\n",
    "print(\"ğŸ‰ Ready for the next step!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba6e81d",
   "metadata": {},
   "source": [
    "## ğŸ” Step 2: Check Your Setup\n",
    "\n",
    "Let's make sure everything installed correctly and see what hardware you're working with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf1bdc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“… Setup Check Report\n",
      "========================================\n",
      "ğŸ“… Date: 2026-01-12 11:01 UTC\n",
      "ğŸ Python: 3.11.5\n",
      "ğŸ’» Platform: macOS-15.3-arm64-arm-64bit\n",
      "\n",
      "ğŸ“š Library Versions:\n",
      "  âœ… ğŸ¤— Transformers: 4.57.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nina.hosseinikivanan/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… ğŸ“Š Datasets: 4.4.2\n",
      "  âœ… ğŸ”¤ Sentence Transformers: 5.2.0\n",
      "  âœ… ğŸ”¥ PyTorch: 2.9.1\n",
      "  âœ… ğŸ§  Scikit-learn: 1.8.0\n",
      "  âœ… ğŸ“ˆ Matplotlib: 3.10.8\n",
      "  âœ… ğŸ¼ Pandas: 2.3.3\n",
      "  âœ… ğŸ”¢ NumPy: 1.26.4\n",
      "\n",
      "ğŸ’¡ All libraries should show âœ… - if you see âŒ, re-run the installation cell above!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Let's check what we're working with!\n",
    "import sys\n",
    "import platform\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "\n",
    "def get_package_version(name: str) -> str:\n",
    "    \"\"\"Get version of an installed package\"\"\"\n",
    "    try:\n",
    "        return importlib.import_module(name).__version__\n",
    "    except Exception:\n",
    "        return \"âŒ not available\"\n",
    "\n",
    "print(\"ğŸ“… Setup Check Report\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ğŸ“… Date: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\")\n",
    "print(f\"ğŸ Python: {sys.version.split()[0]}\")\n",
    "print(f\"ğŸ’» Platform: {platform.platform()}\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ“š Library Versions:\")\n",
    "libraries = [\n",
    "    (\"transformers\", \"ğŸ¤— Transformers\"),\n",
    "    (\"datasets\", \"ğŸ“Š Datasets\"), \n",
    "    (\"sentence_transformers\", \"ğŸ”¤ Sentence Transformers\"),\n",
    "    (\"torch\", \"ğŸ”¥ PyTorch\"),\n",
    "    (\"sklearn\", \"ğŸ§  Scikit-learn\"),\n",
    "    (\"matplotlib\", \"ğŸ“ˆ Matplotlib\"),\n",
    "    (\"pandas\", \"ğŸ¼ Pandas\"),\n",
    "    (\"numpy\", \"ğŸ”¢ NumPy\")\n",
    "]\n",
    "\n",
    "for pkg_name, display_name in libraries:\n",
    "    version = get_package_version(pkg_name)\n",
    "    status = \"âœ…\" if \"not available\" not in version else \"âŒ\"\n",
    "    print(f\"  {status} {display_name}: {version}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ All libraries should show âœ… - if you see âŒ, re-run the installation cell above!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ–¥ï¸ Hardware Check - Let's see what computing power you have!\n",
    "print(\"\\nğŸ–¥ï¸ Hardware Information:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    # Check for GPU availability\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    \n",
    "    if gpu_available:\n",
    "        print(\"ğŸš€ GPU Status: âœ… Available!\")\n",
    "        print(f\"   ğŸ® GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   âš¡ CUDA Version: {torch.version.cuda}\")\n",
    "        print(\"   ğŸ’¡ Great! You can run larger models faster\")\n",
    "    else:\n",
    "        print(\"ğŸ–¥ï¸  GPU Status: âŒ Not available (using CPU)\")\n",
    "        print(\"   ğŸ’¡ No worries! CPU works fine for this course\")\n",
    "        print(\"   ğŸ”§ To get GPU in Colab: Runtime â†’ Change runtime type â†’ GPU\")\n",
    "    \n",
    "    print(f\"\\nğŸ§  PyTorch Backend: {torch.version.__version__}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Hardware check failed: {e}\")\n",
    "    print(\"ğŸ’¡ This might be okay - try continuing with the course\")\n",
    "\n",
    "print(\"\\nğŸ‰ Setup check complete! You're ready to start learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab568db",
   "metadata": {},
   "source": [
    "## ğŸŒ Step 3: Choose Your Language & Create Your Dataset\n",
    "\n",
    "This is the fun part! You'll pick a language to focus on and create a small dataset that you'll use throughout all sessions.\n",
    "\n",
    "### **ğŸ¤” What makes a language \"low-resource\"?**\n",
    "- **Limited training data:** Less text available online for AI models to learn from\n",
    "- **Fewer speakers:** Often spoken by smaller communities  \n",
    "- **Less tech support:** Fewer tools, keyboards, fonts available\n",
    "- **Examples:** Luxembourgish (~600K speakers), Irish (~1.7M), Maltese (~500K), Icelandic (~350K)\n",
    "\n",
    "### **ğŸ“ Dataset Requirements:**\n",
    "Your sentences should be:\n",
    "- **ğŸ“ Short:** 6-20 words each (easier for models to handle)\n",
    "- **ğŸ”’ Public-safe:** Nothing personal, private, or confidential\n",
    "- **ğŸŒ Diverse:** Include different sentence types for better testing\n",
    "- **ğŸ“Š Consistent:** We'll compare these across different models\n",
    "\n",
    "### **ğŸ’¡ Pro Tips for Good Test Sentences:**\n",
    "- âœ… Include one with **numbers** (tests number handling)\n",
    "- âœ… Include one with **punctuation** (tests formatting)  \n",
    "- âœ… Include one with **borrowed words** (tests multilingual mixing)\n",
    "- âœ… Include **different topics** (greetings, facts, questions)\n",
    "- âŒ Avoid **names of real people** or **private information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30058e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸŒ Choose your target language and create your dataset!\n",
    "\n",
    "# ğŸ”¤ Set your target language code\n",
    "# Common options: \"lb\" (Luxembourgish), \"ga\" (Irish), \"mt\" (Maltese), \n",
    "#                \"is\" (Icelandic), \"eu\" (Basque), \"cy\" (Welsh)\n",
    "TARGET_LANG = \"lb\"  # Change this to your chosen language!\n",
    "\n",
    "print(f\"ğŸ¯ Your chosen language: {TARGET_LANG}\")\n",
    "print(\"ğŸ’¡ You can change this anytime by editing the cell above\")\n",
    "\n",
    "# ğŸ“š Sample datasets to get you started\n",
    "# These show the pattern - replace with your own sentences!\n",
    "mini_texts = {\n",
    "    \"en\": [\n",
    "        \"I enjoy learning how language models process text.\",\n",
    "        \"This sentence includes a number: 2026, and a comma.\",\n",
    "        \"Short prompts can still produce complex outputs.\",\n",
    "        \"Tokenization choices can change meaning and cost.\",\n",
    "        \"We will evaluate correctness, fluency, and safety.\"\n",
    "    ],\n",
    "    \"lb\": [  # Luxembourgish examples\n",
    "        \"Ech hunn Loscht ze verstoen, wÃ©i Sproochmodeller Text verschaffen.\",\n",
    "        \"DÃ«se Saz enthÃ¤lt eng Zuel: 2026, an eng Komma.\",\n",
    "        \"Kuerz Prompte kÃ«nnen trotzdeem komplex Ã„ntwerte produzÃ©ieren.\",\n",
    "        \"TokenisÃ©ierung kann Bedeitung an KÃ¤schte beaflossen.\",\n",
    "        \"Mir evaluÃ©ieren Richtegkeet, FlÃ«ssegkeet an SÃ©cherheet.\"\n",
    "    ],\n",
    "    \"ga\": [  # Irish examples\n",
    "        \"Is maith liom foghlaim conas a phrÃ³iseÃ¡lann samhlacha teanga tÃ©acs.\",\n",
    "        \"TÃ¡ uimhir sa abairt seo: 2026, agus camÃ³g.\",\n",
    "        \"Is fÃ©idir le leid ghearr aschuir chasta a thÃ¡irgeadh fÃ³s.\",\n",
    "        \"Is fÃ©idir le roghanna tocainithe brÃ­ agus costas a athrÃº.\",\n",
    "        \"DÃ©anaimid measÃºnÃº ar chruinneas, lÃ­ofacht agus sÃ¡bhÃ¡ilteacht.\"\n",
    "    ],\n",
    "    \"mt\": [  # Maltese examples  \n",
    "        \"JogÄ§obni nitgÄ§allem kif il-mudelli tal-lingwa jipproÄ‹essaw it-test.\",\n",
    "        \"Din is-sentenza tinkludi numru: 2026, u virgola.\",\n",
    "        \"Prompts qosra xorta jistgÄ§u jipproduÄ‹u outputs kumplessi.\",\n",
    "        \"L-gÄ§aÅ¼liet tat-tokenization jistgÄ§u jbiddlu t-tifsira u l-ispejjeÅ¼.\",\n",
    "        \"AÄ§na nevalwaw it-tÄ§assib, il-fluwenza u s-sigurtÃ .\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ğŸ”§ Add your language if it's not in the examples above\n",
    "if TARGET_LANG not in mini_texts:\n",
    "    print(f\"\\nğŸ“ {TARGET_LANG} not in examples - please add your sentences below!\")\n",
    "    mini_texts[TARGET_LANG] = [\n",
    "        \"Add your first sentence here (6-20 words).\",\n",
    "        \"Add your second sentence with a number: 2026.\",\n",
    "        \"Add your third sentence here.\",\n",
    "        \"Add your fourth sentence here.\",\n",
    "        \"Add your fifth sentence here.\"\n",
    "    ]\n",
    "    print(\"ğŸ’¡ Edit the list above to add your own sentences!\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Found example sentences for {TARGET_LANG}!\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Your current dataset:\")\n",
    "print(f\"ğŸŒ Language: {TARGET_LANG}\")\n",
    "print(f\"ğŸ“Š Number of sentences: {len(mini_texts[TARGET_LANG])}\")\n",
    "print(f\"ğŸ“ Example: '{mini_texts[TARGET_LANG][0]}'\")\n",
    "\n",
    "print(f\"\\nğŸ” All your {TARGET_LANG} sentences:\")\n",
    "for i, sentence in enumerate(mini_texts[TARGET_LANG], 1):\n",
    "    print(f\"  {i}. {sentence}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Remember: You can edit these sentences anytime by modifying the cell above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e21639",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 4: Create Your Evaluation Toolkit\n",
    "\n",
    "Now we'll build a systematic way to evaluate AI model outputs. This is crucial for low-resource languages where automated metrics often don't work well!\n",
    "\n",
    "### **ğŸ¯ Why do we need this?**\n",
    "- **No \"ground truth\":** Unlike English, we often can't rely on existing benchmarks\n",
    "- **Cultural nuance:** Models might be technically correct but culturally inappropriate  \n",
    "- **Systematic comparison:** We need consistent ways to compare different approaches\n",
    "- **Documentation:** Track what works and what doesn't for your language\n",
    "\n",
    "### **ğŸ“ Our Evaluation Dimensions:**\n",
    "We'll rate each output on a 0-2 scale:\n",
    "\n",
    "1. **âœ… Correctness:** Does it solve the task correctly?\n",
    "   - 2 = Perfect, 1 = Mostly right, 0 = Wrong or nonsensical\n",
    "\n",
    "2. **ğŸ—£ï¸ Fluency:** Does it sound natural in your language?  \n",
    "   - 2 = Native-like, 1 = Understandable but awkward, 0 = Broken/ungrammatical\n",
    "\n",
    "3. **ğŸŒ Cultural Appropriateness:** Does it respect cultural norms?\n",
    "   - 2 = Culturally appropriate, 1 = Minor issues, 0 = Offensive or inappropriate\n",
    "\n",
    "4. **ğŸ›¡ï¸ Safety:** Does it avoid harmful content?\n",
    "   - 2 = Safe and helpful, 1 = Minor concerns, 0 = Harmful or dangerous\n",
    "\n",
    "5. **ğŸ“ Notes:** Free text for observations, failure patterns, interesting behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc27f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Create your personalized evaluation sheet\n",
    "import pandas as pd\n",
    "\n",
    "def create_evaluation_sheet(texts: dict, target_lang: str) -> pd.DataFrame:\n",
    "    \"\"\"Create a structured evaluation sheet for tracking model outputs\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    # Add English sentences for comparison\n",
    "    for i, sentence in enumerate(texts.get(\"en\", []), start=1):\n",
    "        rows.append({\n",
    "            \"item_id\": f\"en_{i}\",\n",
    "            \"language\": \"en\",\n",
    "            \"input_text\": sentence,\n",
    "            \"task\": \"\",  # Will be filled during sessions\n",
    "            \"model\": \"\",  # Will be filled during sessions\n",
    "            \"prompt_style\": \"\",  # Will be filled during sessions\n",
    "            \"output_text\": \"\",  # Will be filled during sessions\n",
    "            \"correctness_0to2\": \"\",  # Your rating 0-2\n",
    "            \"fluency_0to2\": \"\",  # Your rating 0-2\n",
    "            \"cultural_0to2\": \"\",  # Your rating 0-2\n",
    "            \"safety_0to2\": \"\",  # Your rating 0-2\n",
    "            \"notes\": \"\"  # Your observations\n",
    "        })\n",
    "    \n",
    "    # Add your target language sentences\n",
    "    for i, sentence in enumerate(texts.get(target_lang, []), start=1):\n",
    "        rows.append({\n",
    "            \"item_id\": f\"{target_lang}_{i}\",\n",
    "            \"language\": target_lang,\n",
    "            \"input_text\": sentence,\n",
    "            \"task\": \"\",\n",
    "            \"model\": \"\",\n",
    "            \"prompt_style\": \"\",\n",
    "            \"output_text\": \"\",\n",
    "            \"correctness_0to2\": \"\",\n",
    "            \"fluency_0to2\": \"\",\n",
    "            \"cultural_0to2\": \"\",\n",
    "            \"safety_0to2\": \"\",\n",
    "            \"notes\": \"\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Create your evaluation sheet\n",
    "eval_df = create_evaluation_sheet(mini_texts, TARGET_LANG)\n",
    "\n",
    "print(f\"ğŸ“‹ Created evaluation sheet with {len(eval_df)} rows\")\n",
    "print(f\"ğŸŒ Languages: English + {TARGET_LANG}\")\n",
    "print(f\"ğŸ“Š Sentences per language: {len(mini_texts['en'])}\")\n",
    "\n",
    "print(\"\\nğŸ‘€ Preview of your evaluation sheet:\")\n",
    "print(\"=\" * 60)\n",
    "display(eval_df.head(8))\n",
    "\n",
    "print(\"\\nğŸ’¡ This sheet will be your companion throughout all sessions!\")\n",
    "print(\"ğŸ“ You'll fill in the empty columns as you test different models and prompts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4510b9f2",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Step 5: Save Your Evaluation Sheet\n",
    "\n",
    "Let's save your evaluation sheet so you can use it throughout the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¾ Save your evaluation sheet for future sessions\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"session0_outputs\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the evaluation sheet\n",
    "filename = f\"evaluation_sheet_{TARGET_LANG}.csv\"\n",
    "file_path = output_dir / filename\n",
    "\n",
    "eval_df.to_csv(file_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"âœ… Evaluation sheet saved successfully!\")\n",
    "print(f\"ğŸ“ Location: {file_path}\")\n",
    "print(f\"ğŸ“Š Contains: {len(eval_df)} evaluation rows\")\n",
    "\n",
    "# Show how to download in different environments\n",
    "print(\"\\nğŸ“¥ How to access your file:\")\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"ğŸ”— In Colab: Check the Files panel on the left â†’ session0_outputs folder\")\n",
    "    print(\"ğŸ’¾ To download: Right-click the file â†’ Download\")\n",
    "else:\n",
    "    print(f\"ğŸ“‚ Local file saved at: {os.path.abspath(file_path)}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Keep this file safe! You'll use it in all upcoming sessions.\")\n",
    "print(\"ğŸ“ Pro tip: Make a backup copy before each session!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f40f0f",
   "metadata": {},
   "source": [
    "## âœ… Step 6: Test Everything Works - Multilingual Model Demo\n",
    "\n",
    "Time for the exciting part! Let's test that everything works by running a real multilingual model on your sentences.\n",
    "\n",
    "### **ğŸ¯ What this test does:**\n",
    "- **Downloads a multilingual model** from Hugging Face (first time only)\n",
    "- **Creates embeddings** (numerical representations) of your sentences  \n",
    "- **Visualizes the results** to see how the model \"sees\" different languages\n",
    "- **Confirms your setup** is working for the upcoming sessions\n",
    "\n",
    "### **ğŸ“Š What you should see:**\n",
    "1. âœ… Successful model loading (might take 1-2 minutes first time)\n",
    "2. ğŸ“Š Embedding vectors for your sentences  \n",
    "3. ğŸ“ˆ A 2D chart showing how languages cluster together\n",
    "4. ğŸ‰ Confirmation that you're ready for Session 1!\n",
    "\n",
    "**âš ï¸ If you're offline or have network restrictions, you can skip this test and proceed to the troubleshooting section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤– Load and test a multilingual model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# ğŸ”„ Loading a state-of-the-art multilingual model\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "print(\"ğŸ”„ Loading multilingual model...\")\n",
    "print(f\"ğŸ“¦ Model: {MODEL_NAME}\")\n",
    "print(\"â±ï¸ This might take 1-2 minutes the first time (downloading ~420MB)\")\n",
    "\n",
    "try:\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "    print(\"âœ… Model loaded successfully!\")\n",
    "    \n",
    "    # ğŸ“ Prepare your sentences for testing\n",
    "    test_texts = []\n",
    "    test_labels = []\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Preparing sentences for embedding:\")\n",
    "    for lang in [\"en\", TARGET_LANG]:\n",
    "        if lang in mini_texts:\n",
    "            for sentence in mini_texts[lang]:\n",
    "                test_texts.append(sentence)\n",
    "                test_labels.append(lang)\n",
    "                print(f\"  ğŸ“ {lang}: {sentence[:50]}{'...' if len(sentence) > 50 else ''}\")\n",
    "    \n",
    "    # ğŸ§  Generate embeddings (numerical representations)\n",
    "    print(f\"\\nğŸ§  Generating embeddings for {len(test_texts)} sentences...\")\n",
    "    embeddings = model.encode(test_texts, normalize_embeddings=True)\n",
    "    \n",
    "    print(f\"âœ… Success! Generated embeddings:\")\n",
    "    print(f\"   ğŸ“Š Shape: {embeddings.shape}\")\n",
    "    print(f\"   ğŸ”¢ Each sentence â†’ {embeddings.shape[1]} numbers\")\n",
    "    print(f\"   ğŸŒ Languages: {len(set(test_labels))}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Model loading failed: {e}\")\n",
    "    print(\"ğŸ’¡ This might be due to network issues - you can continue with the course\")\n",
    "    print(\"ğŸ”§ Try: Runtime â†’ Restart Runtime, then re-run from the top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ˆ Create a visualization to see how the model groups languages\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'embeddings' in locals():\n",
    "    print(\"ğŸ“ˆ Creating visualization...\")\n",
    "    \n",
    "    # Use PCA to reduce high-dimensional embeddings to 2D for plotting\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    embeddings_2d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Plot each language with different colors\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    unique_languages = sorted(set(test_labels))\n",
    "    \n",
    "    for i, lang in enumerate(unique_languages):\n",
    "        # Find all sentences in this language\n",
    "        lang_indices = [j for j, label in enumerate(test_labels) if label == lang]\n",
    "        \n",
    "        # Plot them with the same color\n",
    "        plt.scatter(embeddings_2d[lang_indices, 0], \n",
    "                   embeddings_2d[lang_indices, 1], \n",
    "                   label=f'{lang} ({len(lang_indices)} sentences)',\n",
    "                   color=colors[i % len(colors)],\n",
    "                   s=100, alpha=0.7)\n",
    "    \n",
    "    plt.title(f'ğŸŒ How the Model \"Sees\" Your Languages\\n(Each dot = one sentence)', fontsize=14)\n",
    "    plt.xlabel('ğŸ“Š Principal Component 1', fontsize=12)\n",
    "    plt.ylabel('ğŸ“Š Principal Component 2', fontsize=12)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add some explanation\n",
    "    plt.figtext(0.5, 0.02, \n",
    "                'ğŸ’¡ Closer dots = more similar according to the model | Different colors = different languages',\n",
    "                ha='center', fontsize=10, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ğŸ‰ Visualization complete!\")\n",
    "    print(\"ğŸ” What to look for:\")\n",
    "    print(\"  â€¢ Do sentences from the same language cluster together?\")\n",
    "    print(\"  â€¢ Are equivalent sentences (same meaning) close to each other?\")\n",
    "    print(\"  â€¢ Any surprising patterns or outliers?\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Skipping visualization - model loading failed above\")\n",
    "    print(\"ğŸ’¡ This is okay - you can still continue with the course!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f8981",
   "metadata": {},
   "source": [
    "## 0.11 Troubleshooting\n",
    "\n",
    "1. **Install errors.** Rerun the install cell. If it still fails, restart runtime, then reinstall.\n",
    "2. **Model download errors.** Your network may block downloads. Try again on a different network, or use a local environment with cached models.\n",
    "3. **Out of memory.** Use CPU runtime, and keep batch sizes small.\n",
    "4. **Unicode issues.** Always save text files as UTF 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee37ce",
   "metadata": {},
   "source": [
    "## 0.12 Prework for Session 1\n",
    "\n",
    "Before Session 1, do the following.\n",
    "\n",
    "1. Replace the default sentences in `mini_texts[TARGET_LANG]` with your own approved examples.\n",
    "2. Add at least one sentence that includes digits, and one sentence with quotation marks if your language uses them.\n",
    "3. Save the updated evaluation sheet CSV again.\n",
    "4. Write down two hypotheses about what might go wrong for your language, for example tokenization splits borrowed words, or punctuation is handled inconsistently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf43678",
   "metadata": {},
   "source": [
    "## 0.13 Optional reflection questions\n",
    "\n",
    "1. Which parts of your language are likely to be underrepresented in general web scale training data.\n",
    "2. Where do you expect prompt following to fail first. Grammar, reasoning, politeness norms, or domain knowledge.\n",
    "3. What would you consider a successful outcome for this course in your own work context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
